# Generated from one_for_all.g4 by ANTLR 4.7.1
# encoding: utf-8
from antlr4 import *
from io import StringIO
from typing.io import TextIO
import sys

def serializedATN():
    with StringIO() as buf:
        buf.write("\3\u608b\ua72a\u8133\ub9ed\u417c\u3be7\u7786\u5964\3\62")
        buf.write("\u020b\4\2\t\2\4\3\t\3\4\4\t\4\4\5\t\5\4\6\t\6\4\7\t\7")
        buf.write("\4\b\t\b\4\t\t\t\4\n\t\n\4\13\t\13\4\f\t\f\4\r\t\r\4\16")
        buf.write("\t\16\4\17\t\17\4\20\t\20\4\21\t\21\4\22\t\22\4\23\t\23")
        buf.write("\4\24\t\24\4\25\t\25\4\26\t\26\4\27\t\27\4\30\t\30\4\31")
        buf.write("\t\31\4\32\t\32\4\33\t\33\4\34\t\34\4\35\t\35\4\36\t\36")
        buf.write("\4\37\t\37\4 \t \4!\t!\4\"\t\"\4#\t#\4$\t$\4%\t%\4&\t")
        buf.write("&\4\'\t\'\4(\t(\4)\t)\4*\t*\4+\t+\4,\t,\4-\t-\4.\t.\4")
        buf.write("/\t/\4\60\t\60\4\61\t\61\4\62\t\62\4\63\t\63\4\64\t\64")
        buf.write("\4\65\t\65\4\66\t\66\4\67\t\67\48\t8\49\t9\4:\t:\4;\t")
        buf.write(";\4<\t<\4=\t=\4>\t>\4?\t?\4@\t@\4A\tA\4B\tB\4C\tC\4D\t")
        buf.write("D\3\2\3\2\3\2\3\2\5\2\u008d\n\2\3\2\5\2\u0090\n\2\3\2")
        buf.write("\3\2\5\2\u0094\n\2\3\2\3\2\3\3\3\3\3\4\3\4\3\5\6\5\u009d")
        buf.write("\n\5\r\5\16\5\u009e\3\6\3\6\3\6\3\6\3\6\5\6\u00a6\n\6")
        buf.write("\3\6\5\6\u00a9\n\6\3\6\3\6\3\7\3\7\5\7\u00af\n\7\3\b\3")
        buf.write("\b\3\b\3\b\6\b\u00b5\n\b\r\b\16\b\u00b6\3\t\3\t\3\t\3")
        buf.write("\t\6\t\u00bd\n\t\r\t\16\t\u00be\3\n\6\n\u00c2\n\n\r\n")
        buf.write("\16\n\u00c3\3\13\3\13\3\13\3\13\3\13\5\13\u00cb\n\13\3")
        buf.write("\13\3\13\3\13\3\f\3\f\3\f\3\f\3\f\3\f\3\f\3\f\5\f\u00d8")
        buf.write("\n\f\3\f\3\f\3\r\3\r\3\r\3\r\3\r\3\r\3\r\3\r\3\r\5\r\u00e5")
        buf.write("\n\r\7\r\u00e7\n\r\f\r\16\r\u00ea\13\r\3\16\3\16\3\17")
        buf.write("\3\17\6\17\u00f0\n\17\r\17\16\17\u00f1\3\20\3\20\3\20")
        buf.write("\3\20\3\20\3\20\3\20\5\20\u00fb\n\20\3\20\3\20\3\20\3")
        buf.write("\20\3\20\3\20\5\20\u0103\n\20\7\20\u0105\n\20\f\20\16")
        buf.write("\20\u0108\13\20\3\20\3\20\3\21\3\21\3\21\3\21\3\21\3\21")
        buf.write("\3\21\5\21\u0113\n\21\3\21\3\21\3\21\3\21\3\21\3\21\3")
        buf.write("\21\3\21\5\21\u011d\n\21\3\21\3\21\7\21\u0121\n\21\f\21")
        buf.write("\16\21\u0124\13\21\3\21\3\21\3\22\3\22\3\23\3\23\3\23")
        buf.write("\3\24\3\24\3\24\3\24\3\25\3\25\3\25\3\25\3\26\3\26\3\26")
        buf.write("\3\26\3\26\3\26\3\26\7\26\u013c\n\26\f\26\16\26\u013f")
        buf.write("\13\26\3\27\3\27\3\27\3\27\3\27\3\30\3\30\3\30\3\30\3")
        buf.write("\30\3\30\3\30\3\30\3\30\3\31\3\31\3\32\3\32\3\33\3\33")
        buf.write("\3\33\3\33\3\33\3\33\3\33\3\33\3\33\3\34\3\34\3\35\3\35")
        buf.write("\3\36\3\36\3\37\3\37\3\37\3\37\3\37\3\37\3\37\3\37\3 ")
        buf.write("\3 \3 \3 \3 \3 \3!\3!\3!\3!\5!\u0174\n!\3\"\3\"\3#\6#")
        buf.write("\u0179\n#\r#\16#\u017a\3$\3$\3$\5$\u0180\n$\3$\3$\3$\5")
        buf.write("$\u0185\n$\3%\3%\3&\3&\3\'\3\'\3(\6(\u018e\n(\r(\16(\u018f")
        buf.write("\3)\3)\3)\3)\3)\3)\3)\5)\u0199\n)\3)\3)\3)\5)\u019e\n")
        buf.write(")\3*\3*\3+\3+\3,\3,\3-\3-\3.\3.\3/\3/\3\60\3\60\3\61\6")
        buf.write("\61\u01af\n\61\r\61\16\61\u01b0\3\62\3\62\3\62\3\62\5")
        buf.write("\62\u01b7\n\62\3\63\3\63\3\64\3\64\3\65\3\65\3\66\6\66")
        buf.write("\u01c0\n\66\r\66\16\66\u01c1\3\67\3\67\3\67\3\67\5\67")
        buf.write("\u01c8\n\67\38\38\39\39\3:\3:\3;\3;\3;\3;\3;\5;\u01d5")
        buf.write("\n;\3<\3<\3=\3=\3>\3>\3>\3>\3>\5>\u01e0\n>\3?\6?\u01e3")
        buf.write("\n?\r?\16?\u01e4\3@\3@\3@\3@\5@\u01eb\n@\3A\3A\3A\3A\3")
        buf.write("A\3A\3A\5A\u01f4\nA\3B\3B\3B\3B\5B\u01fa\nB\7B\u01fc\n")
        buf.write("B\fB\16B\u01ff\13B\3B\3B\3B\3C\3C\3D\3D\3D\3D\3D\3D\2")
        buf.write("\2E\2\4\6\b\n\f\16\20\22\24\26\30\32\34\36 \"$&(*,.\60")
        buf.write("\62\64\668:<>@BDFHJLNPRTVXZ\\^`bdfhjlnprtvxz|~\u0080\u0082")
        buf.write("\u0084\u0086\2\3\4\2,/\61\61\2\u0203\2\u0088\3\2\2\2\4")
        buf.write("\u0097\3\2\2\2\6\u0099\3\2\2\2\b\u009c\3\2\2\2\n\u00a0")
        buf.write("\3\2\2\2\f\u00ae\3\2\2\2\16\u00b4\3\2\2\2\20\u00bc\3\2")
        buf.write("\2\2\22\u00c1\3\2\2\2\24\u00c5\3\2\2\2\26\u00cf\3\2\2")
        buf.write("\2\30\u00e8\3\2\2\2\32\u00eb\3\2\2\2\34\u00ef\3\2\2\2")
        buf.write("\36\u00f3\3\2\2\2 \u010b\3\2\2\2\"\u0127\3\2\2\2$\u0129")
        buf.write("\3\2\2\2&\u012c\3\2\2\2(\u0130\3\2\2\2*\u013d\3\2\2\2")
        buf.write(",\u0140\3\2\2\2.\u0145\3\2\2\2\60\u014e\3\2\2\2\62\u0150")
        buf.write("\3\2\2\2\64\u0152\3\2\2\2\66\u015b\3\2\2\28\u015d\3\2")
        buf.write("\2\2:\u015f\3\2\2\2<\u0161\3\2\2\2>\u0169\3\2\2\2@\u0173")
        buf.write("\3\2\2\2B\u0175\3\2\2\2D\u0178\3\2\2\2F\u017c\3\2\2\2")
        buf.write("H\u0186\3\2\2\2J\u0188\3\2\2\2L\u018a\3\2\2\2N\u018d\3")
        buf.write("\2\2\2P\u0191\3\2\2\2R\u019f\3\2\2\2T\u01a1\3\2\2\2V\u01a3")
        buf.write("\3\2\2\2X\u01a5\3\2\2\2Z\u01a7\3\2\2\2\\\u01a9\3\2\2\2")
        buf.write("^\u01ab\3\2\2\2`\u01ae\3\2\2\2b\u01b2\3\2\2\2d\u01b8\3")
        buf.write("\2\2\2f\u01ba\3\2\2\2h\u01bc\3\2\2\2j\u01bf\3\2\2\2l\u01c3")
        buf.write("\3\2\2\2n\u01c9\3\2\2\2p\u01cb\3\2\2\2r\u01cd\3\2\2\2")
        buf.write("t\u01d4\3\2\2\2v\u01d6\3\2\2\2x\u01d8\3\2\2\2z\u01df\3")
        buf.write("\2\2\2|\u01e2\3\2\2\2~\u01ea\3\2\2\2\u0080\u01ec\3\2\2")
        buf.write("\2\u0082\u01f5\3\2\2\2\u0084\u0203\3\2\2\2\u0086\u0205")
        buf.write("\3\2\2\2\u0088\u0089\7\17\2\2\u0089\u008a\7\61\2\2\u008a")
        buf.write("\u008c\7(\2\2\u008b\u008d\5\b\5\2\u008c\u008b\3\2\2\2")
        buf.write("\u008c\u008d\3\2\2\2\u008d\u008f\3\2\2\2\u008e\u0090\5")
        buf.write("\34\17\2\u008f\u008e\3\2\2\2\u008f\u0090\3\2\2\2\u0090")
        buf.write("\u0091\3\2\2\2\u0091\u0093\5\4\3\2\u0092\u0094\5\22\n")
        buf.write("\2\u0093\u0092\3\2\2\2\u0093\u0094\3\2\2\2\u0094\u0095")
        buf.write("\3\2\2\2\u0095\u0096\5\6\4\2\u0096\3\3\2\2\2\u0097\u0098")
        buf.write("\3\2\2\2\u0098\5\3\2\2\2\u0099\u009a\5$\23\2\u009a\7\3")
        buf.write("\2\2\2\u009b\u009d\5\n\6\2\u009c\u009b\3\2\2\2\u009d\u009e")
        buf.write("\3\2\2\2\u009e\u009c\3\2\2\2\u009e\u009f\3\2\2\2\u009f")
        buf.write("\t\3\2\2\2\u00a0\u00a1\7\20\2\2\u00a1\u00a2\7\61\2\2\u00a2")
        buf.write("\u00a3\5\f\7\2\u00a3\u00a5\7\31\2\2\u00a4\u00a6\5\16\b")
        buf.write("\2\u00a5\u00a4\3\2\2\2\u00a5\u00a6\3\2\2\2\u00a6\u00a8")
        buf.write("\3\2\2\2\u00a7\u00a9\5\20\t\2\u00a8\u00a7\3\2\2\2\u00a8")
        buf.write("\u00a9\3\2\2\2\u00a9\u00aa\3\2\2\2\u00aa\u00ab\7\32\2")
        buf.write("\2\u00ab\13\3\2\2\2\u00ac\u00ad\7)\2\2\u00ad\u00af\7\61")
        buf.write("\2\2\u00ae\u00ac\3\2\2\2\u00ae\u00af\3\2\2\2\u00af\r\3")
        buf.write("\2\2\2\u00b0\u00b1\7\22\2\2\u00b1\u00b5\5\34\17\2\u00b2")
        buf.write("\u00b3\7\22\2\2\u00b3\u00b5\5\22\n\2\u00b4\u00b0\3\2\2")
        buf.write("\2\u00b4\u00b2\3\2\2\2\u00b5\u00b6\3\2\2\2\u00b6\u00b4")
        buf.write("\3\2\2\2\u00b6\u00b7\3\2\2\2\u00b7\17\3\2\2\2\u00b8\u00b9")
        buf.write("\7\21\2\2\u00b9\u00bd\5\34\17\2\u00ba\u00bb\7\21\2\2\u00bb")
        buf.write("\u00bd\5\22\n\2\u00bc\u00b8\3\2\2\2\u00bc\u00ba\3\2\2")
        buf.write("\2\u00bd\u00be\3\2\2\2\u00be\u00bc\3\2\2\2\u00be\u00bf")
        buf.write("\3\2\2\2\u00bf\21\3\2\2\2\u00c0\u00c2\5\24\13\2\u00c1")
        buf.write("\u00c0\3\2\2\2\u00c2\u00c3\3\2\2\2\u00c3\u00c1\3\2\2\2")
        buf.write("\u00c3\u00c4\3\2\2\2\u00c4\23\3\2\2\2\u00c5\u00c6\7\25")
        buf.write("\2\2\u00c6\u00c7\5\"\22\2\u00c7\u00c8\7\61\2\2\u00c8\u00ca")
        buf.write("\7\27\2\2\u00c9\u00cb\5\26\f\2\u00ca\u00c9\3\2\2\2\u00ca")
        buf.write("\u00cb\3\2\2\2\u00cb\u00cc\3\2\2\2\u00cc\u00cd\7\30\2")
        buf.write("\2\u00cd\u00ce\5&\24\2\u00ce\25\3\2\2\2\u00cf\u00d0\7")
        buf.write("\16\2\2\u00d0\u00d1\5\"\22\2\u00d1\u00d7\7\61\2\2\u00d2")
        buf.write("\u00d3\7\33\2\2\u00d3\u00d4\5D#\2\u00d4\u00d5\5\32\16")
        buf.write("\2\u00d5\u00d6\7\34\2\2\u00d6\u00d8\3\2\2\2\u00d7\u00d2")
        buf.write("\3\2\2\2\u00d7\u00d8\3\2\2\2\u00d8\u00d9\3\2\2\2\u00d9")
        buf.write("\u00da\5\30\r\2\u00da\27\3\2\2\2\u00db\u00dc\7+\2\2\u00dc")
        buf.write("\u00dd\7\16\2\2\u00dd\u00de\5\"\22\2\u00de\u00e4\7\61")
        buf.write("\2\2\u00df\u00e0\7\33\2\2\u00e0\u00e1\5D#\2\u00e1\u00e2")
        buf.write("\5\32\16\2\u00e2\u00e3\7\34\2\2\u00e3\u00e5\3\2\2\2\u00e4")
        buf.write("\u00df\3\2\2\2\u00e4\u00e5\3\2\2\2\u00e5\u00e7\3\2\2\2")
        buf.write("\u00e6\u00db\3\2\2\2\u00e7\u00ea\3\2\2\2\u00e8\u00e6\3")
        buf.write("\2\2\2\u00e8\u00e9\3\2\2\2\u00e9\31\3\2\2\2\u00ea\u00e8")
        buf.write("\3\2\2\2\u00eb\u00ec\3\2\2\2\u00ec\33\3\2\2\2\u00ed\u00f0")
        buf.write("\5\36\20\2\u00ee\u00f0\5 \21\2\u00ef\u00ed\3\2\2\2\u00ef")
        buf.write("\u00ee\3\2\2\2\u00f0\u00f1\3\2\2\2\u00f1\u00ef\3\2\2\2")
        buf.write("\u00f1\u00f2\3\2\2\2\u00f2\35\3\2\2\2\u00f3\u00f4\7\16")
        buf.write("\2\2\u00f4\u00f5\5\"\22\2\u00f5\u00fa\7\61\2\2\u00f6\u00f7")
        buf.write("\7\33\2\2\u00f7\u00f8\5D#\2\u00f8\u00f9\7\34\2\2\u00f9")
        buf.write("\u00fb\3\2\2\2\u00fa\u00f6\3\2\2\2\u00fa\u00fb\3\2\2\2")
        buf.write("\u00fb\u0106\3\2\2\2\u00fc\u00fd\7+\2\2\u00fd\u0102\7")
        buf.write("\61\2\2\u00fe\u00ff\7\33\2\2\u00ff\u0100\5D#\2\u0100\u0101")
        buf.write("\7\34\2\2\u0101\u0103\3\2\2\2\u0102\u00fe\3\2\2\2\u0102")
        buf.write("\u0103\3\2\2\2\u0103\u0105\3\2\2\2\u0104\u00fc\3\2\2\2")
        buf.write("\u0105\u0108\3\2\2\2\u0106\u0104\3\2\2\2\u0106\u0107\3")
        buf.write("\2\2\2\u0107\u0109\3\2\2\2\u0108\u0106\3\2\2\2\u0109\u010a")
        buf.write("\7(\2\2\u010a\37\3\2\2\2\u010b\u010c\7\16\2\2\u010c\u010d")
        buf.write("\5\"\22\2\u010d\u0112\7\61\2\2\u010e\u010f\7\33\2\2\u010f")
        buf.write("\u0110\5D#\2\u0110\u0111\7\34\2\2\u0111\u0113\3\2\2\2")
        buf.write("\u0112\u010e\3\2\2\2\u0112\u0113\3\2\2\2\u0113\u0114\3")
        buf.write("\2\2\2\u0114\u0115\7!\2\2\u0115\u0122\5D#\2\u0116\u0117")
        buf.write("\7+\2\2\u0117\u011c\7\61\2\2\u0118\u0119\7\33\2\2\u0119")
        buf.write("\u011a\5D#\2\u011a\u011b\7\34\2\2\u011b\u011d\3\2\2\2")
        buf.write("\u011c\u0118\3\2\2\2\u011c\u011d\3\2\2\2\u011d\u011e\3")
        buf.write("\2\2\2\u011e\u011f\7!\2\2\u011f\u0121\5D#\2\u0120\u0116")
        buf.write("\3\2\2\2\u0121\u0124\3\2\2\2\u0122\u0120\3\2\2\2\u0122")
        buf.write("\u0123\3\2\2\2\u0123\u0125\3\2\2\2\u0124\u0122\3\2\2\2")
        buf.write("\u0125\u0126\7(\2\2\u0126!\3\2\2\2\u0127\u0128\t\2\2\2")
        buf.write("\u0128#\3\2\2\2\u0129\u012a\7\23\2\2\u012a\u012b\5&\24")
        buf.write("\2\u012b%\3\2\2\2\u012c\u012d\7\31\2\2\u012d\u012e\5*")
        buf.write("\26\2\u012e\u012f\7\32\2\2\u012f\'\3\2\2\2\u0130\u0131")
        buf.write("\7\60\2\2\u0131\u0132\5D#\2\u0132\u0133\7(\2\2\u0133)")
        buf.write("\3\2\2\2\u0134\u013c\5,\27\2\u0135\u013c\5.\30\2\u0136")
        buf.write("\u013c\5\64\33\2\u0137\u013c\5> \2\u0138\u013c\5<\37\2")
        buf.write("\u0139\u013c\5\34\17\2\u013a\u013c\5(\25\2\u013b\u0134")
        buf.write("\3\2\2\2\u013b\u0135\3\2\2\2\u013b\u0136\3\2\2\2\u013b")
        buf.write("\u0137\3\2\2\2\u013b\u0138\3\2\2\2\u013b\u0139\3\2\2\2")
        buf.write("\u013b\u013a\3\2\2\2\u013c\u013f\3\2\2\2\u013d\u013b\3")
        buf.write("\2\2\2\u013d\u013e\3\2\2\2\u013e+\3\2\2\2\u013f\u013d")
        buf.write("\3\2\2\2\u0140\u0141\5|?\2\u0141\u0142\7!\2\2\u0142\u0143")
        buf.write("\5D#\2\u0143\u0144\7(\2\2\u0144-\3\2\2\2\u0145\u0146\7")
        buf.write("\13\2\2\u0146\u0147\7\27\2\2\u0147\u0148\5D#\2\u0148\u0149")
        buf.write("\7\30\2\2\u0149\u014a\5\60\31\2\u014a\u014b\5&\24\2\u014b")
        buf.write("\u014c\5@!\2\u014c\u014d\5\62\32\2\u014d/\3\2\2\2\u014e")
        buf.write("\u014f\3\2\2\2\u014f\61\3\2\2\2\u0150\u0151\3\2\2\2\u0151")
        buf.write("\63\3\2\2\2\u0152\u0153\7\r\2\2\u0153\u0154\5\66\34\2")
        buf.write("\u0154\u0155\7\27\2\2\u0155\u0156\5D#\2\u0156\u0157\7")
        buf.write("\30\2\2\u0157\u0158\58\35\2\u0158\u0159\5&\24\2\u0159")
        buf.write("\u015a\5:\36\2\u015a\65\3\2\2\2\u015b\u015c\3\2\2\2\u015c")
        buf.write("\67\3\2\2\2\u015d\u015e\3\2\2\2\u015e9\3\2\2\2\u015f\u0160")
        buf.write("\3\2\2\2\u0160;\3\2\2\2\u0161\u0162\7\24\2\2\u0162\u0163")
        buf.write("\7\27\2\2\u0163\u0164\5D#\2\u0164\u0165\7+\2\2\u0165\u0166")
        buf.write("\7\61\2\2\u0166\u0167\7\30\2\2\u0167\u0168\7(\2\2\u0168")
        buf.write("=\3\2\2\2\u0169\u016a\7\26\2\2\u016a\u016b\7\27\2\2\u016b")
        buf.write("\u016c\5D#\2\u016c\u016d\7\30\2\2\u016d\u016e\7(\2\2\u016e")
        buf.write("?\3\2\2\2\u016f\u0170\5B\"\2\u0170\u0171\7\f\2\2\u0171")
        buf.write("\u0172\5&\24\2\u0172\u0174\3\2\2\2\u0173\u016f\3\2\2\2")
        buf.write("\u0173\u0174\3\2\2\2\u0174A\3\2\2\2\u0175\u0176\3\2\2")
        buf.write("\2\u0176C\3\2\2\2\u0177\u0179\5F$\2\u0178\u0177\3\2\2")
        buf.write("\2\u0179\u017a\3\2\2\2\u017a\u0178\3\2\2\2\u017a\u017b")
        buf.write("\3\2\2\2\u017bE\3\2\2\2\u017c\u0184\5N(\2\u017d\u0180")
        buf.write("\5J&\2\u017e\u0180\5L\'\2\u017f\u017d\3\2\2\2\u017f\u017e")
        buf.write("\3\2\2\2\u0180\u0181\3\2\2\2\u0181\u0182\5N(\2\u0182\u0183")
        buf.write("\5H%\2\u0183\u0185\3\2\2\2\u0184\u017f\3\2\2\2\u0184\u0185")
        buf.write("\3\2\2\2\u0185G\3\2\2\2\u0186\u0187\3\2\2\2\u0187I\3\2")
        buf.write("\2\2\u0188\u0189\7\7\2\2\u0189K\3\2\2\2\u018a\u018b\7")
        buf.write("\b\2\2\u018bM\3\2\2\2\u018c\u018e\5P)\2\u018d\u018c\3")
        buf.write("\2\2\2\u018e\u018f\3\2\2\2\u018f\u018d\3\2\2\2\u018f\u0190")
        buf.write("\3\2\2\2\u0190O\3\2\2\2\u0191\u019d\5`\61\2\u0192\u0199")
        buf.write("\5T+\2\u0193\u0199\5V,\2\u0194\u0199\5X-\2\u0195\u0199")
        buf.write("\5Z.\2\u0196\u0199\5\\/\2\u0197\u0199\5^\60\2\u0198\u0192")
        buf.write("\3\2\2\2\u0198\u0193\3\2\2\2\u0198\u0194\3\2\2\2\u0198")
        buf.write("\u0195\3\2\2\2\u0198\u0196\3\2\2\2\u0198\u0197\3\2\2\2")
        buf.write("\u0199\u019a\3\2\2\2\u019a\u019b\5`\61\2\u019b\u019c\5")
        buf.write("R*\2\u019c\u019e\3\2\2\2\u019d\u0198\3\2\2\2\u019d\u019e")
        buf.write("\3\2\2\2\u019eQ\3\2\2\2\u019f\u01a0\3\2\2\2\u01a0S\3\2")
        buf.write("\2\2\u01a1\u01a2\7\'\2\2\u01a2U\3\2\2\2\u01a3\u01a4\7")
        buf.write("\"\2\2\u01a4W\3\2\2\2\u01a5\u01a6\7#\2\2\u01a6Y\3\2\2")
        buf.write("\2\u01a7\u01a8\7%\2\2\u01a8[\3\2\2\2\u01a9\u01aa\7$\2")
        buf.write("\2\u01aa]\3\2\2\2\u01ab\u01ac\7&\2\2\u01ac_\3\2\2\2\u01ad")
        buf.write("\u01af\5b\62\2\u01ae\u01ad\3\2\2\2\u01af\u01b0\3\2\2\2")
        buf.write("\u01b0\u01ae\3\2\2\2\u01b0\u01b1\3\2\2\2\u01b1a\3\2\2")
        buf.write("\2\u01b2\u01b3\5j\66\2\u01b3\u01b6\5d\63\2\u01b4\u01b7")
        buf.write("\5f\64\2\u01b5\u01b7\5h\65\2\u01b6\u01b4\3\2\2\2\u01b6")
        buf.write("\u01b5\3\2\2\2\u01b6\u01b7\3\2\2\2\u01b7c\3\2\2\2\u01b8")
        buf.write("\u01b9\3\2\2\2\u01b9e\3\2\2\2\u01ba\u01bb\7\35\2\2\u01bb")
        buf.write("g\3\2\2\2\u01bc\u01bd\7\36\2\2\u01bdi\3\2\2\2\u01be\u01c0")
        buf.write("\5l\67\2\u01bf\u01be\3\2\2\2\u01c0\u01c1\3\2\2\2\u01c1")
        buf.write("\u01bf\3\2\2\2\u01c1\u01c2\3\2\2\2\u01c2k\3\2\2\2\u01c3")
        buf.write("\u01c4\5t;\2\u01c4\u01c7\5n8\2\u01c5\u01c8\5p9\2\u01c6")
        buf.write("\u01c8\5r:\2\u01c7\u01c5\3\2\2\2\u01c7\u01c6\3\2\2\2\u01c7")
        buf.write("\u01c8\3\2\2\2\u01c8m\3\2\2\2\u01c9\u01ca\3\2\2\2\u01ca")
        buf.write("o\3\2\2\2\u01cb\u01cc\7\37\2\2\u01ccq\3\2\2\2\u01cd\u01ce")
        buf.write("\7 \2\2\u01ces\3\2\2\2\u01cf\u01d0\5v<\2\u01d0\u01d1\5")
        buf.write("D#\2\u01d1\u01d2\5x=\2\u01d2\u01d5\3\2\2\2\u01d3\u01d5")
        buf.write("\5z>\2\u01d4\u01cf\3\2\2\2\u01d4\u01d3\3\2\2\2\u01d5u")
        buf.write("\3\2\2\2\u01d6\u01d7\7\27\2\2\u01d7w\3\2\2\2\u01d8\u01d9")
        buf.write("\7\30\2\2\u01d9y\3\2\2\2\u01da\u01e0\7\4\2\2\u01db\u01e0")
        buf.write("\7\5\2\2\u01dc\u01e0\7\3\2\2\u01dd\u01e0\7\6\2\2\u01de")
        buf.write("\u01e0\5|?\2\u01df\u01da\3\2\2\2\u01df\u01db\3\2\2\2\u01df")
        buf.write("\u01dc\3\2\2\2\u01df\u01dd\3\2\2\2\u01df\u01de\3\2\2\2")
        buf.write("\u01e0{\3\2\2\2\u01e1\u01e3\5~@\2\u01e2\u01e1\3\2\2\2")
        buf.write("\u01e3\u01e4\3\2\2\2\u01e4\u01e2\3\2\2\2\u01e4\u01e5\3")
        buf.write("\2\2\2\u01e5}\3\2\2\2\u01e6\u01eb\7\61\2\2\u01e7\u01eb")
        buf.write("\5\u0080A\2\u01e8\u01eb\5\u0082B\2\u01e9\u01eb\5\u0086")
        buf.write("D\2\u01ea\u01e6\3\2\2\2\u01ea\u01e7\3\2\2\2\u01ea\u01e8")
        buf.write("\3\2\2\2\u01ea\u01e9\3\2\2\2\u01eb\177\3\2\2\2\u01ec\u01ed")
        buf.write("\7\61\2\2\u01ed\u01ee\7*\2\2\u01ee\u01f3\7\61\2\2\u01ef")
        buf.write("\u01f0\7\27\2\2\u01f0\u01f1\5D#\2\u01f1\u01f2\7\30\2\2")
        buf.write("\u01f2\u01f4\3\2\2\2\u01f3\u01ef\3\2\2\2\u01f3\u01f4\3")
        buf.write("\2\2\2\u01f4\u0081\3\2\2\2\u01f5\u01f6\7\61\2\2\u01f6")
        buf.write("\u01fd\7\27\2\2\u01f7\u01f9\5D#\2\u01f8\u01fa\7+\2\2\u01f9")
        buf.write("\u01f8\3\2\2\2\u01f9\u01fa\3\2\2\2\u01fa\u01fc\3\2\2\2")
        buf.write("\u01fb\u01f7\3\2\2\2\u01fc\u01ff\3\2\2\2\u01fd\u01fb\3")
        buf.write("\2\2\2\u01fd\u01fe\3\2\2\2\u01fe\u0200\3\2\2\2\u01ff\u01fd")
        buf.write("\3\2\2\2\u0200\u0201\5\u0084C\2\u0201\u0202\7\30\2\2\u0202")
        buf.write("\u0083\3\2\2\2\u0203\u0204\3\2\2\2\u0204\u0085\3\2\2\2")
        buf.write("\u0205\u0206\7\61\2\2\u0206\u0207\7\33\2\2\u0207\u0208")
        buf.write("\5D#\2\u0208\u0209\7\34\2\2\u0209\u0087\3\2\2\2.\u008c")
        buf.write("\u008f\u0093\u009e\u00a5\u00a8\u00ae\u00b4\u00b6\u00bc")
        buf.write("\u00be\u00c3\u00ca\u00d7\u00e4\u00e8\u00ef\u00f1\u00fa")
        buf.write("\u0102\u0106\u0112\u011c\u0122\u013b\u013d\u0173\u017a")
        buf.write("\u017f\u0184\u018f\u0198\u019d\u01b0\u01b6\u01c1\u01c7")
        buf.write("\u01d4\u01df\u01e4\u01ea\u01f3\u01f9\u01fd")
        return buf.getvalue()


class one_for_allParser ( Parser ):

    grammarFileName = "one_for_all.g4"

    atn = ATNDeserializer().deserialize(serializedATN())

    decisionsToDFA = [ DFA(ds, i) for i, ds in enumerate(atn.decisionToState) ]

    sharedContextCache = PredictionContextCache()

    literalNames = [ "<INVALID>", "<INVALID>", "<INVALID>", "<INVALID>", 
                     "<INVALID>", "'&&'", "'||'", "'true'", "'false'", "'if'", 
                     "'else'", "'while'", "'var'", "'program'", "'class'", 
                     "'private'", "'public'", "'main'", "'read'", "'function'", 
                     "'write'", "'('", "')'", "'{'", "'}'", "'['", "']'", 
                     "'+'", "'-'", "'*'", "'/'", "'='", "'!='", "'>'", "'<'", 
                     "'>='", "'<='", "'=='", "';'", "':'", "'.'", "','", 
                     "'int'", "'float'", "'bool'", "'string'", "'return'" ]

    symbolicNames = [ "<INVALID>", "STRING", "FLOAT", "INT", "BOOLEAN", 
                      "TOK_AND", "TOK_OR", "TRUE", "FALSE", "TOK_IF", "TOK_ELSE", 
                      "TOK_WHILE", "TOK_VAR", "TOK_PROGRAM", "TOK_CLASS", 
                      "TOK_PRIVATE", "TOK_PUBLIC", "TOK_MAIN", "TOK_READ", 
                      "TOK_FUNCTION", "TOK_WRITE", "TOK_LPAREN", "TOK_RPAREN", 
                      "TOK_LBRACE", "TOK_RBRACE", "TOK_LBRACKET", "TOK_RBRACKET", 
                      "TOK_PLUS", "TOK_MINUS", "TOK_MULTIPLICATION", "TOK_DIVISION", 
                      "TOK_EQUAL", "TOK_DIFFERENT", "TOK_GREATER", "TOK_LESS", 
                      "TOK_GREATER_EQ", "TOK_LESS_EQ", "TOK_SAME", "TOK_SEMICOLON", 
                      "TOK_COLON", "TOK_DOT", "TOK_COMMA", "TOK_INT", "TOK_FLOAT", 
                      "TOK_BOOLEAN", "TOK_STRING", "TOK_RETURN", "TOK_ID", 
                      "ESPACIOS" ]

    RULE_programa = 0
    RULE_neuro_jump_main = 1
    RULE_restOfProgram = 2
    RULE_classes = 3
    RULE_class_definition = 4
    RULE_inheritance = 5
    RULE_class_public = 6
    RULE_class_private = 7
    RULE_routines = 8
    RULE_routine_definition = 9
    RULE_parameters = 10
    RULE_parameters_recursive = 11
    RULE_neuro_array = 12
    RULE_variables = 13
    RULE_variable_definition = 14
    RULE_variable_assign = 15
    RULE_data_type = 16
    RULE_main = 17
    RULE_block = 18
    RULE_return_expr = 19
    RULE_statute = 20
    RULE_assignment = 21
    RULE_condition = 22
    RULE_neuro_if = 23
    RULE_neuro_endif = 24
    RULE_loop = 25
    RULE_neuro_while_begin = 26
    RULE_neuro_while_expression = 27
    RULE_neuro_while_end = 28
    RULE_input_ = 29
    RULE_output = 30
    RULE_condition_else = 31
    RULE_neuro_else = 32
    RULE_expressions = 33
    RULE_expression_definition = 34
    RULE_neuro_expression = 35
    RULE_token_and = 36
    RULE_token_or = 37
    RULE_relational_exprs = 38
    RULE_relational_expr_definition = 39
    RULE_neuro_relational = 40
    RULE_token_same = 41
    RULE_token_different = 42
    RULE_token_greater = 43
    RULE_token_greater_eq = 44
    RULE_token_less = 45
    RULE_token_less_eq = 46
    RULE_sumMinus_exprs = 47
    RULE_sumMinus_expr_definition = 48
    RULE_neuro_sumMinus = 49
    RULE_token_plus = 50
    RULE_token_minus = 51
    RULE_multiDiv_exprs = 52
    RULE_multiDiv_expr_definition = 53
    RULE_neuro_multiDiv = 54
    RULE_token_multiplication = 55
    RULE_token_division = 56
    RULE_factor = 57
    RULE_token_lparen = 58
    RULE_token_rparen = 59
    RULE_constant = 60
    RULE_id_ = 61
    RULE_id_definition_ = 62
    RULE_evaluate_class = 63
    RULE_evaluate_function = 64
    RULE_neuro_params = 65
    RULE_evaluate_array = 66

    ruleNames =  [ "programa", "neuro_jump_main", "restOfProgram", "classes", 
                   "class_definition", "inheritance", "class_public", "class_private", 
                   "routines", "routine_definition", "parameters", "parameters_recursive", 
                   "neuro_array", "variables", "variable_definition", "variable_assign", 
                   "data_type", "main", "block", "return_expr", "statute", 
                   "assignment", "condition", "neuro_if", "neuro_endif", 
                   "loop", "neuro_while_begin", "neuro_while_expression", 
                   "neuro_while_end", "input_", "output", "condition_else", 
                   "neuro_else", "expressions", "expression_definition", 
                   "neuro_expression", "token_and", "token_or", "relational_exprs", 
                   "relational_expr_definition", "neuro_relational", "token_same", 
                   "token_different", "token_greater", "token_greater_eq", 
                   "token_less", "token_less_eq", "sumMinus_exprs", "sumMinus_expr_definition", 
                   "neuro_sumMinus", "token_plus", "token_minus", "multiDiv_exprs", 
                   "multiDiv_expr_definition", "neuro_multiDiv", "token_multiplication", 
                   "token_division", "factor", "token_lparen", "token_rparen", 
                   "constant", "id_", "id_definition_", "evaluate_class", 
                   "evaluate_function", "neuro_params", "evaluate_array" ]

    EOF = Token.EOF
    STRING=1
    FLOAT=2
    INT=3
    BOOLEAN=4
    TOK_AND=5
    TOK_OR=6
    TRUE=7
    FALSE=8
    TOK_IF=9
    TOK_ELSE=10
    TOK_WHILE=11
    TOK_VAR=12
    TOK_PROGRAM=13
    TOK_CLASS=14
    TOK_PRIVATE=15
    TOK_PUBLIC=16
    TOK_MAIN=17
    TOK_READ=18
    TOK_FUNCTION=19
    TOK_WRITE=20
    TOK_LPAREN=21
    TOK_RPAREN=22
    TOK_LBRACE=23
    TOK_RBRACE=24
    TOK_LBRACKET=25
    TOK_RBRACKET=26
    TOK_PLUS=27
    TOK_MINUS=28
    TOK_MULTIPLICATION=29
    TOK_DIVISION=30
    TOK_EQUAL=31
    TOK_DIFFERENT=32
    TOK_GREATER=33
    TOK_LESS=34
    TOK_GREATER_EQ=35
    TOK_LESS_EQ=36
    TOK_SAME=37
    TOK_SEMICOLON=38
    TOK_COLON=39
    TOK_DOT=40
    TOK_COMMA=41
    TOK_INT=42
    TOK_FLOAT=43
    TOK_BOOLEAN=44
    TOK_STRING=45
    TOK_RETURN=46
    TOK_ID=47
    ESPACIOS=48

    def __init__(self, input:TokenStream, output:TextIO = sys.stdout):
        super().__init__(input, output)
        self.checkVersion("4.7.1")
        self._interp = ParserATNSimulator(self, self.atn, self.decisionsToDFA, self.sharedContextCache)
        self._predicates = None



    class ProgramaContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_PROGRAM(self):
            return self.getToken(one_for_allParser.TOK_PROGRAM, 0)

        def TOK_ID(self):
            return self.getToken(one_for_allParser.TOK_ID, 0)

        def TOK_SEMICOLON(self):
            return self.getToken(one_for_allParser.TOK_SEMICOLON, 0)

        def neuro_jump_main(self):
            return self.getTypedRuleContext(one_for_allParser.Neuro_jump_mainContext,0)


        def restOfProgram(self):
            return self.getTypedRuleContext(one_for_allParser.RestOfProgramContext,0)


        def classes(self):
            return self.getTypedRuleContext(one_for_allParser.ClassesContext,0)


        def variables(self):
            return self.getTypedRuleContext(one_for_allParser.VariablesContext,0)


        def routines(self):
            return self.getTypedRuleContext(one_for_allParser.RoutinesContext,0)


        def getRuleIndex(self):
            return one_for_allParser.RULE_programa

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterPrograma" ):
                listener.enterPrograma(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitPrograma" ):
                listener.exitPrograma(self)




    def programa(self):

        localctx = one_for_allParser.ProgramaContext(self, self._ctx, self.state)
        self.enterRule(localctx, 0, self.RULE_programa)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 134
            self.match(one_for_allParser.TOK_PROGRAM)
            self.state = 135
            self.match(one_for_allParser.TOK_ID)
            self.state = 136
            self.match(one_for_allParser.TOK_SEMICOLON)
            self.state = 138
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            if _la==one_for_allParser.TOK_CLASS:
                self.state = 137
                self.classes()


            self.state = 141
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            if _la==one_for_allParser.TOK_VAR:
                self.state = 140
                self.variables()


            self.state = 143
            self.neuro_jump_main()
            self.state = 145
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            if _la==one_for_allParser.TOK_FUNCTION:
                self.state = 144
                self.routines()


            self.state = 147
            self.restOfProgram()
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Neuro_jump_mainContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser


        def getRuleIndex(self):
            return one_for_allParser.RULE_neuro_jump_main

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterNeuro_jump_main" ):
                listener.enterNeuro_jump_main(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitNeuro_jump_main" ):
                listener.exitNeuro_jump_main(self)




    def neuro_jump_main(self):

        localctx = one_for_allParser.Neuro_jump_mainContext(self, self._ctx, self.state)
        self.enterRule(localctx, 2, self.RULE_neuro_jump_main)
        try:
            self.enterOuterAlt(localctx, 1)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class RestOfProgramContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def main(self):
            return self.getTypedRuleContext(one_for_allParser.MainContext,0)


        def getRuleIndex(self):
            return one_for_allParser.RULE_restOfProgram

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterRestOfProgram" ):
                listener.enterRestOfProgram(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitRestOfProgram" ):
                listener.exitRestOfProgram(self)




    def restOfProgram(self):

        localctx = one_for_allParser.RestOfProgramContext(self, self._ctx, self.state)
        self.enterRule(localctx, 4, self.RULE_restOfProgram)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 151
            self.main()
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class ClassesContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def class_definition(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.Class_definitionContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.Class_definitionContext,i)


        def getRuleIndex(self):
            return one_for_allParser.RULE_classes

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterClasses" ):
                listener.enterClasses(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitClasses" ):
                listener.exitClasses(self)




    def classes(self):

        localctx = one_for_allParser.ClassesContext(self, self._ctx, self.state)
        self.enterRule(localctx, 6, self.RULE_classes)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 154 
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while True:
                self.state = 153
                self.class_definition()
                self.state = 156 
                self._errHandler.sync(self)
                _la = self._input.LA(1)
                if not (_la==one_for_allParser.TOK_CLASS):
                    break

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Class_definitionContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_CLASS(self):
            return self.getToken(one_for_allParser.TOK_CLASS, 0)

        def TOK_ID(self):
            return self.getToken(one_for_allParser.TOK_ID, 0)

        def inheritance(self):
            return self.getTypedRuleContext(one_for_allParser.InheritanceContext,0)


        def TOK_LBRACE(self):
            return self.getToken(one_for_allParser.TOK_LBRACE, 0)

        def TOK_RBRACE(self):
            return self.getToken(one_for_allParser.TOK_RBRACE, 0)

        def class_public(self):
            return self.getTypedRuleContext(one_for_allParser.Class_publicContext,0)


        def class_private(self):
            return self.getTypedRuleContext(one_for_allParser.Class_privateContext,0)


        def getRuleIndex(self):
            return one_for_allParser.RULE_class_definition

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterClass_definition" ):
                listener.enterClass_definition(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitClass_definition" ):
                listener.exitClass_definition(self)




    def class_definition(self):

        localctx = one_for_allParser.Class_definitionContext(self, self._ctx, self.state)
        self.enterRule(localctx, 8, self.RULE_class_definition)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 158
            self.match(one_for_allParser.TOK_CLASS)
            self.state = 159
            self.match(one_for_allParser.TOK_ID)
            self.state = 160
            self.inheritance()
            self.state = 161
            self.match(one_for_allParser.TOK_LBRACE)
            self.state = 163
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            if _la==one_for_allParser.TOK_PUBLIC:
                self.state = 162
                self.class_public()


            self.state = 166
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            if _la==one_for_allParser.TOK_PRIVATE:
                self.state = 165
                self.class_private()


            self.state = 168
            self.match(one_for_allParser.TOK_RBRACE)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class InheritanceContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_COLON(self):
            return self.getToken(one_for_allParser.TOK_COLON, 0)

        def TOK_ID(self):
            return self.getToken(one_for_allParser.TOK_ID, 0)

        def getRuleIndex(self):
            return one_for_allParser.RULE_inheritance

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterInheritance" ):
                listener.enterInheritance(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitInheritance" ):
                listener.exitInheritance(self)




    def inheritance(self):

        localctx = one_for_allParser.InheritanceContext(self, self._ctx, self.state)
        self.enterRule(localctx, 10, self.RULE_inheritance)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 172
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            if _la==one_for_allParser.TOK_COLON:
                self.state = 170
                self.match(one_for_allParser.TOK_COLON)
                self.state = 171
                self.match(one_for_allParser.TOK_ID)


        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Class_publicContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_PUBLIC(self, i:int=None):
            if i is None:
                return self.getTokens(one_for_allParser.TOK_PUBLIC)
            else:
                return self.getToken(one_for_allParser.TOK_PUBLIC, i)

        def variables(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.VariablesContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.VariablesContext,i)


        def routines(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.RoutinesContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.RoutinesContext,i)


        def getRuleIndex(self):
            return one_for_allParser.RULE_class_public

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterClass_public" ):
                listener.enterClass_public(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitClass_public" ):
                listener.exitClass_public(self)




    def class_public(self):

        localctx = one_for_allParser.Class_publicContext(self, self._ctx, self.state)
        self.enterRule(localctx, 12, self.RULE_class_public)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 178 
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while True:
                self.state = 178
                self._errHandler.sync(self)
                la_ = self._interp.adaptivePredict(self._input,7,self._ctx)
                if la_ == 1:
                    self.state = 174
                    self.match(one_for_allParser.TOK_PUBLIC)
                    self.state = 175
                    self.variables()
                    pass

                elif la_ == 2:
                    self.state = 176
                    self.match(one_for_allParser.TOK_PUBLIC)
                    self.state = 177
                    self.routines()
                    pass


                self.state = 180 
                self._errHandler.sync(self)
                _la = self._input.LA(1)
                if not (_la==one_for_allParser.TOK_PUBLIC):
                    break

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Class_privateContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_PRIVATE(self, i:int=None):
            if i is None:
                return self.getTokens(one_for_allParser.TOK_PRIVATE)
            else:
                return self.getToken(one_for_allParser.TOK_PRIVATE, i)

        def variables(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.VariablesContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.VariablesContext,i)


        def routines(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.RoutinesContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.RoutinesContext,i)


        def getRuleIndex(self):
            return one_for_allParser.RULE_class_private

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterClass_private" ):
                listener.enterClass_private(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitClass_private" ):
                listener.exitClass_private(self)




    def class_private(self):

        localctx = one_for_allParser.Class_privateContext(self, self._ctx, self.state)
        self.enterRule(localctx, 14, self.RULE_class_private)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 186 
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while True:
                self.state = 186
                self._errHandler.sync(self)
                la_ = self._interp.adaptivePredict(self._input,9,self._ctx)
                if la_ == 1:
                    self.state = 182
                    self.match(one_for_allParser.TOK_PRIVATE)
                    self.state = 183
                    self.variables()
                    pass

                elif la_ == 2:
                    self.state = 184
                    self.match(one_for_allParser.TOK_PRIVATE)
                    self.state = 185
                    self.routines()
                    pass


                self.state = 188 
                self._errHandler.sync(self)
                _la = self._input.LA(1)
                if not (_la==one_for_allParser.TOK_PRIVATE):
                    break

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class RoutinesContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def routine_definition(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.Routine_definitionContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.Routine_definitionContext,i)


        def getRuleIndex(self):
            return one_for_allParser.RULE_routines

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterRoutines" ):
                listener.enterRoutines(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitRoutines" ):
                listener.exitRoutines(self)




    def routines(self):

        localctx = one_for_allParser.RoutinesContext(self, self._ctx, self.state)
        self.enterRule(localctx, 16, self.RULE_routines)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 191 
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while True:
                self.state = 190
                self.routine_definition()
                self.state = 193 
                self._errHandler.sync(self)
                _la = self._input.LA(1)
                if not (_la==one_for_allParser.TOK_FUNCTION):
                    break

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Routine_definitionContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_FUNCTION(self):
            return self.getToken(one_for_allParser.TOK_FUNCTION, 0)

        def data_type(self):
            return self.getTypedRuleContext(one_for_allParser.Data_typeContext,0)


        def TOK_ID(self):
            return self.getToken(one_for_allParser.TOK_ID, 0)

        def TOK_LPAREN(self):
            return self.getToken(one_for_allParser.TOK_LPAREN, 0)

        def TOK_RPAREN(self):
            return self.getToken(one_for_allParser.TOK_RPAREN, 0)

        def block(self):
            return self.getTypedRuleContext(one_for_allParser.BlockContext,0)


        def parameters(self):
            return self.getTypedRuleContext(one_for_allParser.ParametersContext,0)


        def getRuleIndex(self):
            return one_for_allParser.RULE_routine_definition

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterRoutine_definition" ):
                listener.enterRoutine_definition(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitRoutine_definition" ):
                listener.exitRoutine_definition(self)




    def routine_definition(self):

        localctx = one_for_allParser.Routine_definitionContext(self, self._ctx, self.state)
        self.enterRule(localctx, 18, self.RULE_routine_definition)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 195
            self.match(one_for_allParser.TOK_FUNCTION)
            self.state = 196
            self.data_type()
            self.state = 197
            self.match(one_for_allParser.TOK_ID)
            self.state = 198
            self.match(one_for_allParser.TOK_LPAREN)
            self.state = 200
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            if _la==one_for_allParser.TOK_VAR:
                self.state = 199
                self.parameters()


            self.state = 202
            self.match(one_for_allParser.TOK_RPAREN)
            self.state = 203
            self.block()
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class ParametersContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_VAR(self):
            return self.getToken(one_for_allParser.TOK_VAR, 0)

        def data_type(self):
            return self.getTypedRuleContext(one_for_allParser.Data_typeContext,0)


        def TOK_ID(self):
            return self.getToken(one_for_allParser.TOK_ID, 0)

        def parameters_recursive(self):
            return self.getTypedRuleContext(one_for_allParser.Parameters_recursiveContext,0)


        def TOK_LBRACKET(self):
            return self.getToken(one_for_allParser.TOK_LBRACKET, 0)

        def expressions(self):
            return self.getTypedRuleContext(one_for_allParser.ExpressionsContext,0)


        def neuro_array(self):
            return self.getTypedRuleContext(one_for_allParser.Neuro_arrayContext,0)


        def TOK_RBRACKET(self):
            return self.getToken(one_for_allParser.TOK_RBRACKET, 0)

        def getRuleIndex(self):
            return one_for_allParser.RULE_parameters

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterParameters" ):
                listener.enterParameters(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitParameters" ):
                listener.exitParameters(self)




    def parameters(self):

        localctx = one_for_allParser.ParametersContext(self, self._ctx, self.state)
        self.enterRule(localctx, 20, self.RULE_parameters)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 205
            self.match(one_for_allParser.TOK_VAR)
            self.state = 206
            self.data_type()
            self.state = 207
            self.match(one_for_allParser.TOK_ID)
            self.state = 213
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            if _la==one_for_allParser.TOK_LBRACKET:
                self.state = 208
                self.match(one_for_allParser.TOK_LBRACKET)
                self.state = 209
                self.expressions()
                self.state = 210
                self.neuro_array()
                self.state = 211
                self.match(one_for_allParser.TOK_RBRACKET)


            self.state = 215
            self.parameters_recursive()
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Parameters_recursiveContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_COMMA(self, i:int=None):
            if i is None:
                return self.getTokens(one_for_allParser.TOK_COMMA)
            else:
                return self.getToken(one_for_allParser.TOK_COMMA, i)

        def TOK_VAR(self, i:int=None):
            if i is None:
                return self.getTokens(one_for_allParser.TOK_VAR)
            else:
                return self.getToken(one_for_allParser.TOK_VAR, i)

        def data_type(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.Data_typeContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.Data_typeContext,i)


        def TOK_ID(self, i:int=None):
            if i is None:
                return self.getTokens(one_for_allParser.TOK_ID)
            else:
                return self.getToken(one_for_allParser.TOK_ID, i)

        def TOK_LBRACKET(self, i:int=None):
            if i is None:
                return self.getTokens(one_for_allParser.TOK_LBRACKET)
            else:
                return self.getToken(one_for_allParser.TOK_LBRACKET, i)

        def expressions(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.ExpressionsContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.ExpressionsContext,i)


        def neuro_array(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.Neuro_arrayContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.Neuro_arrayContext,i)


        def TOK_RBRACKET(self, i:int=None):
            if i is None:
                return self.getTokens(one_for_allParser.TOK_RBRACKET)
            else:
                return self.getToken(one_for_allParser.TOK_RBRACKET, i)

        def getRuleIndex(self):
            return one_for_allParser.RULE_parameters_recursive

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterParameters_recursive" ):
                listener.enterParameters_recursive(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitParameters_recursive" ):
                listener.exitParameters_recursive(self)




    def parameters_recursive(self):

        localctx = one_for_allParser.Parameters_recursiveContext(self, self._ctx, self.state)
        self.enterRule(localctx, 22, self.RULE_parameters_recursive)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 230
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while _la==one_for_allParser.TOK_COMMA:
                self.state = 217
                self.match(one_for_allParser.TOK_COMMA)
                self.state = 218
                self.match(one_for_allParser.TOK_VAR)
                self.state = 219
                self.data_type()
                self.state = 220
                self.match(one_for_allParser.TOK_ID)
                self.state = 226
                self._errHandler.sync(self)
                _la = self._input.LA(1)
                if _la==one_for_allParser.TOK_LBRACKET:
                    self.state = 221
                    self.match(one_for_allParser.TOK_LBRACKET)
                    self.state = 222
                    self.expressions()
                    self.state = 223
                    self.neuro_array()
                    self.state = 224
                    self.match(one_for_allParser.TOK_RBRACKET)


                self.state = 232
                self._errHandler.sync(self)
                _la = self._input.LA(1)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Neuro_arrayContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser


        def getRuleIndex(self):
            return one_for_allParser.RULE_neuro_array

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterNeuro_array" ):
                listener.enterNeuro_array(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitNeuro_array" ):
                listener.exitNeuro_array(self)




    def neuro_array(self):

        localctx = one_for_allParser.Neuro_arrayContext(self, self._ctx, self.state)
        self.enterRule(localctx, 24, self.RULE_neuro_array)
        try:
            self.enterOuterAlt(localctx, 1)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class VariablesContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def variable_definition(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.Variable_definitionContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.Variable_definitionContext,i)


        def variable_assign(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.Variable_assignContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.Variable_assignContext,i)


        def getRuleIndex(self):
            return one_for_allParser.RULE_variables

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterVariables" ):
                listener.enterVariables(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitVariables" ):
                listener.exitVariables(self)




    def variables(self):

        localctx = one_for_allParser.VariablesContext(self, self._ctx, self.state)
        self.enterRule(localctx, 26, self.RULE_variables)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 237 
            self._errHandler.sync(self)
            _alt = 1
            while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                if _alt == 1:
                    self.state = 237
                    self._errHandler.sync(self)
                    la_ = self._interp.adaptivePredict(self._input,16,self._ctx)
                    if la_ == 1:
                        self.state = 235
                        self.variable_definition()
                        pass

                    elif la_ == 2:
                        self.state = 236
                        self.variable_assign()
                        pass



                else:
                    raise NoViableAltException(self)
                self.state = 239 
                self._errHandler.sync(self)
                _alt = self._interp.adaptivePredict(self._input,17,self._ctx)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Variable_definitionContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_VAR(self):
            return self.getToken(one_for_allParser.TOK_VAR, 0)

        def data_type(self):
            return self.getTypedRuleContext(one_for_allParser.Data_typeContext,0)


        def TOK_ID(self, i:int=None):
            if i is None:
                return self.getTokens(one_for_allParser.TOK_ID)
            else:
                return self.getToken(one_for_allParser.TOK_ID, i)

        def TOK_SEMICOLON(self):
            return self.getToken(one_for_allParser.TOK_SEMICOLON, 0)

        def TOK_LBRACKET(self, i:int=None):
            if i is None:
                return self.getTokens(one_for_allParser.TOK_LBRACKET)
            else:
                return self.getToken(one_for_allParser.TOK_LBRACKET, i)

        def expressions(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.ExpressionsContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.ExpressionsContext,i)


        def TOK_RBRACKET(self, i:int=None):
            if i is None:
                return self.getTokens(one_for_allParser.TOK_RBRACKET)
            else:
                return self.getToken(one_for_allParser.TOK_RBRACKET, i)

        def TOK_COMMA(self, i:int=None):
            if i is None:
                return self.getTokens(one_for_allParser.TOK_COMMA)
            else:
                return self.getToken(one_for_allParser.TOK_COMMA, i)

        def getRuleIndex(self):
            return one_for_allParser.RULE_variable_definition

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterVariable_definition" ):
                listener.enterVariable_definition(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitVariable_definition" ):
                listener.exitVariable_definition(self)




    def variable_definition(self):

        localctx = one_for_allParser.Variable_definitionContext(self, self._ctx, self.state)
        self.enterRule(localctx, 28, self.RULE_variable_definition)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 241
            self.match(one_for_allParser.TOK_VAR)
            self.state = 242
            self.data_type()
            self.state = 243
            self.match(one_for_allParser.TOK_ID)
            self.state = 248
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            if _la==one_for_allParser.TOK_LBRACKET:
                self.state = 244
                self.match(one_for_allParser.TOK_LBRACKET)
                self.state = 245
                self.expressions()
                self.state = 246
                self.match(one_for_allParser.TOK_RBRACKET)


            self.state = 260
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while _la==one_for_allParser.TOK_COMMA:
                self.state = 250
                self.match(one_for_allParser.TOK_COMMA)
                self.state = 251
                self.match(one_for_allParser.TOK_ID)
                self.state = 256
                self._errHandler.sync(self)
                _la = self._input.LA(1)
                if _la==one_for_allParser.TOK_LBRACKET:
                    self.state = 252
                    self.match(one_for_allParser.TOK_LBRACKET)
                    self.state = 253
                    self.expressions()
                    self.state = 254
                    self.match(one_for_allParser.TOK_RBRACKET)


                self.state = 262
                self._errHandler.sync(self)
                _la = self._input.LA(1)

            self.state = 263
            self.match(one_for_allParser.TOK_SEMICOLON)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Variable_assignContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_VAR(self):
            return self.getToken(one_for_allParser.TOK_VAR, 0)

        def data_type(self):
            return self.getTypedRuleContext(one_for_allParser.Data_typeContext,0)


        def TOK_ID(self, i:int=None):
            if i is None:
                return self.getTokens(one_for_allParser.TOK_ID)
            else:
                return self.getToken(one_for_allParser.TOK_ID, i)

        def TOK_EQUAL(self, i:int=None):
            if i is None:
                return self.getTokens(one_for_allParser.TOK_EQUAL)
            else:
                return self.getToken(one_for_allParser.TOK_EQUAL, i)

        def expressions(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.ExpressionsContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.ExpressionsContext,i)


        def TOK_SEMICOLON(self):
            return self.getToken(one_for_allParser.TOK_SEMICOLON, 0)

        def TOK_LBRACKET(self, i:int=None):
            if i is None:
                return self.getTokens(one_for_allParser.TOK_LBRACKET)
            else:
                return self.getToken(one_for_allParser.TOK_LBRACKET, i)

        def TOK_RBRACKET(self, i:int=None):
            if i is None:
                return self.getTokens(one_for_allParser.TOK_RBRACKET)
            else:
                return self.getToken(one_for_allParser.TOK_RBRACKET, i)

        def TOK_COMMA(self, i:int=None):
            if i is None:
                return self.getTokens(one_for_allParser.TOK_COMMA)
            else:
                return self.getToken(one_for_allParser.TOK_COMMA, i)

        def getRuleIndex(self):
            return one_for_allParser.RULE_variable_assign

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterVariable_assign" ):
                listener.enterVariable_assign(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitVariable_assign" ):
                listener.exitVariable_assign(self)




    def variable_assign(self):

        localctx = one_for_allParser.Variable_assignContext(self, self._ctx, self.state)
        self.enterRule(localctx, 30, self.RULE_variable_assign)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 265
            self.match(one_for_allParser.TOK_VAR)
            self.state = 266
            self.data_type()
            self.state = 267
            self.match(one_for_allParser.TOK_ID)
            self.state = 272
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            if _la==one_for_allParser.TOK_LBRACKET:
                self.state = 268
                self.match(one_for_allParser.TOK_LBRACKET)
                self.state = 269
                self.expressions()
                self.state = 270
                self.match(one_for_allParser.TOK_RBRACKET)


            self.state = 274
            self.match(one_for_allParser.TOK_EQUAL)
            self.state = 275
            self.expressions()
            self.state = 288
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while _la==one_for_allParser.TOK_COMMA:
                self.state = 276
                self.match(one_for_allParser.TOK_COMMA)
                self.state = 277
                self.match(one_for_allParser.TOK_ID)
                self.state = 282
                self._errHandler.sync(self)
                _la = self._input.LA(1)
                if _la==one_for_allParser.TOK_LBRACKET:
                    self.state = 278
                    self.match(one_for_allParser.TOK_LBRACKET)
                    self.state = 279
                    self.expressions()
                    self.state = 280
                    self.match(one_for_allParser.TOK_RBRACKET)


                self.state = 284
                self.match(one_for_allParser.TOK_EQUAL)
                self.state = 285
                self.expressions()
                self.state = 290
                self._errHandler.sync(self)
                _la = self._input.LA(1)

            self.state = 291
            self.match(one_for_allParser.TOK_SEMICOLON)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Data_typeContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_INT(self):
            return self.getToken(one_for_allParser.TOK_INT, 0)

        def TOK_FLOAT(self):
            return self.getToken(one_for_allParser.TOK_FLOAT, 0)

        def TOK_STRING(self):
            return self.getToken(one_for_allParser.TOK_STRING, 0)

        def TOK_BOOLEAN(self):
            return self.getToken(one_for_allParser.TOK_BOOLEAN, 0)

        def TOK_ID(self):
            return self.getToken(one_for_allParser.TOK_ID, 0)

        def getRuleIndex(self):
            return one_for_allParser.RULE_data_type

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterData_type" ):
                listener.enterData_type(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitData_type" ):
                listener.exitData_type(self)




    def data_type(self):

        localctx = one_for_allParser.Data_typeContext(self, self._ctx, self.state)
        self.enterRule(localctx, 32, self.RULE_data_type)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 293
            _la = self._input.LA(1)
            if not((((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << one_for_allParser.TOK_INT) | (1 << one_for_allParser.TOK_FLOAT) | (1 << one_for_allParser.TOK_BOOLEAN) | (1 << one_for_allParser.TOK_STRING) | (1 << one_for_allParser.TOK_ID))) != 0)):
                self._errHandler.recoverInline(self)
            else:
                self._errHandler.reportMatch(self)
                self.consume()
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class MainContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_MAIN(self):
            return self.getToken(one_for_allParser.TOK_MAIN, 0)

        def block(self):
            return self.getTypedRuleContext(one_for_allParser.BlockContext,0)


        def getRuleIndex(self):
            return one_for_allParser.RULE_main

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterMain" ):
                listener.enterMain(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitMain" ):
                listener.exitMain(self)




    def main(self):

        localctx = one_for_allParser.MainContext(self, self._ctx, self.state)
        self.enterRule(localctx, 34, self.RULE_main)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 295
            self.match(one_for_allParser.TOK_MAIN)
            self.state = 296
            self.block()
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class BlockContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_LBRACE(self):
            return self.getToken(one_for_allParser.TOK_LBRACE, 0)

        def statute(self):
            return self.getTypedRuleContext(one_for_allParser.StatuteContext,0)


        def TOK_RBRACE(self):
            return self.getToken(one_for_allParser.TOK_RBRACE, 0)

        def getRuleIndex(self):
            return one_for_allParser.RULE_block

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterBlock" ):
                listener.enterBlock(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitBlock" ):
                listener.exitBlock(self)




    def block(self):

        localctx = one_for_allParser.BlockContext(self, self._ctx, self.state)
        self.enterRule(localctx, 36, self.RULE_block)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 298
            self.match(one_for_allParser.TOK_LBRACE)
            self.state = 299
            self.statute()
            self.state = 300
            self.match(one_for_allParser.TOK_RBRACE)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Return_exprContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_RETURN(self):
            return self.getToken(one_for_allParser.TOK_RETURN, 0)

        def expressions(self):
            return self.getTypedRuleContext(one_for_allParser.ExpressionsContext,0)


        def TOK_SEMICOLON(self):
            return self.getToken(one_for_allParser.TOK_SEMICOLON, 0)

        def getRuleIndex(self):
            return one_for_allParser.RULE_return_expr

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterReturn_expr" ):
                listener.enterReturn_expr(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitReturn_expr" ):
                listener.exitReturn_expr(self)




    def return_expr(self):

        localctx = one_for_allParser.Return_exprContext(self, self._ctx, self.state)
        self.enterRule(localctx, 38, self.RULE_return_expr)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 302
            self.match(one_for_allParser.TOK_RETURN)
            self.state = 303
            self.expressions()
            self.state = 304
            self.match(one_for_allParser.TOK_SEMICOLON)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class StatuteContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def assignment(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.AssignmentContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.AssignmentContext,i)


        def condition(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.ConditionContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.ConditionContext,i)


        def loop(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.LoopContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.LoopContext,i)


        def output(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.OutputContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.OutputContext,i)


        def input_(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.Input_Context)
            else:
                return self.getTypedRuleContext(one_for_allParser.Input_Context,i)


        def variables(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.VariablesContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.VariablesContext,i)


        def return_expr(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.Return_exprContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.Return_exprContext,i)


        def getRuleIndex(self):
            return one_for_allParser.RULE_statute

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterStatute" ):
                listener.enterStatute(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitStatute" ):
                listener.exitStatute(self)




    def statute(self):

        localctx = one_for_allParser.StatuteContext(self, self._ctx, self.state)
        self.enterRule(localctx, 40, self.RULE_statute)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 315
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << one_for_allParser.TOK_IF) | (1 << one_for_allParser.TOK_WHILE) | (1 << one_for_allParser.TOK_VAR) | (1 << one_for_allParser.TOK_READ) | (1 << one_for_allParser.TOK_WRITE) | (1 << one_for_allParser.TOK_RETURN) | (1 << one_for_allParser.TOK_ID))) != 0):
                self.state = 313
                self._errHandler.sync(self)
                token = self._input.LA(1)
                if token in [one_for_allParser.TOK_ID]:
                    self.state = 306
                    self.assignment()
                    pass
                elif token in [one_for_allParser.TOK_IF]:
                    self.state = 307
                    self.condition()
                    pass
                elif token in [one_for_allParser.TOK_WHILE]:
                    self.state = 308
                    self.loop()
                    pass
                elif token in [one_for_allParser.TOK_WRITE]:
                    self.state = 309
                    self.output()
                    pass
                elif token in [one_for_allParser.TOK_READ]:
                    self.state = 310
                    self.input_()
                    pass
                elif token in [one_for_allParser.TOK_VAR]:
                    self.state = 311
                    self.variables()
                    pass
                elif token in [one_for_allParser.TOK_RETURN]:
                    self.state = 312
                    self.return_expr()
                    pass
                else:
                    raise NoViableAltException(self)

                self.state = 317
                self._errHandler.sync(self)
                _la = self._input.LA(1)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class AssignmentContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def id_(self):
            return self.getTypedRuleContext(one_for_allParser.Id_Context,0)


        def TOK_EQUAL(self):
            return self.getToken(one_for_allParser.TOK_EQUAL, 0)

        def expressions(self):
            return self.getTypedRuleContext(one_for_allParser.ExpressionsContext,0)


        def TOK_SEMICOLON(self):
            return self.getToken(one_for_allParser.TOK_SEMICOLON, 0)

        def getRuleIndex(self):
            return one_for_allParser.RULE_assignment

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterAssignment" ):
                listener.enterAssignment(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitAssignment" ):
                listener.exitAssignment(self)




    def assignment(self):

        localctx = one_for_allParser.AssignmentContext(self, self._ctx, self.state)
        self.enterRule(localctx, 42, self.RULE_assignment)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 318
            self.id_()
            self.state = 319
            self.match(one_for_allParser.TOK_EQUAL)
            self.state = 320
            self.expressions()
            self.state = 321
            self.match(one_for_allParser.TOK_SEMICOLON)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class ConditionContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_IF(self):
            return self.getToken(one_for_allParser.TOK_IF, 0)

        def TOK_LPAREN(self):
            return self.getToken(one_for_allParser.TOK_LPAREN, 0)

        def expressions(self):
            return self.getTypedRuleContext(one_for_allParser.ExpressionsContext,0)


        def TOK_RPAREN(self):
            return self.getToken(one_for_allParser.TOK_RPAREN, 0)

        def neuro_if(self):
            return self.getTypedRuleContext(one_for_allParser.Neuro_ifContext,0)


        def block(self):
            return self.getTypedRuleContext(one_for_allParser.BlockContext,0)


        def condition_else(self):
            return self.getTypedRuleContext(one_for_allParser.Condition_elseContext,0)


        def neuro_endif(self):
            return self.getTypedRuleContext(one_for_allParser.Neuro_endifContext,0)


        def getRuleIndex(self):
            return one_for_allParser.RULE_condition

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterCondition" ):
                listener.enterCondition(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitCondition" ):
                listener.exitCondition(self)




    def condition(self):

        localctx = one_for_allParser.ConditionContext(self, self._ctx, self.state)
        self.enterRule(localctx, 44, self.RULE_condition)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 323
            self.match(one_for_allParser.TOK_IF)
            self.state = 324
            self.match(one_for_allParser.TOK_LPAREN)
            self.state = 325
            self.expressions()
            self.state = 326
            self.match(one_for_allParser.TOK_RPAREN)
            self.state = 327
            self.neuro_if()
            self.state = 328
            self.block()
            self.state = 329
            self.condition_else()
            self.state = 330
            self.neuro_endif()
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Neuro_ifContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser


        def getRuleIndex(self):
            return one_for_allParser.RULE_neuro_if

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterNeuro_if" ):
                listener.enterNeuro_if(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitNeuro_if" ):
                listener.exitNeuro_if(self)




    def neuro_if(self):

        localctx = one_for_allParser.Neuro_ifContext(self, self._ctx, self.state)
        self.enterRule(localctx, 46, self.RULE_neuro_if)
        try:
            self.enterOuterAlt(localctx, 1)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Neuro_endifContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser


        def getRuleIndex(self):
            return one_for_allParser.RULE_neuro_endif

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterNeuro_endif" ):
                listener.enterNeuro_endif(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitNeuro_endif" ):
                listener.exitNeuro_endif(self)




    def neuro_endif(self):

        localctx = one_for_allParser.Neuro_endifContext(self, self._ctx, self.state)
        self.enterRule(localctx, 48, self.RULE_neuro_endif)
        try:
            self.enterOuterAlt(localctx, 1)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class LoopContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_WHILE(self):
            return self.getToken(one_for_allParser.TOK_WHILE, 0)

        def neuro_while_begin(self):
            return self.getTypedRuleContext(one_for_allParser.Neuro_while_beginContext,0)


        def TOK_LPAREN(self):
            return self.getToken(one_for_allParser.TOK_LPAREN, 0)

        def expressions(self):
            return self.getTypedRuleContext(one_for_allParser.ExpressionsContext,0)


        def TOK_RPAREN(self):
            return self.getToken(one_for_allParser.TOK_RPAREN, 0)

        def neuro_while_expression(self):
            return self.getTypedRuleContext(one_for_allParser.Neuro_while_expressionContext,0)


        def block(self):
            return self.getTypedRuleContext(one_for_allParser.BlockContext,0)


        def neuro_while_end(self):
            return self.getTypedRuleContext(one_for_allParser.Neuro_while_endContext,0)


        def getRuleIndex(self):
            return one_for_allParser.RULE_loop

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterLoop" ):
                listener.enterLoop(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitLoop" ):
                listener.exitLoop(self)




    def loop(self):

        localctx = one_for_allParser.LoopContext(self, self._ctx, self.state)
        self.enterRule(localctx, 50, self.RULE_loop)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 336
            self.match(one_for_allParser.TOK_WHILE)
            self.state = 337
            self.neuro_while_begin()
            self.state = 338
            self.match(one_for_allParser.TOK_LPAREN)
            self.state = 339
            self.expressions()
            self.state = 340
            self.match(one_for_allParser.TOK_RPAREN)
            self.state = 341
            self.neuro_while_expression()
            self.state = 342
            self.block()
            self.state = 343
            self.neuro_while_end()
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Neuro_while_beginContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser


        def getRuleIndex(self):
            return one_for_allParser.RULE_neuro_while_begin

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterNeuro_while_begin" ):
                listener.enterNeuro_while_begin(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitNeuro_while_begin" ):
                listener.exitNeuro_while_begin(self)




    def neuro_while_begin(self):

        localctx = one_for_allParser.Neuro_while_beginContext(self, self._ctx, self.state)
        self.enterRule(localctx, 52, self.RULE_neuro_while_begin)
        try:
            self.enterOuterAlt(localctx, 1)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Neuro_while_expressionContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser


        def getRuleIndex(self):
            return one_for_allParser.RULE_neuro_while_expression

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterNeuro_while_expression" ):
                listener.enterNeuro_while_expression(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitNeuro_while_expression" ):
                listener.exitNeuro_while_expression(self)




    def neuro_while_expression(self):

        localctx = one_for_allParser.Neuro_while_expressionContext(self, self._ctx, self.state)
        self.enterRule(localctx, 54, self.RULE_neuro_while_expression)
        try:
            self.enterOuterAlt(localctx, 1)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Neuro_while_endContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser


        def getRuleIndex(self):
            return one_for_allParser.RULE_neuro_while_end

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterNeuro_while_end" ):
                listener.enterNeuro_while_end(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitNeuro_while_end" ):
                listener.exitNeuro_while_end(self)




    def neuro_while_end(self):

        localctx = one_for_allParser.Neuro_while_endContext(self, self._ctx, self.state)
        self.enterRule(localctx, 56, self.RULE_neuro_while_end)
        try:
            self.enterOuterAlt(localctx, 1)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Input_Context(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_READ(self):
            return self.getToken(one_for_allParser.TOK_READ, 0)

        def TOK_LPAREN(self):
            return self.getToken(one_for_allParser.TOK_LPAREN, 0)

        def expressions(self):
            return self.getTypedRuleContext(one_for_allParser.ExpressionsContext,0)


        def TOK_COMMA(self):
            return self.getToken(one_for_allParser.TOK_COMMA, 0)

        def TOK_ID(self):
            return self.getToken(one_for_allParser.TOK_ID, 0)

        def TOK_RPAREN(self):
            return self.getToken(one_for_allParser.TOK_RPAREN, 0)

        def TOK_SEMICOLON(self):
            return self.getToken(one_for_allParser.TOK_SEMICOLON, 0)

        def getRuleIndex(self):
            return one_for_allParser.RULE_input_

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterInput_" ):
                listener.enterInput_(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitInput_" ):
                listener.exitInput_(self)




    def input_(self):

        localctx = one_for_allParser.Input_Context(self, self._ctx, self.state)
        self.enterRule(localctx, 58, self.RULE_input_)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 351
            self.match(one_for_allParser.TOK_READ)
            self.state = 352
            self.match(one_for_allParser.TOK_LPAREN)
            self.state = 353
            self.expressions()
            self.state = 354
            self.match(one_for_allParser.TOK_COMMA)
            self.state = 355
            self.match(one_for_allParser.TOK_ID)
            self.state = 356
            self.match(one_for_allParser.TOK_RPAREN)
            self.state = 357
            self.match(one_for_allParser.TOK_SEMICOLON)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class OutputContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_WRITE(self):
            return self.getToken(one_for_allParser.TOK_WRITE, 0)

        def TOK_LPAREN(self):
            return self.getToken(one_for_allParser.TOK_LPAREN, 0)

        def expressions(self):
            return self.getTypedRuleContext(one_for_allParser.ExpressionsContext,0)


        def TOK_RPAREN(self):
            return self.getToken(one_for_allParser.TOK_RPAREN, 0)

        def TOK_SEMICOLON(self):
            return self.getToken(one_for_allParser.TOK_SEMICOLON, 0)

        def getRuleIndex(self):
            return one_for_allParser.RULE_output

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterOutput" ):
                listener.enterOutput(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitOutput" ):
                listener.exitOutput(self)




    def output(self):

        localctx = one_for_allParser.OutputContext(self, self._ctx, self.state)
        self.enterRule(localctx, 60, self.RULE_output)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 359
            self.match(one_for_allParser.TOK_WRITE)
            self.state = 360
            self.match(one_for_allParser.TOK_LPAREN)
            self.state = 361
            self.expressions()
            self.state = 362
            self.match(one_for_allParser.TOK_RPAREN)
            self.state = 363
            self.match(one_for_allParser.TOK_SEMICOLON)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Condition_elseContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def neuro_else(self):
            return self.getTypedRuleContext(one_for_allParser.Neuro_elseContext,0)


        def TOK_ELSE(self):
            return self.getToken(one_for_allParser.TOK_ELSE, 0)

        def block(self):
            return self.getTypedRuleContext(one_for_allParser.BlockContext,0)


        def getRuleIndex(self):
            return one_for_allParser.RULE_condition_else

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterCondition_else" ):
                listener.enterCondition_else(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitCondition_else" ):
                listener.exitCondition_else(self)




    def condition_else(self):

        localctx = one_for_allParser.Condition_elseContext(self, self._ctx, self.state)
        self.enterRule(localctx, 62, self.RULE_condition_else)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 369
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            if _la==one_for_allParser.TOK_ELSE:
                self.state = 365
                self.neuro_else()
                self.state = 366
                self.match(one_for_allParser.TOK_ELSE)
                self.state = 367
                self.block()


        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Neuro_elseContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser


        def getRuleIndex(self):
            return one_for_allParser.RULE_neuro_else

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterNeuro_else" ):
                listener.enterNeuro_else(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitNeuro_else" ):
                listener.exitNeuro_else(self)




    def neuro_else(self):

        localctx = one_for_allParser.Neuro_elseContext(self, self._ctx, self.state)
        self.enterRule(localctx, 64, self.RULE_neuro_else)
        try:
            self.enterOuterAlt(localctx, 1)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class ExpressionsContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def expression_definition(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.Expression_definitionContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.Expression_definitionContext,i)


        def getRuleIndex(self):
            return one_for_allParser.RULE_expressions

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterExpressions" ):
                listener.enterExpressions(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitExpressions" ):
                listener.exitExpressions(self)




    def expressions(self):

        localctx = one_for_allParser.ExpressionsContext(self, self._ctx, self.state)
        self.enterRule(localctx, 66, self.RULE_expressions)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 374 
            self._errHandler.sync(self)
            _alt = 1
            while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                if _alt == 1:
                    self.state = 373
                    self.expression_definition()

                else:
                    raise NoViableAltException(self)
                self.state = 376 
                self._errHandler.sync(self)
                _alt = self._interp.adaptivePredict(self._input,27,self._ctx)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Expression_definitionContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def relational_exprs(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.Relational_exprsContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.Relational_exprsContext,i)


        def neuro_expression(self):
            return self.getTypedRuleContext(one_for_allParser.Neuro_expressionContext,0)


        def token_and(self):
            return self.getTypedRuleContext(one_for_allParser.Token_andContext,0)


        def token_or(self):
            return self.getTypedRuleContext(one_for_allParser.Token_orContext,0)


        def getRuleIndex(self):
            return one_for_allParser.RULE_expression_definition

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterExpression_definition" ):
                listener.enterExpression_definition(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitExpression_definition" ):
                listener.exitExpression_definition(self)




    def expression_definition(self):

        localctx = one_for_allParser.Expression_definitionContext(self, self._ctx, self.state)
        self.enterRule(localctx, 68, self.RULE_expression_definition)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 378
            self.relational_exprs()
            self.state = 386
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            if _la==one_for_allParser.TOK_AND or _la==one_for_allParser.TOK_OR:
                self.state = 381
                self._errHandler.sync(self)
                token = self._input.LA(1)
                if token in [one_for_allParser.TOK_AND]:
                    self.state = 379
                    self.token_and()
                    pass
                elif token in [one_for_allParser.TOK_OR]:
                    self.state = 380
                    self.token_or()
                    pass
                else:
                    raise NoViableAltException(self)

                self.state = 383
                self.relational_exprs()
                self.state = 384
                self.neuro_expression()


        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Neuro_expressionContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser


        def getRuleIndex(self):
            return one_for_allParser.RULE_neuro_expression

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterNeuro_expression" ):
                listener.enterNeuro_expression(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitNeuro_expression" ):
                listener.exitNeuro_expression(self)




    def neuro_expression(self):

        localctx = one_for_allParser.Neuro_expressionContext(self, self._ctx, self.state)
        self.enterRule(localctx, 70, self.RULE_neuro_expression)
        try:
            self.enterOuterAlt(localctx, 1)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Token_andContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_AND(self):
            return self.getToken(one_for_allParser.TOK_AND, 0)

        def getRuleIndex(self):
            return one_for_allParser.RULE_token_and

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterToken_and" ):
                listener.enterToken_and(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitToken_and" ):
                listener.exitToken_and(self)




    def token_and(self):

        localctx = one_for_allParser.Token_andContext(self, self._ctx, self.state)
        self.enterRule(localctx, 72, self.RULE_token_and)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 390
            self.match(one_for_allParser.TOK_AND)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Token_orContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_OR(self):
            return self.getToken(one_for_allParser.TOK_OR, 0)

        def getRuleIndex(self):
            return one_for_allParser.RULE_token_or

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterToken_or" ):
                listener.enterToken_or(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitToken_or" ):
                listener.exitToken_or(self)




    def token_or(self):

        localctx = one_for_allParser.Token_orContext(self, self._ctx, self.state)
        self.enterRule(localctx, 74, self.RULE_token_or)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 392
            self.match(one_for_allParser.TOK_OR)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Relational_exprsContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def relational_expr_definition(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.Relational_expr_definitionContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.Relational_expr_definitionContext,i)


        def getRuleIndex(self):
            return one_for_allParser.RULE_relational_exprs

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterRelational_exprs" ):
                listener.enterRelational_exprs(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitRelational_exprs" ):
                listener.exitRelational_exprs(self)




    def relational_exprs(self):

        localctx = one_for_allParser.Relational_exprsContext(self, self._ctx, self.state)
        self.enterRule(localctx, 76, self.RULE_relational_exprs)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 395 
            self._errHandler.sync(self)
            _alt = 1
            while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                if _alt == 1:
                    self.state = 394
                    self.relational_expr_definition()

                else:
                    raise NoViableAltException(self)
                self.state = 397 
                self._errHandler.sync(self)
                _alt = self._interp.adaptivePredict(self._input,30,self._ctx)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Relational_expr_definitionContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def sumMinus_exprs(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.SumMinus_exprsContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.SumMinus_exprsContext,i)


        def neuro_relational(self):
            return self.getTypedRuleContext(one_for_allParser.Neuro_relationalContext,0)


        def token_same(self):
            return self.getTypedRuleContext(one_for_allParser.Token_sameContext,0)


        def token_different(self):
            return self.getTypedRuleContext(one_for_allParser.Token_differentContext,0)


        def token_greater(self):
            return self.getTypedRuleContext(one_for_allParser.Token_greaterContext,0)


        def token_greater_eq(self):
            return self.getTypedRuleContext(one_for_allParser.Token_greater_eqContext,0)


        def token_less(self):
            return self.getTypedRuleContext(one_for_allParser.Token_lessContext,0)


        def token_less_eq(self):
            return self.getTypedRuleContext(one_for_allParser.Token_less_eqContext,0)


        def getRuleIndex(self):
            return one_for_allParser.RULE_relational_expr_definition

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterRelational_expr_definition" ):
                listener.enterRelational_expr_definition(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitRelational_expr_definition" ):
                listener.exitRelational_expr_definition(self)




    def relational_expr_definition(self):

        localctx = one_for_allParser.Relational_expr_definitionContext(self, self._ctx, self.state)
        self.enterRule(localctx, 78, self.RULE_relational_expr_definition)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 399
            self.sumMinus_exprs()
            self.state = 411
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            if (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << one_for_allParser.TOK_DIFFERENT) | (1 << one_for_allParser.TOK_GREATER) | (1 << one_for_allParser.TOK_LESS) | (1 << one_for_allParser.TOK_GREATER_EQ) | (1 << one_for_allParser.TOK_LESS_EQ) | (1 << one_for_allParser.TOK_SAME))) != 0):
                self.state = 406
                self._errHandler.sync(self)
                token = self._input.LA(1)
                if token in [one_for_allParser.TOK_SAME]:
                    self.state = 400
                    self.token_same()
                    pass
                elif token in [one_for_allParser.TOK_DIFFERENT]:
                    self.state = 401
                    self.token_different()
                    pass
                elif token in [one_for_allParser.TOK_GREATER]:
                    self.state = 402
                    self.token_greater()
                    pass
                elif token in [one_for_allParser.TOK_GREATER_EQ]:
                    self.state = 403
                    self.token_greater_eq()
                    pass
                elif token in [one_for_allParser.TOK_LESS]:
                    self.state = 404
                    self.token_less()
                    pass
                elif token in [one_for_allParser.TOK_LESS_EQ]:
                    self.state = 405
                    self.token_less_eq()
                    pass
                else:
                    raise NoViableAltException(self)

                self.state = 408
                self.sumMinus_exprs()
                self.state = 409
                self.neuro_relational()


        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Neuro_relationalContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser


        def getRuleIndex(self):
            return one_for_allParser.RULE_neuro_relational

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterNeuro_relational" ):
                listener.enterNeuro_relational(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitNeuro_relational" ):
                listener.exitNeuro_relational(self)




    def neuro_relational(self):

        localctx = one_for_allParser.Neuro_relationalContext(self, self._ctx, self.state)
        self.enterRule(localctx, 80, self.RULE_neuro_relational)
        try:
            self.enterOuterAlt(localctx, 1)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Token_sameContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_SAME(self):
            return self.getToken(one_for_allParser.TOK_SAME, 0)

        def getRuleIndex(self):
            return one_for_allParser.RULE_token_same

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterToken_same" ):
                listener.enterToken_same(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitToken_same" ):
                listener.exitToken_same(self)




    def token_same(self):

        localctx = one_for_allParser.Token_sameContext(self, self._ctx, self.state)
        self.enterRule(localctx, 82, self.RULE_token_same)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 415
            self.match(one_for_allParser.TOK_SAME)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Token_differentContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_DIFFERENT(self):
            return self.getToken(one_for_allParser.TOK_DIFFERENT, 0)

        def getRuleIndex(self):
            return one_for_allParser.RULE_token_different

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterToken_different" ):
                listener.enterToken_different(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitToken_different" ):
                listener.exitToken_different(self)




    def token_different(self):

        localctx = one_for_allParser.Token_differentContext(self, self._ctx, self.state)
        self.enterRule(localctx, 84, self.RULE_token_different)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 417
            self.match(one_for_allParser.TOK_DIFFERENT)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Token_greaterContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_GREATER(self):
            return self.getToken(one_for_allParser.TOK_GREATER, 0)

        def getRuleIndex(self):
            return one_for_allParser.RULE_token_greater

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterToken_greater" ):
                listener.enterToken_greater(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitToken_greater" ):
                listener.exitToken_greater(self)




    def token_greater(self):

        localctx = one_for_allParser.Token_greaterContext(self, self._ctx, self.state)
        self.enterRule(localctx, 86, self.RULE_token_greater)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 419
            self.match(one_for_allParser.TOK_GREATER)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Token_greater_eqContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_GREATER_EQ(self):
            return self.getToken(one_for_allParser.TOK_GREATER_EQ, 0)

        def getRuleIndex(self):
            return one_for_allParser.RULE_token_greater_eq

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterToken_greater_eq" ):
                listener.enterToken_greater_eq(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitToken_greater_eq" ):
                listener.exitToken_greater_eq(self)




    def token_greater_eq(self):

        localctx = one_for_allParser.Token_greater_eqContext(self, self._ctx, self.state)
        self.enterRule(localctx, 88, self.RULE_token_greater_eq)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 421
            self.match(one_for_allParser.TOK_GREATER_EQ)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Token_lessContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_LESS(self):
            return self.getToken(one_for_allParser.TOK_LESS, 0)

        def getRuleIndex(self):
            return one_for_allParser.RULE_token_less

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterToken_less" ):
                listener.enterToken_less(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitToken_less" ):
                listener.exitToken_less(self)




    def token_less(self):

        localctx = one_for_allParser.Token_lessContext(self, self._ctx, self.state)
        self.enterRule(localctx, 90, self.RULE_token_less)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 423
            self.match(one_for_allParser.TOK_LESS)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Token_less_eqContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_LESS_EQ(self):
            return self.getToken(one_for_allParser.TOK_LESS_EQ, 0)

        def getRuleIndex(self):
            return one_for_allParser.RULE_token_less_eq

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterToken_less_eq" ):
                listener.enterToken_less_eq(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitToken_less_eq" ):
                listener.exitToken_less_eq(self)




    def token_less_eq(self):

        localctx = one_for_allParser.Token_less_eqContext(self, self._ctx, self.state)
        self.enterRule(localctx, 92, self.RULE_token_less_eq)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 425
            self.match(one_for_allParser.TOK_LESS_EQ)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class SumMinus_exprsContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def sumMinus_expr_definition(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.SumMinus_expr_definitionContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.SumMinus_expr_definitionContext,i)


        def getRuleIndex(self):
            return one_for_allParser.RULE_sumMinus_exprs

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterSumMinus_exprs" ):
                listener.enterSumMinus_exprs(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitSumMinus_exprs" ):
                listener.exitSumMinus_exprs(self)




    def sumMinus_exprs(self):

        localctx = one_for_allParser.SumMinus_exprsContext(self, self._ctx, self.state)
        self.enterRule(localctx, 94, self.RULE_sumMinus_exprs)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 428 
            self._errHandler.sync(self)
            _alt = 1
            while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                if _alt == 1:
                    self.state = 427
                    self.sumMinus_expr_definition()

                else:
                    raise NoViableAltException(self)
                self.state = 430 
                self._errHandler.sync(self)
                _alt = self._interp.adaptivePredict(self._input,33,self._ctx)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class SumMinus_expr_definitionContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def multiDiv_exprs(self):
            return self.getTypedRuleContext(one_for_allParser.MultiDiv_exprsContext,0)


        def neuro_sumMinus(self):
            return self.getTypedRuleContext(one_for_allParser.Neuro_sumMinusContext,0)


        def token_plus(self):
            return self.getTypedRuleContext(one_for_allParser.Token_plusContext,0)


        def token_minus(self):
            return self.getTypedRuleContext(one_for_allParser.Token_minusContext,0)


        def getRuleIndex(self):
            return one_for_allParser.RULE_sumMinus_expr_definition

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterSumMinus_expr_definition" ):
                listener.enterSumMinus_expr_definition(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitSumMinus_expr_definition" ):
                listener.exitSumMinus_expr_definition(self)




    def sumMinus_expr_definition(self):

        localctx = one_for_allParser.SumMinus_expr_definitionContext(self, self._ctx, self.state)
        self.enterRule(localctx, 96, self.RULE_sumMinus_expr_definition)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 432
            self.multiDiv_exprs()
            self.state = 433
            self.neuro_sumMinus()
            self.state = 436
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [one_for_allParser.TOK_PLUS]:
                self.state = 434
                self.token_plus()
                pass
            elif token in [one_for_allParser.TOK_MINUS]:
                self.state = 435
                self.token_minus()
                pass
            elif token in [one_for_allParser.STRING, one_for_allParser.FLOAT, one_for_allParser.INT, one_for_allParser.BOOLEAN, one_for_allParser.TOK_AND, one_for_allParser.TOK_OR, one_for_allParser.TOK_LPAREN, one_for_allParser.TOK_RPAREN, one_for_allParser.TOK_RBRACKET, one_for_allParser.TOK_DIFFERENT, one_for_allParser.TOK_GREATER, one_for_allParser.TOK_LESS, one_for_allParser.TOK_GREATER_EQ, one_for_allParser.TOK_LESS_EQ, one_for_allParser.TOK_SAME, one_for_allParser.TOK_SEMICOLON, one_for_allParser.TOK_COMMA, one_for_allParser.TOK_ID]:
                pass
            else:
                pass
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Neuro_sumMinusContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser


        def getRuleIndex(self):
            return one_for_allParser.RULE_neuro_sumMinus

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterNeuro_sumMinus" ):
                listener.enterNeuro_sumMinus(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitNeuro_sumMinus" ):
                listener.exitNeuro_sumMinus(self)




    def neuro_sumMinus(self):

        localctx = one_for_allParser.Neuro_sumMinusContext(self, self._ctx, self.state)
        self.enterRule(localctx, 98, self.RULE_neuro_sumMinus)
        try:
            self.enterOuterAlt(localctx, 1)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Token_plusContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_PLUS(self):
            return self.getToken(one_for_allParser.TOK_PLUS, 0)

        def getRuleIndex(self):
            return one_for_allParser.RULE_token_plus

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterToken_plus" ):
                listener.enterToken_plus(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitToken_plus" ):
                listener.exitToken_plus(self)




    def token_plus(self):

        localctx = one_for_allParser.Token_plusContext(self, self._ctx, self.state)
        self.enterRule(localctx, 100, self.RULE_token_plus)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 440
            self.match(one_for_allParser.TOK_PLUS)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Token_minusContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_MINUS(self):
            return self.getToken(one_for_allParser.TOK_MINUS, 0)

        def getRuleIndex(self):
            return one_for_allParser.RULE_token_minus

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterToken_minus" ):
                listener.enterToken_minus(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitToken_minus" ):
                listener.exitToken_minus(self)




    def token_minus(self):

        localctx = one_for_allParser.Token_minusContext(self, self._ctx, self.state)
        self.enterRule(localctx, 102, self.RULE_token_minus)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 442
            self.match(one_for_allParser.TOK_MINUS)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class MultiDiv_exprsContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def multiDiv_expr_definition(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.MultiDiv_expr_definitionContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.MultiDiv_expr_definitionContext,i)


        def getRuleIndex(self):
            return one_for_allParser.RULE_multiDiv_exprs

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterMultiDiv_exprs" ):
                listener.enterMultiDiv_exprs(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitMultiDiv_exprs" ):
                listener.exitMultiDiv_exprs(self)




    def multiDiv_exprs(self):

        localctx = one_for_allParser.MultiDiv_exprsContext(self, self._ctx, self.state)
        self.enterRule(localctx, 104, self.RULE_multiDiv_exprs)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 445 
            self._errHandler.sync(self)
            _alt = 1
            while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                if _alt == 1:
                    self.state = 444
                    self.multiDiv_expr_definition()

                else:
                    raise NoViableAltException(self)
                self.state = 447 
                self._errHandler.sync(self)
                _alt = self._interp.adaptivePredict(self._input,35,self._ctx)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class MultiDiv_expr_definitionContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def factor(self):
            return self.getTypedRuleContext(one_for_allParser.FactorContext,0)


        def neuro_multiDiv(self):
            return self.getTypedRuleContext(one_for_allParser.Neuro_multiDivContext,0)


        def token_multiplication(self):
            return self.getTypedRuleContext(one_for_allParser.Token_multiplicationContext,0)


        def token_division(self):
            return self.getTypedRuleContext(one_for_allParser.Token_divisionContext,0)


        def getRuleIndex(self):
            return one_for_allParser.RULE_multiDiv_expr_definition

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterMultiDiv_expr_definition" ):
                listener.enterMultiDiv_expr_definition(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitMultiDiv_expr_definition" ):
                listener.exitMultiDiv_expr_definition(self)




    def multiDiv_expr_definition(self):

        localctx = one_for_allParser.MultiDiv_expr_definitionContext(self, self._ctx, self.state)
        self.enterRule(localctx, 106, self.RULE_multiDiv_expr_definition)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 449
            self.factor()
            self.state = 450
            self.neuro_multiDiv()
            self.state = 453
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [one_for_allParser.TOK_MULTIPLICATION]:
                self.state = 451
                self.token_multiplication()
                pass
            elif token in [one_for_allParser.TOK_DIVISION]:
                self.state = 452
                self.token_division()
                pass
            elif token in [one_for_allParser.STRING, one_for_allParser.FLOAT, one_for_allParser.INT, one_for_allParser.BOOLEAN, one_for_allParser.TOK_AND, one_for_allParser.TOK_OR, one_for_allParser.TOK_LPAREN, one_for_allParser.TOK_RPAREN, one_for_allParser.TOK_RBRACKET, one_for_allParser.TOK_PLUS, one_for_allParser.TOK_MINUS, one_for_allParser.TOK_DIFFERENT, one_for_allParser.TOK_GREATER, one_for_allParser.TOK_LESS, one_for_allParser.TOK_GREATER_EQ, one_for_allParser.TOK_LESS_EQ, one_for_allParser.TOK_SAME, one_for_allParser.TOK_SEMICOLON, one_for_allParser.TOK_COMMA, one_for_allParser.TOK_ID]:
                pass
            else:
                pass
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Neuro_multiDivContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser


        def getRuleIndex(self):
            return one_for_allParser.RULE_neuro_multiDiv

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterNeuro_multiDiv" ):
                listener.enterNeuro_multiDiv(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitNeuro_multiDiv" ):
                listener.exitNeuro_multiDiv(self)




    def neuro_multiDiv(self):

        localctx = one_for_allParser.Neuro_multiDivContext(self, self._ctx, self.state)
        self.enterRule(localctx, 108, self.RULE_neuro_multiDiv)
        try:
            self.enterOuterAlt(localctx, 1)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Token_multiplicationContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_MULTIPLICATION(self):
            return self.getToken(one_for_allParser.TOK_MULTIPLICATION, 0)

        def getRuleIndex(self):
            return one_for_allParser.RULE_token_multiplication

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterToken_multiplication" ):
                listener.enterToken_multiplication(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitToken_multiplication" ):
                listener.exitToken_multiplication(self)




    def token_multiplication(self):

        localctx = one_for_allParser.Token_multiplicationContext(self, self._ctx, self.state)
        self.enterRule(localctx, 110, self.RULE_token_multiplication)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 457
            self.match(one_for_allParser.TOK_MULTIPLICATION)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Token_divisionContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_DIVISION(self):
            return self.getToken(one_for_allParser.TOK_DIVISION, 0)

        def getRuleIndex(self):
            return one_for_allParser.RULE_token_division

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterToken_division" ):
                listener.enterToken_division(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitToken_division" ):
                listener.exitToken_division(self)




    def token_division(self):

        localctx = one_for_allParser.Token_divisionContext(self, self._ctx, self.state)
        self.enterRule(localctx, 112, self.RULE_token_division)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 459
            self.match(one_for_allParser.TOK_DIVISION)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class FactorContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def token_lparen(self):
            return self.getTypedRuleContext(one_for_allParser.Token_lparenContext,0)


        def expressions(self):
            return self.getTypedRuleContext(one_for_allParser.ExpressionsContext,0)


        def token_rparen(self):
            return self.getTypedRuleContext(one_for_allParser.Token_rparenContext,0)


        def constant(self):
            return self.getTypedRuleContext(one_for_allParser.ConstantContext,0)


        def getRuleIndex(self):
            return one_for_allParser.RULE_factor

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterFactor" ):
                listener.enterFactor(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitFactor" ):
                listener.exitFactor(self)




    def factor(self):

        localctx = one_for_allParser.FactorContext(self, self._ctx, self.state)
        self.enterRule(localctx, 114, self.RULE_factor)
        try:
            self.state = 466
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [one_for_allParser.TOK_LPAREN]:
                self.enterOuterAlt(localctx, 1)
                self.state = 461
                self.token_lparen()
                self.state = 462
                self.expressions()
                self.state = 463
                self.token_rparen()
                pass
            elif token in [one_for_allParser.STRING, one_for_allParser.FLOAT, one_for_allParser.INT, one_for_allParser.BOOLEAN, one_for_allParser.TOK_ID]:
                self.enterOuterAlt(localctx, 2)
                self.state = 465
                self.constant()
                pass
            else:
                raise NoViableAltException(self)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Token_lparenContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_LPAREN(self):
            return self.getToken(one_for_allParser.TOK_LPAREN, 0)

        def getRuleIndex(self):
            return one_for_allParser.RULE_token_lparen

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterToken_lparen" ):
                listener.enterToken_lparen(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitToken_lparen" ):
                listener.exitToken_lparen(self)




    def token_lparen(self):

        localctx = one_for_allParser.Token_lparenContext(self, self._ctx, self.state)
        self.enterRule(localctx, 116, self.RULE_token_lparen)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 468
            self.match(one_for_allParser.TOK_LPAREN)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Token_rparenContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_RPAREN(self):
            return self.getToken(one_for_allParser.TOK_RPAREN, 0)

        def getRuleIndex(self):
            return one_for_allParser.RULE_token_rparen

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterToken_rparen" ):
                listener.enterToken_rparen(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitToken_rparen" ):
                listener.exitToken_rparen(self)




    def token_rparen(self):

        localctx = one_for_allParser.Token_rparenContext(self, self._ctx, self.state)
        self.enterRule(localctx, 118, self.RULE_token_rparen)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 470
            self.match(one_for_allParser.TOK_RPAREN)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class ConstantContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def FLOAT(self):
            return self.getToken(one_for_allParser.FLOAT, 0)

        def INT(self):
            return self.getToken(one_for_allParser.INT, 0)

        def STRING(self):
            return self.getToken(one_for_allParser.STRING, 0)

        def BOOLEAN(self):
            return self.getToken(one_for_allParser.BOOLEAN, 0)

        def id_(self):
            return self.getTypedRuleContext(one_for_allParser.Id_Context,0)


        def getRuleIndex(self):
            return one_for_allParser.RULE_constant

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterConstant" ):
                listener.enterConstant(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitConstant" ):
                listener.exitConstant(self)




    def constant(self):

        localctx = one_for_allParser.ConstantContext(self, self._ctx, self.state)
        self.enterRule(localctx, 120, self.RULE_constant)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 477
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [one_for_allParser.FLOAT]:
                self.state = 472
                self.match(one_for_allParser.FLOAT)
                pass
            elif token in [one_for_allParser.INT]:
                self.state = 473
                self.match(one_for_allParser.INT)
                pass
            elif token in [one_for_allParser.STRING]:
                self.state = 474
                self.match(one_for_allParser.STRING)
                pass
            elif token in [one_for_allParser.BOOLEAN]:
                self.state = 475
                self.match(one_for_allParser.BOOLEAN)
                pass
            elif token in [one_for_allParser.TOK_ID]:
                self.state = 476
                self.id_()
                pass
            else:
                raise NoViableAltException(self)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Id_Context(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def id_definition_(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.Id_definition_Context)
            else:
                return self.getTypedRuleContext(one_for_allParser.Id_definition_Context,i)


        def getRuleIndex(self):
            return one_for_allParser.RULE_id_

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterId_" ):
                listener.enterId_(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitId_" ):
                listener.exitId_(self)




    def id_(self):

        localctx = one_for_allParser.Id_Context(self, self._ctx, self.state)
        self.enterRule(localctx, 122, self.RULE_id_)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 480 
            self._errHandler.sync(self)
            _alt = 1
            while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                if _alt == 1:
                    self.state = 479
                    self.id_definition_()

                else:
                    raise NoViableAltException(self)
                self.state = 482 
                self._errHandler.sync(self)
                _alt = self._interp.adaptivePredict(self._input,39,self._ctx)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Id_definition_Context(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_ID(self):
            return self.getToken(one_for_allParser.TOK_ID, 0)

        def evaluate_class(self):
            return self.getTypedRuleContext(one_for_allParser.Evaluate_classContext,0)


        def evaluate_function(self):
            return self.getTypedRuleContext(one_for_allParser.Evaluate_functionContext,0)


        def evaluate_array(self):
            return self.getTypedRuleContext(one_for_allParser.Evaluate_arrayContext,0)


        def getRuleIndex(self):
            return one_for_allParser.RULE_id_definition_

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterId_definition_" ):
                listener.enterId_definition_(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitId_definition_" ):
                listener.exitId_definition_(self)




    def id_definition_(self):

        localctx = one_for_allParser.Id_definition_Context(self, self._ctx, self.state)
        self.enterRule(localctx, 124, self.RULE_id_definition_)
        try:
            self.state = 488
            self._errHandler.sync(self)
            la_ = self._interp.adaptivePredict(self._input,40,self._ctx)
            if la_ == 1:
                self.enterOuterAlt(localctx, 1)
                self.state = 484
                self.match(one_for_allParser.TOK_ID)
                pass

            elif la_ == 2:
                self.enterOuterAlt(localctx, 2)
                self.state = 485
                self.evaluate_class()
                pass

            elif la_ == 3:
                self.enterOuterAlt(localctx, 3)
                self.state = 486
                self.evaluate_function()
                pass

            elif la_ == 4:
                self.enterOuterAlt(localctx, 4)
                self.state = 487
                self.evaluate_array()
                pass


        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Evaluate_classContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_ID(self, i:int=None):
            if i is None:
                return self.getTokens(one_for_allParser.TOK_ID)
            else:
                return self.getToken(one_for_allParser.TOK_ID, i)

        def TOK_DOT(self):
            return self.getToken(one_for_allParser.TOK_DOT, 0)

        def TOK_LPAREN(self):
            return self.getToken(one_for_allParser.TOK_LPAREN, 0)

        def expressions(self):
            return self.getTypedRuleContext(one_for_allParser.ExpressionsContext,0)


        def TOK_RPAREN(self):
            return self.getToken(one_for_allParser.TOK_RPAREN, 0)

        def getRuleIndex(self):
            return one_for_allParser.RULE_evaluate_class

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterEvaluate_class" ):
                listener.enterEvaluate_class(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitEvaluate_class" ):
                listener.exitEvaluate_class(self)




    def evaluate_class(self):

        localctx = one_for_allParser.Evaluate_classContext(self, self._ctx, self.state)
        self.enterRule(localctx, 126, self.RULE_evaluate_class)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 490
            self.match(one_for_allParser.TOK_ID)
            self.state = 491
            self.match(one_for_allParser.TOK_DOT)
            self.state = 492
            self.match(one_for_allParser.TOK_ID)
            self.state = 497
            self._errHandler.sync(self)
            la_ = self._interp.adaptivePredict(self._input,41,self._ctx)
            if la_ == 1:
                self.state = 493
                self.match(one_for_allParser.TOK_LPAREN)
                self.state = 494
                self.expressions()
                self.state = 495
                self.match(one_for_allParser.TOK_RPAREN)


        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Evaluate_functionContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_ID(self):
            return self.getToken(one_for_allParser.TOK_ID, 0)

        def TOK_LPAREN(self):
            return self.getToken(one_for_allParser.TOK_LPAREN, 0)

        def neuro_params(self):
            return self.getTypedRuleContext(one_for_allParser.Neuro_paramsContext,0)


        def TOK_RPAREN(self):
            return self.getToken(one_for_allParser.TOK_RPAREN, 0)

        def expressions(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.ExpressionsContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.ExpressionsContext,i)


        def TOK_COMMA(self, i:int=None):
            if i is None:
                return self.getTokens(one_for_allParser.TOK_COMMA)
            else:
                return self.getToken(one_for_allParser.TOK_COMMA, i)

        def getRuleIndex(self):
            return one_for_allParser.RULE_evaluate_function

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterEvaluate_function" ):
                listener.enterEvaluate_function(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitEvaluate_function" ):
                listener.exitEvaluate_function(self)




    def evaluate_function(self):

        localctx = one_for_allParser.Evaluate_functionContext(self, self._ctx, self.state)
        self.enterRule(localctx, 128, self.RULE_evaluate_function)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 499
            self.match(one_for_allParser.TOK_ID)
            self.state = 500
            self.match(one_for_allParser.TOK_LPAREN)
            self.state = 507
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << one_for_allParser.STRING) | (1 << one_for_allParser.FLOAT) | (1 << one_for_allParser.INT) | (1 << one_for_allParser.BOOLEAN) | (1 << one_for_allParser.TOK_LPAREN) | (1 << one_for_allParser.TOK_ID))) != 0):
                self.state = 501
                self.expressions()
                self.state = 503
                self._errHandler.sync(self)
                _la = self._input.LA(1)
                if _la==one_for_allParser.TOK_COMMA:
                    self.state = 502
                    self.match(one_for_allParser.TOK_COMMA)


                self.state = 509
                self._errHandler.sync(self)
                _la = self._input.LA(1)

            self.state = 510
            self.neuro_params()
            self.state = 511
            self.match(one_for_allParser.TOK_RPAREN)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Neuro_paramsContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser


        def getRuleIndex(self):
            return one_for_allParser.RULE_neuro_params

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterNeuro_params" ):
                listener.enterNeuro_params(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitNeuro_params" ):
                listener.exitNeuro_params(self)




    def neuro_params(self):

        localctx = one_for_allParser.Neuro_paramsContext(self, self._ctx, self.state)
        self.enterRule(localctx, 130, self.RULE_neuro_params)
        try:
            self.enterOuterAlt(localctx, 1)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Evaluate_arrayContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_ID(self):
            return self.getToken(one_for_allParser.TOK_ID, 0)

        def TOK_LBRACKET(self):
            return self.getToken(one_for_allParser.TOK_LBRACKET, 0)

        def expressions(self):
            return self.getTypedRuleContext(one_for_allParser.ExpressionsContext,0)


        def TOK_RBRACKET(self):
            return self.getToken(one_for_allParser.TOK_RBRACKET, 0)

        def getRuleIndex(self):
            return one_for_allParser.RULE_evaluate_array

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterEvaluate_array" ):
                listener.enterEvaluate_array(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitEvaluate_array" ):
                listener.exitEvaluate_array(self)




    def evaluate_array(self):

        localctx = one_for_allParser.Evaluate_arrayContext(self, self._ctx, self.state)
        self.enterRule(localctx, 132, self.RULE_evaluate_array)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 515
            self.match(one_for_allParser.TOK_ID)
            self.state = 516
            self.match(one_for_allParser.TOK_LBRACKET)
            self.state = 517
            self.expressions()
            self.state = 518
            self.match(one_for_allParser.TOK_RBRACKET)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx





