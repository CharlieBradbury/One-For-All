# Generated from one_for_all.g4 by ANTLR 4.7.1
# encoding: utf-8
from antlr4 import *
from io import StringIO
from typing.io import TextIO
import sys

def serializedATN():
    with StringIO() as buf:
        buf.write("\3\u608b\ua72a\u8133\ub9ed\u417c\u3be7\u7786\u5964\3\63")
        buf.write("\u0255\4\2\t\2\4\3\t\3\4\4\t\4\4\5\t\5\4\6\t\6\4\7\t\7")
        buf.write("\4\b\t\b\4\t\t\t\4\n\t\n\4\13\t\13\4\f\t\f\4\r\t\r\4\16")
        buf.write("\t\16\4\17\t\17\4\20\t\20\4\21\t\21\4\22\t\22\4\23\t\23")
        buf.write("\4\24\t\24\4\25\t\25\4\26\t\26\4\27\t\27\4\30\t\30\4\31")
        buf.write("\t\31\4\32\t\32\4\33\t\33\4\34\t\34\4\35\t\35\4\36\t\36")
        buf.write("\4\37\t\37\4 \t \4!\t!\4\"\t\"\4#\t#\4$\t$\4%\t%\4&\t")
        buf.write("&\4\'\t\'\4(\t(\4)\t)\4*\t*\4+\t+\4,\t,\4-\t-\4.\t.\4")
        buf.write("/\t/\4\60\t\60\4\61\t\61\4\62\t\62\4\63\t\63\4\64\t\64")
        buf.write("\4\65\t\65\4\66\t\66\4\67\t\67\48\t8\49\t9\4:\t:\4;\t")
        buf.write(";\4<\t<\4=\t=\4>\t>\4?\t?\4@\t@\4A\tA\4B\tB\4C\tC\4D\t")
        buf.write("D\4E\tE\4F\tF\4G\tG\4H\tH\4I\tI\4J\tJ\4K\tK\4L\tL\4M\t")
        buf.write("M\3\2\3\2\3\2\3\2\5\2\u009f\n\2\3\2\5\2\u00a2\n\2\3\2")
        buf.write("\3\2\5\2\u00a6\n\2\3\2\3\2\3\3\3\3\3\4\3\4\3\5\6\5\u00af")
        buf.write("\n\5\r\5\16\5\u00b0\3\6\3\6\3\6\5\6\u00b6\n\6\3\6\3\6")
        buf.write("\5\6\u00ba\n\6\3\6\5\6\u00bd\n\6\3\6\3\6\3\6\3\7\3\7\3")
        buf.write("\7\3\7\3\b\3\b\3\t\3\t\3\t\3\t\6\t\u00cc\n\t\r\t\16\t")
        buf.write("\u00cd\3\n\3\n\3\n\3\n\6\n\u00d4\n\n\r\n\16\n\u00d5\3")
        buf.write("\13\3\13\3\13\5\13\u00db\n\13\3\13\3\13\3\13\3\f\6\f\u00e1")
        buf.write("\n\f\r\f\16\f\u00e2\3\r\3\r\3\r\3\r\3\r\5\r\u00ea\n\r")
        buf.write("\3\r\3\r\3\r\3\16\3\16\3\16\3\16\3\16\3\16\3\16\3\16\5")
        buf.write("\16\u00f7\n\16\3\16\3\16\3\17\3\17\3\17\3\17\3\17\3\17")
        buf.write("\3\17\3\17\3\17\3\17\5\17\u0105\n\17\7\17\u0107\n\17\f")
        buf.write("\17\16\17\u010a\13\17\3\20\3\20\3\21\3\21\3\22\3\22\6")
        buf.write("\22\u0112\n\22\r\22\16\22\u0113\3\23\3\23\3\23\3\23\3")
        buf.write("\23\3\23\3\23\5\23\u011d\n\23\3\23\3\23\3\23\3\23\3\23")
        buf.write("\3\23\5\23\u0125\n\23\7\23\u0127\n\23\f\23\16\23\u012a")
        buf.write("\13\23\3\23\3\23\3\24\3\24\3\24\3\24\3\24\3\24\3\24\5")
        buf.write("\24\u0135\n\24\3\24\3\24\3\24\3\24\3\24\3\24\3\24\3\24")
        buf.write("\5\24\u013f\n\24\3\24\3\24\7\24\u0143\n\24\f\24\16\24")
        buf.write("\u0146\13\24\3\24\3\24\3\25\3\25\3\26\3\26\3\26\3\27\3")
        buf.write("\27\3\27\3\27\3\30\3\30\3\30\3\30\3\31\3\31\3\31\3\31")
        buf.write("\3\31\3\31\3\31\7\31\u015e\n\31\f\31\16\31\u0161\13\31")
        buf.write("\3\32\3\32\3\32\3\32\3\32\3\33\3\33\3\33\3\33\3\33\3\33")
        buf.write("\3\33\3\33\3\33\3\34\3\34\3\35\3\35\3\36\3\36\3\36\3\36")
        buf.write("\3\36\3\36\3\36\3\36\3\36\3\37\3\37\3 \3 \3!\3!\3\"\3")
        buf.write("\"\3\"\3\"\3\"\3\"\3\"\3\"\3#\3#\3#\3#\3#\5#\u0191\n#")
        buf.write("\3#\3#\3#\3#\3$\3$\3$\3$\6$\u019b\n$\r$\16$\u019c\3%\3")
        buf.write("%\3&\3&\3\'\3\'\3\'\3\'\5\'\u01a7\n\'\3(\3(\3)\6)\u01ac")
        buf.write("\n)\r)\16)\u01ad\3*\3*\3*\5*\u01b3\n*\3*\3*\3*\5*\u01b8")
        buf.write("\n*\3+\3+\3,\3,\3-\3-\3.\6.\u01c1\n.\r.\16.\u01c2\3/\3")
        buf.write("/\3/\3/\3/\3/\3/\5/\u01cc\n/\3/\3/\3/\5/\u01d1\n/\3\60")
        buf.write("\3\60\3\61\3\61\3\62\3\62\3\63\3\63\3\64\3\64\3\65\3\65")
        buf.write("\3\66\3\66\3\67\6\67\u01e2\n\67\r\67\16\67\u01e3\38\3")
        buf.write("8\38\38\58\u01ea\n8\39\39\3:\3:\3;\3;\3<\6<\u01f3\n<\r")
        buf.write("<\16<\u01f4\3=\3=\3=\3=\5=\u01fb\n=\3>\3>\3?\3?\3@\3@")
        buf.write("\3A\3A\3A\3A\3A\5A\u0208\nA\3B\3B\3C\3C\3D\3D\3D\3D\3")
        buf.write("D\5D\u0213\nD\3E\6E\u0216\nE\rE\16E\u0217\3F\3F\3F\3F")
        buf.write("\3F\5F\u021f\nF\3G\3G\3G\3G\3G\3G\3G\5G\u0228\nG\7G\u022a")
        buf.write("\nG\fG\16G\u022d\13G\3G\3G\3G\3G\3H\3H\3I\3I\3J\3J\3J")
        buf.write("\3J\3J\3J\3J\5J\u023e\nJ\3K\3K\3K\3K\5K\u0244\nK\7K\u0246")
        buf.write("\nK\fK\16K\u0249\13K\3K\3K\3K\3L\3L\3M\3M\3M\3M\3M\3M")
        buf.write("\2\2N\2\4\6\b\n\f\16\20\22\24\26\30\32\34\36 \"$&(*,.")
        buf.write("\60\62\64\668:<>@BDFHJLNPRTVXZ\\^`bdfhjlnprtvxz|~\u0080")
        buf.write("\u0082\u0084\u0086\u0088\u008a\u008c\u008e\u0090\u0092")
        buf.write("\u0094\u0096\u0098\2\3\4\2-\60\62\62\2\u024a\2\u009a\3")
        buf.write("\2\2\2\4\u00a9\3\2\2\2\6\u00ab\3\2\2\2\b\u00ae\3\2\2\2")
        buf.write("\n\u00b2\3\2\2\2\f\u00c1\3\2\2\2\16\u00c5\3\2\2\2\20\u00cb")
        buf.write("\3\2\2\2\22\u00d3\3\2\2\2\24\u00d7\3\2\2\2\26\u00e0\3")
        buf.write("\2\2\2\30\u00e4\3\2\2\2\32\u00ee\3\2\2\2\34\u0108\3\2")
        buf.write("\2\2\36\u010b\3\2\2\2 \u010d\3\2\2\2\"\u0111\3\2\2\2$")
        buf.write("\u0115\3\2\2\2&\u012d\3\2\2\2(\u0149\3\2\2\2*\u014b\3")
        buf.write("\2\2\2,\u014e\3\2\2\2.\u0152\3\2\2\2\60\u015f\3\2\2\2")
        buf.write("\62\u0162\3\2\2\2\64\u0167\3\2\2\2\66\u0170\3\2\2\28\u0172")
        buf.write("\3\2\2\2:\u0174\3\2\2\2<\u017d\3\2\2\2>\u017f\3\2\2\2")
        buf.write("@\u0181\3\2\2\2B\u0183\3\2\2\2D\u018b\3\2\2\2F\u019a\3")
        buf.write("\2\2\2H\u019e\3\2\2\2J\u01a0\3\2\2\2L\u01a6\3\2\2\2N\u01a8")
        buf.write("\3\2\2\2P\u01ab\3\2\2\2R\u01af\3\2\2\2T\u01b9\3\2\2\2")
        buf.write("V\u01bb\3\2\2\2X\u01bd\3\2\2\2Z\u01c0\3\2\2\2\\\u01c4")
        buf.write("\3\2\2\2^\u01d2\3\2\2\2`\u01d4\3\2\2\2b\u01d6\3\2\2\2")
        buf.write("d\u01d8\3\2\2\2f\u01da\3\2\2\2h\u01dc\3\2\2\2j\u01de\3")
        buf.write("\2\2\2l\u01e1\3\2\2\2n\u01e5\3\2\2\2p\u01eb\3\2\2\2r\u01ed")
        buf.write("\3\2\2\2t\u01ef\3\2\2\2v\u01f2\3\2\2\2x\u01f6\3\2\2\2")
        buf.write("z\u01fc\3\2\2\2|\u01fe\3\2\2\2~\u0200\3\2\2\2\u0080\u0207")
        buf.write("\3\2\2\2\u0082\u0209\3\2\2\2\u0084\u020b\3\2\2\2\u0086")
        buf.write("\u0212\3\2\2\2\u0088\u0215\3\2\2\2\u008a\u021e\3\2\2\2")
        buf.write("\u008c\u0220\3\2\2\2\u008e\u0232\3\2\2\2\u0090\u0234\3")
        buf.write("\2\2\2\u0092\u0236\3\2\2\2\u0094\u023f\3\2\2\2\u0096\u024d")
        buf.write("\3\2\2\2\u0098\u024f\3\2\2\2\u009a\u009b\7\17\2\2\u009b")
        buf.write("\u009c\7\62\2\2\u009c\u009e\7)\2\2\u009d\u009f\5\b\5\2")
        buf.write("\u009e\u009d\3\2\2\2\u009e\u009f\3\2\2\2\u009f\u00a1\3")
        buf.write("\2\2\2\u00a0\u00a2\5\"\22\2\u00a1\u00a0\3\2\2\2\u00a1")
        buf.write("\u00a2\3\2\2\2\u00a2\u00a3\3\2\2\2\u00a3\u00a5\5\4\3\2")
        buf.write("\u00a4\u00a6\5\26\f\2\u00a5\u00a4\3\2\2\2\u00a5\u00a6")
        buf.write("\3\2\2\2\u00a6\u00a7\3\2\2\2\u00a7\u00a8\5\6\4\2\u00a8")
        buf.write("\3\3\2\2\2\u00a9\u00aa\3\2\2\2\u00aa\5\3\2\2\2\u00ab\u00ac")
        buf.write("\5*\26\2\u00ac\7\3\2\2\2\u00ad\u00af\5\n\6\2\u00ae\u00ad")
        buf.write("\3\2\2\2\u00af\u00b0\3\2\2\2\u00b0\u00ae\3\2\2\2\u00b0")
        buf.write("\u00b1\3\2\2\2\u00b1\t\3\2\2\2\u00b2\u00b3\7\20\2\2\u00b3")
        buf.write("\u00b5\7\62\2\2\u00b4\u00b6\5\f\7\2\u00b5\u00b4\3\2\2")
        buf.write("\2\u00b5\u00b6\3\2\2\2\u00b6\u00b7\3\2\2\2\u00b7\u00b9")
        buf.write("\7\32\2\2\u00b8\u00ba\5\20\t\2\u00b9\u00b8\3\2\2\2\u00b9")
        buf.write("\u00ba\3\2\2\2\u00ba\u00bc\3\2\2\2\u00bb\u00bd\5\22\n")
        buf.write("\2\u00bc\u00bb\3\2\2\2\u00bc\u00bd\3\2\2\2\u00bd\u00be")
        buf.write("\3\2\2\2\u00be\u00bf\5\24\13\2\u00bf\u00c0\7\33\2\2\u00c0")
        buf.write("\13\3\2\2\2\u00c1\u00c2\7*\2\2\u00c2\u00c3\7\62\2\2\u00c3")
        buf.write("\u00c4\5\16\b\2\u00c4\r\3\2\2\2\u00c5\u00c6\3\2\2\2\u00c6")
        buf.write("\17\3\2\2\2\u00c7\u00c8\7\22\2\2\u00c8\u00cc\5\"\22\2")
        buf.write("\u00c9\u00ca\7\22\2\2\u00ca\u00cc\5\26\f\2\u00cb\u00c7")
        buf.write("\3\2\2\2\u00cb\u00c9\3\2\2\2\u00cc\u00cd\3\2\2\2\u00cd")
        buf.write("\u00cb\3\2\2\2\u00cd\u00ce\3\2\2\2\u00ce\21\3\2\2\2\u00cf")
        buf.write("\u00d0\7\21\2\2\u00d0\u00d4\5\"\22\2\u00d1\u00d2\7\21")
        buf.write("\2\2\u00d2\u00d4\5\26\f\2\u00d3\u00cf\3\2\2\2\u00d3\u00d1")
        buf.write("\3\2\2\2\u00d4\u00d5\3\2\2\2\u00d5\u00d3\3\2\2\2\u00d5")
        buf.write("\u00d6\3\2\2\2\u00d6\23\3\2\2\2\u00d7\u00d8\7\24\2\2\u00d8")
        buf.write("\u00da\7\30\2\2\u00d9\u00db\5\32\16\2\u00da\u00d9\3\2")
        buf.write("\2\2\u00da\u00db\3\2\2\2\u00db\u00dc\3\2\2\2\u00dc\u00dd")
        buf.write("\7\31\2\2\u00dd\u00de\5,\27\2\u00de\25\3\2\2\2\u00df\u00e1")
        buf.write("\5\30\r\2\u00e0\u00df\3\2\2\2\u00e1\u00e2\3\2\2\2\u00e2")
        buf.write("\u00e0\3\2\2\2\u00e2\u00e3\3\2\2\2\u00e3\27\3\2\2\2\u00e4")
        buf.write("\u00e5\7\26\2\2\u00e5\u00e6\5(\25\2\u00e6\u00e7\7\62\2")
        buf.write("\2\u00e7\u00e9\7\30\2\2\u00e8\u00ea\5\32\16\2\u00e9\u00e8")
        buf.write("\3\2\2\2\u00e9\u00ea\3\2\2\2\u00ea\u00eb\3\2\2\2\u00eb")
        buf.write("\u00ec\7\31\2\2\u00ec\u00ed\5,\27\2\u00ed\31\3\2\2\2\u00ee")
        buf.write("\u00ef\7\16\2\2\u00ef\u00f0\5(\25\2\u00f0\u00f6\7\62\2")
        buf.write("\2\u00f1\u00f2\7\34\2\2\u00f2\u00f3\5P)\2\u00f3\u00f4")
        buf.write("\5\36\20\2\u00f4\u00f5\7\35\2\2\u00f5\u00f7\3\2\2\2\u00f6")
        buf.write("\u00f1\3\2\2\2\u00f6\u00f7\3\2\2\2\u00f7\u00f8\3\2\2\2")
        buf.write("\u00f8\u00f9\5\34\17\2\u00f9\33\3\2\2\2\u00fa\u00fb\7")
        buf.write(",\2\2\u00fb\u00fc\7\16\2\2\u00fc\u00fd\5 \21\2\u00fd\u00fe")
        buf.write("\5(\25\2\u00fe\u0104\7\62\2\2\u00ff\u0100\7\34\2\2\u0100")
        buf.write("\u0101\5P)\2\u0101\u0102\5\36\20\2\u0102\u0103\7\35\2")
        buf.write("\2\u0103\u0105\3\2\2\2\u0104\u00ff\3\2\2\2\u0104\u0105")
        buf.write("\3\2\2\2\u0105\u0107\3\2\2\2\u0106\u00fa\3\2\2\2\u0107")
        buf.write("\u010a\3\2\2\2\u0108\u0106\3\2\2\2\u0108\u0109\3\2\2\2")
        buf.write("\u0109\35\3\2\2\2\u010a\u0108\3\2\2\2\u010b\u010c\3\2")
        buf.write("\2\2\u010c\37\3\2\2\2\u010d\u010e\3\2\2\2\u010e!\3\2\2")
        buf.write("\2\u010f\u0112\5$\23\2\u0110\u0112\5&\24\2\u0111\u010f")
        buf.write("\3\2\2\2\u0111\u0110\3\2\2\2\u0112\u0113\3\2\2\2\u0113")
        buf.write("\u0111\3\2\2\2\u0113\u0114\3\2\2\2\u0114#\3\2\2\2\u0115")
        buf.write("\u0116\7\16\2\2\u0116\u0117\5(\25\2\u0117\u011c\7\62\2")
        buf.write("\2\u0118\u0119\7\34\2\2\u0119\u011a\5P)\2\u011a\u011b")
        buf.write("\7\35\2\2\u011b\u011d\3\2\2\2\u011c\u0118\3\2\2\2\u011c")
        buf.write("\u011d\3\2\2\2\u011d\u0128\3\2\2\2\u011e\u011f\7,\2\2")
        buf.write("\u011f\u0124\7\62\2\2\u0120\u0121\7\34\2\2\u0121\u0122")
        buf.write("\5P)\2\u0122\u0123\7\35\2\2\u0123\u0125\3\2\2\2\u0124")
        buf.write("\u0120\3\2\2\2\u0124\u0125\3\2\2\2\u0125\u0127\3\2\2\2")
        buf.write("\u0126\u011e\3\2\2\2\u0127\u012a\3\2\2\2\u0128\u0126\3")
        buf.write("\2\2\2\u0128\u0129\3\2\2\2\u0129\u012b\3\2\2\2\u012a\u0128")
        buf.write("\3\2\2\2\u012b\u012c\7)\2\2\u012c%\3\2\2\2\u012d\u012e")
        buf.write("\7\16\2\2\u012e\u012f\5(\25\2\u012f\u0134\7\62\2\2\u0130")
        buf.write("\u0131\7\34\2\2\u0131\u0132\5P)\2\u0132\u0133\7\35\2\2")
        buf.write("\u0133\u0135\3\2\2\2\u0134\u0130\3\2\2\2\u0134\u0135\3")
        buf.write("\2\2\2\u0135\u0136\3\2\2\2\u0136\u0137\7\"\2\2\u0137\u0144")
        buf.write("\5P)\2\u0138\u0139\7,\2\2\u0139\u013e\7\62\2\2\u013a\u013b")
        buf.write("\7\34\2\2\u013b\u013c\5P)\2\u013c\u013d\7\35\2\2\u013d")
        buf.write("\u013f\3\2\2\2\u013e\u013a\3\2\2\2\u013e\u013f\3\2\2\2")
        buf.write("\u013f\u0140\3\2\2\2\u0140\u0141\7\"\2\2\u0141\u0143\5")
        buf.write("P)\2\u0142\u0138\3\2\2\2\u0143\u0146\3\2\2\2\u0144\u0142")
        buf.write("\3\2\2\2\u0144\u0145\3\2\2\2\u0145\u0147\3\2\2\2\u0146")
        buf.write("\u0144\3\2\2\2\u0147\u0148\7)\2\2\u0148\'\3\2\2\2\u0149")
        buf.write("\u014a\t\2\2\2\u014a)\3\2\2\2\u014b\u014c\7\23\2\2\u014c")
        buf.write("\u014d\5,\27\2\u014d+\3\2\2\2\u014e\u014f\7\32\2\2\u014f")
        buf.write("\u0150\5\60\31\2\u0150\u0151\7\33\2\2\u0151-\3\2\2\2\u0152")
        buf.write("\u0153\7\61\2\2\u0153\u0154\5P)\2\u0154\u0155\7)\2\2\u0155")
        buf.write("/\3\2\2\2\u0156\u015e\5\62\32\2\u0157\u015e\5\64\33\2")
        buf.write("\u0158\u015e\5:\36\2\u0159\u015e\5D#\2\u015a\u015e\5B")
        buf.write("\"\2\u015b\u015e\5\"\22\2\u015c\u015e\5.\30\2\u015d\u0156")
        buf.write("\3\2\2\2\u015d\u0157\3\2\2\2\u015d\u0158\3\2\2\2\u015d")
        buf.write("\u0159\3\2\2\2\u015d\u015a\3\2\2\2\u015d\u015b\3\2\2\2")
        buf.write("\u015d\u015c\3\2\2\2\u015e\u0161\3\2\2\2\u015f\u015d\3")
        buf.write("\2\2\2\u015f\u0160\3\2\2\2\u0160\61\3\2\2\2\u0161\u015f")
        buf.write("\3\2\2\2\u0162\u0163\5\u0088E\2\u0163\u0164\7\"\2\2\u0164")
        buf.write("\u0165\5P)\2\u0165\u0166\7)\2\2\u0166\63\3\2\2\2\u0167")
        buf.write("\u0168\7\13\2\2\u0168\u0169\7\30\2\2\u0169\u016a\5P)\2")
        buf.write("\u016a\u016b\7\31\2\2\u016b\u016c\5\66\34\2\u016c\u016d")
        buf.write("\5,\27\2\u016d\u016e\5L\'\2\u016e\u016f\58\35\2\u016f")
        buf.write("\65\3\2\2\2\u0170\u0171\3\2\2\2\u0171\67\3\2\2\2\u0172")
        buf.write("\u0173\3\2\2\2\u01739\3\2\2\2\u0174\u0175\7\r\2\2\u0175")
        buf.write("\u0176\5<\37\2\u0176\u0177\7\30\2\2\u0177\u0178\5P)\2")
        buf.write("\u0178\u0179\7\31\2\2\u0179\u017a\5> \2\u017a\u017b\5")
        buf.write(",\27\2\u017b\u017c\5@!\2\u017c;\3\2\2\2\u017d\u017e\3")
        buf.write("\2\2\2\u017e=\3\2\2\2\u017f\u0180\3\2\2\2\u0180?\3\2\2")
        buf.write("\2\u0181\u0182\3\2\2\2\u0182A\3\2\2\2\u0183\u0184\7\25")
        buf.write("\2\2\u0184\u0185\7\30\2\2\u0185\u0186\5P)\2\u0186\u0187")
        buf.write("\7,\2\2\u0187\u0188\7\62\2\2\u0188\u0189\7\31\2\2\u0189")
        buf.write("\u018a\7)\2\2\u018aC\3\2\2\2\u018b\u018c\7\27\2\2\u018c")
        buf.write("\u018d\7\30\2\2\u018d\u018e\5P)\2\u018e\u0190\5H%\2\u018f")
        buf.write("\u0191\5F$\2\u0190\u018f\3\2\2\2\u0190\u0191\3\2\2\2\u0191")
        buf.write("\u0192\3\2\2\2\u0192\u0193\5J&\2\u0193\u0194\7\31\2\2")
        buf.write("\u0194\u0195\7)\2\2\u0195E\3\2\2\2\u0196\u0197\7,\2\2")
        buf.write("\u0197\u0198\5P)\2\u0198\u0199\5H%\2\u0199\u019b\3\2\2")
        buf.write("\2\u019a\u0196\3\2\2\2\u019b\u019c\3\2\2\2\u019c\u019a")
        buf.write("\3\2\2\2\u019c\u019d\3\2\2\2\u019dG\3\2\2\2\u019e\u019f")
        buf.write("\3\2\2\2\u019fI\3\2\2\2\u01a0\u01a1\3\2\2\2\u01a1K\3\2")
        buf.write("\2\2\u01a2\u01a3\5N(\2\u01a3\u01a4\7\f\2\2\u01a4\u01a5")
        buf.write("\5,\27\2\u01a5\u01a7\3\2\2\2\u01a6\u01a2\3\2\2\2\u01a6")
        buf.write("\u01a7\3\2\2\2\u01a7M\3\2\2\2\u01a8\u01a9\3\2\2\2\u01a9")
        buf.write("O\3\2\2\2\u01aa\u01ac\5R*\2\u01ab\u01aa\3\2\2\2\u01ac")
        buf.write("\u01ad\3\2\2\2\u01ad\u01ab\3\2\2\2\u01ad\u01ae\3\2\2\2")
        buf.write("\u01aeQ\3\2\2\2\u01af\u01b7\5Z.\2\u01b0\u01b3\5V,\2\u01b1")
        buf.write("\u01b3\5X-\2\u01b2\u01b0\3\2\2\2\u01b2\u01b1\3\2\2\2\u01b3")
        buf.write("\u01b4\3\2\2\2\u01b4\u01b5\5Z.\2\u01b5\u01b6\5T+\2\u01b6")
        buf.write("\u01b8\3\2\2\2\u01b7\u01b2\3\2\2\2\u01b7\u01b8\3\2\2\2")
        buf.write("\u01b8S\3\2\2\2\u01b9\u01ba\3\2\2\2\u01baU\3\2\2\2\u01bb")
        buf.write("\u01bc\7\7\2\2\u01bcW\3\2\2\2\u01bd\u01be\7\b\2\2\u01be")
        buf.write("Y\3\2\2\2\u01bf\u01c1\5\\/\2\u01c0\u01bf\3\2\2\2\u01c1")
        buf.write("\u01c2\3\2\2\2\u01c2\u01c0\3\2\2\2\u01c2\u01c3\3\2\2\2")
        buf.write("\u01c3[\3\2\2\2\u01c4\u01d0\5l\67\2\u01c5\u01cc\5`\61")
        buf.write("\2\u01c6\u01cc\5b\62\2\u01c7\u01cc\5d\63\2\u01c8\u01cc")
        buf.write("\5f\64\2\u01c9\u01cc\5h\65\2\u01ca\u01cc\5j\66\2\u01cb")
        buf.write("\u01c5\3\2\2\2\u01cb\u01c6\3\2\2\2\u01cb\u01c7\3\2\2\2")
        buf.write("\u01cb\u01c8\3\2\2\2\u01cb\u01c9\3\2\2\2\u01cb\u01ca\3")
        buf.write("\2\2\2\u01cc\u01cd\3\2\2\2\u01cd\u01ce\5l\67\2\u01ce\u01cf")
        buf.write("\5^\60\2\u01cf\u01d1\3\2\2\2\u01d0\u01cb\3\2\2\2\u01d0")
        buf.write("\u01d1\3\2\2\2\u01d1]\3\2\2\2\u01d2\u01d3\3\2\2\2\u01d3")
        buf.write("_\3\2\2\2\u01d4\u01d5\7(\2\2\u01d5a\3\2\2\2\u01d6\u01d7")
        buf.write("\7#\2\2\u01d7c\3\2\2\2\u01d8\u01d9\7$\2\2\u01d9e\3\2\2")
        buf.write("\2\u01da\u01db\7&\2\2\u01dbg\3\2\2\2\u01dc\u01dd\7%\2")
        buf.write("\2\u01ddi\3\2\2\2\u01de\u01df\7\'\2\2\u01dfk\3\2\2\2\u01e0")
        buf.write("\u01e2\5n8\2\u01e1\u01e0\3\2\2\2\u01e2\u01e3\3\2\2\2\u01e3")
        buf.write("\u01e1\3\2\2\2\u01e3\u01e4\3\2\2\2\u01e4m\3\2\2\2\u01e5")
        buf.write("\u01e6\5v<\2\u01e6\u01e9\5p9\2\u01e7\u01ea\5r:\2\u01e8")
        buf.write("\u01ea\5t;\2\u01e9\u01e7\3\2\2\2\u01e9\u01e8\3\2\2\2\u01e9")
        buf.write("\u01ea\3\2\2\2\u01eao\3\2\2\2\u01eb\u01ec\3\2\2\2\u01ec")
        buf.write("q\3\2\2\2\u01ed\u01ee\7\36\2\2\u01ees\3\2\2\2\u01ef\u01f0")
        buf.write("\7\37\2\2\u01f0u\3\2\2\2\u01f1\u01f3\5x=\2\u01f2\u01f1")
        buf.write("\3\2\2\2\u01f3\u01f4\3\2\2\2\u01f4\u01f2\3\2\2\2\u01f4")
        buf.write("\u01f5\3\2\2\2\u01f5w\3\2\2\2\u01f6\u01f7\5\u0080A\2\u01f7")
        buf.write("\u01fa\5z>\2\u01f8\u01fb\5|?\2\u01f9\u01fb\5~@\2\u01fa")
        buf.write("\u01f8\3\2\2\2\u01fa\u01f9\3\2\2\2\u01fa\u01fb\3\2\2\2")
        buf.write("\u01fby\3\2\2\2\u01fc\u01fd\3\2\2\2\u01fd{\3\2\2\2\u01fe")
        buf.write("\u01ff\7 \2\2\u01ff}\3\2\2\2\u0200\u0201\7!\2\2\u0201")
        buf.write("\177\3\2\2\2\u0202\u0203\5\u0082B\2\u0203\u0204\5P)\2")
        buf.write("\u0204\u0205\5\u0084C\2\u0205\u0208\3\2\2\2\u0206\u0208")
        buf.write("\5\u0086D\2\u0207\u0202\3\2\2\2\u0207\u0206\3\2\2\2\u0208")
        buf.write("\u0081\3\2\2\2\u0209\u020a\7\30\2\2\u020a\u0083\3\2\2")
        buf.write("\2\u020b\u020c\7\31\2\2\u020c\u0085\3\2\2\2\u020d\u0213")
        buf.write("\7\4\2\2\u020e\u0213\7\5\2\2\u020f\u0213\7\3\2\2\u0210")
        buf.write("\u0213\7\6\2\2\u0211\u0213\5\u0088E\2\u0212\u020d\3\2")
        buf.write("\2\2\u0212\u020e\3\2\2\2\u0212\u020f\3\2\2\2\u0212\u0210")
        buf.write("\3\2\2\2\u0212\u0211\3\2\2\2\u0213\u0087\3\2\2\2\u0214")
        buf.write("\u0216\5\u008aF\2\u0215\u0214\3\2\2\2\u0216\u0217\3\2")
        buf.write("\2\2\u0217\u0215\3\2\2\2\u0217\u0218\3\2\2\2\u0218\u0089")
        buf.write("\3\2\2\2\u0219\u021f\7\62\2\2\u021a\u021f\5\u0092J\2\u021b")
        buf.write("\u021f\5\u0094K\2\u021c\u021f\5\u0098M\2\u021d\u021f\5")
        buf.write("\u008cG\2\u021e\u0219\3\2\2\2\u021e\u021a\3\2\2\2\u021e")
        buf.write("\u021b\3\2\2\2\u021e\u021c\3\2\2\2\u021e\u021d\3\2\2\2")
        buf.write("\u021f\u008b\3\2\2\2\u0220\u0221\7\62\2\2\u0221\u0222")
        buf.write("\7\"\2\2\u0222\u0223\7\24\2\2\u0223\u022b\7\30\2\2\u0224")
        buf.write("\u0225\5P)\2\u0225\u0227\5\u008eH\2\u0226\u0228\7,\2\2")
        buf.write("\u0227\u0226\3\2\2\2\u0227\u0228\3\2\2\2\u0228\u022a\3")
        buf.write("\2\2\2\u0229\u0224\3\2\2\2\u022a\u022d\3\2\2\2\u022b\u0229")
        buf.write("\3\2\2\2\u022b\u022c\3\2\2\2\u022c\u022e\3\2\2\2\u022d")
        buf.write("\u022b\3\2\2\2\u022e\u022f\5\u0090I\2\u022f\u0230\7\31")
        buf.write("\2\2\u0230\u0231\7)\2\2\u0231\u008d\3\2\2\2\u0232\u0233")
        buf.write("\3\2\2\2\u0233\u008f\3\2\2\2\u0234\u0235\3\2\2\2\u0235")
        buf.write("\u0091\3\2\2\2\u0236\u0237\7\62\2\2\u0237\u0238\7+\2\2")
        buf.write("\u0238\u023d\7\62\2\2\u0239\u023a\7\30\2\2\u023a\u023b")
        buf.write("\5P)\2\u023b\u023c\7\31\2\2\u023c\u023e\3\2\2\2\u023d")
        buf.write("\u0239\3\2\2\2\u023d\u023e\3\2\2\2\u023e\u0093\3\2\2\2")
        buf.write("\u023f\u0240\7\62\2\2\u0240\u0247\7\30\2\2\u0241\u0243")
        buf.write("\5P)\2\u0242\u0244\7,\2\2\u0243\u0242\3\2\2\2\u0243\u0244")
        buf.write("\3\2\2\2\u0244\u0246\3\2\2\2\u0245\u0241\3\2\2\2\u0246")
        buf.write("\u0249\3\2\2\2\u0247\u0245\3\2\2\2\u0247\u0248\3\2\2\2")
        buf.write("\u0248\u024a\3\2\2\2\u0249\u0247\3\2\2\2\u024a\u024b\5")
        buf.write("\u0096L\2\u024b\u024c\7\31\2\2\u024c\u0095\3\2\2\2\u024d")
        buf.write("\u024e\3\2\2\2\u024e\u0097\3\2\2\2\u024f\u0250\7\62\2")
        buf.write("\2\u0250\u0251\7\34\2\2\u0251\u0252\5P)\2\u0252\u0253")
        buf.write("\7\35\2\2\u0253\u0099\3\2\2\2\63\u009e\u00a1\u00a5\u00b0")
        buf.write("\u00b5\u00b9\u00bc\u00cb\u00cd\u00d3\u00d5\u00da\u00e2")
        buf.write("\u00e9\u00f6\u0104\u0108\u0111\u0113\u011c\u0124\u0128")
        buf.write("\u0134\u013e\u0144\u015d\u015f\u0190\u019c\u01a6\u01ad")
        buf.write("\u01b2\u01b7\u01c2\u01cb\u01d0\u01e3\u01e9\u01f4\u01fa")
        buf.write("\u0207\u0212\u0217\u021e\u0227\u022b\u023d\u0243\u0247")
        return buf.getvalue()


class one_for_allParser ( Parser ):

    grammarFileName = "one_for_all.g4"

    atn = ATNDeserializer().deserialize(serializedATN())

    decisionsToDFA = [ DFA(ds, i) for i, ds in enumerate(atn.decisionToState) ]

    sharedContextCache = PredictionContextCache()

    literalNames = [ "<INVALID>", "<INVALID>", "<INVALID>", "<INVALID>", 
                     "<INVALID>", "'&&'", "'||'", "'true'", "'false'", "'if'", 
                     "'else'", "'while'", "'var'", "'program'", "'class'", 
                     "'private'", "'public'", "'main'", "'init'", "'read'", 
                     "'function'", "'write'", "'('", "')'", "'{'", "'}'", 
                     "'['", "']'", "'+'", "'-'", "'*'", "'/'", "'='", "'!='", 
                     "'>'", "'<'", "'>='", "'<='", "'=='", "';'", "':'", 
                     "'.'", "','", "'int'", "'float'", "'bool'", "'string'", 
                     "'return'" ]

    symbolicNames = [ "<INVALID>", "STRING", "FLOAT", "INT", "BOOLEAN", 
                      "TOK_AND", "TOK_OR", "TRUE", "FALSE", "TOK_IF", "TOK_ELSE", 
                      "TOK_WHILE", "TOK_VAR", "TOK_PROGRAM", "TOK_CLASS", 
                      "TOK_PRIVATE", "TOK_PUBLIC", "TOK_MAIN", "TOK_INIT", 
                      "TOK_READ", "TOK_FUNCTION", "TOK_WRITE", "TOK_LPAREN", 
                      "TOK_RPAREN", "TOK_LBRACE", "TOK_RBRACE", "TOK_LBRACKET", 
                      "TOK_RBRACKET", "TOK_PLUS", "TOK_MINUS", "TOK_MULTIPLICATION", 
                      "TOK_DIVISION", "TOK_EQUAL", "TOK_DIFFERENT", "TOK_GREATER", 
                      "TOK_LESS", "TOK_GREATER_EQ", "TOK_LESS_EQ", "TOK_SAME", 
                      "TOK_SEMICOLON", "TOK_COLON", "TOK_DOT", "TOK_COMMA", 
                      "TOK_INT", "TOK_FLOAT", "TOK_BOOLEAN", "TOK_STRING", 
                      "TOK_RETURN", "TOK_ID", "ESPACIOS" ]

    RULE_programa = 0
    RULE_neuro_jump_main = 1
    RULE_restOfProgram = 2
    RULE_classes = 3
    RULE_class_definition = 4
    RULE_inheritance = 5
    RULE_neuro_inheritance = 6
    RULE_class_public = 7
    RULE_class_private = 8
    RULE_constructor = 9
    RULE_routines = 10
    RULE_routine_definition = 11
    RULE_parameters = 12
    RULE_parameters_recursive = 13
    RULE_neuro_array = 14
    RULE_neuroparam_rec = 15
    RULE_variables = 16
    RULE_variable_definition = 17
    RULE_variable_assign = 18
    RULE_data_type = 19
    RULE_main = 20
    RULE_block = 21
    RULE_return_expr = 22
    RULE_statute = 23
    RULE_assignment = 24
    RULE_condition = 25
    RULE_neuro_if = 26
    RULE_neuro_endif = 27
    RULE_loop = 28
    RULE_neuro_while_begin = 29
    RULE_neuro_while_expression = 30
    RULE_neuro_while_end = 31
    RULE_input_ = 32
    RULE_output = 33
    RULE_output_recursive = 34
    RULE_neuro_getOutput = 35
    RULE_neuro_finishOutput = 36
    RULE_condition_else = 37
    RULE_neuro_else = 38
    RULE_expressions = 39
    RULE_expression_definition = 40
    RULE_neuro_expression = 41
    RULE_token_and = 42
    RULE_token_or = 43
    RULE_relational_exprs = 44
    RULE_relational_expr_definition = 45
    RULE_neuro_relational = 46
    RULE_token_same = 47
    RULE_token_different = 48
    RULE_token_greater = 49
    RULE_token_greater_eq = 50
    RULE_token_less = 51
    RULE_token_less_eq = 52
    RULE_sumMinus_exprs = 53
    RULE_sumMinus_expr_definition = 54
    RULE_neuro_sumMinus = 55
    RULE_token_plus = 56
    RULE_token_minus = 57
    RULE_multiDiv_exprs = 58
    RULE_multiDiv_expr_definition = 59
    RULE_neuro_multiDiv = 60
    RULE_token_multiplication = 61
    RULE_token_division = 62
    RULE_factor = 63
    RULE_token_lparen = 64
    RULE_token_rparen = 65
    RULE_constant = 66
    RULE_id_ = 67
    RULE_id_definition_ = 68
    RULE_init_class = 69
    RULE_neuro_initEval = 70
    RULE_neuro_createConstructor = 71
    RULE_evaluate_class = 72
    RULE_evaluate_function = 73
    RULE_neuro_params = 74
    RULE_evaluate_array = 75

    ruleNames =  [ "programa", "neuro_jump_main", "restOfProgram", "classes", 
                   "class_definition", "inheritance", "neuro_inheritance", 
                   "class_public", "class_private", "constructor", "routines", 
                   "routine_definition", "parameters", "parameters_recursive", 
                   "neuro_array", "neuroparam_rec", "variables", "variable_definition", 
                   "variable_assign", "data_type", "main", "block", "return_expr", 
                   "statute", "assignment", "condition", "neuro_if", "neuro_endif", 
                   "loop", "neuro_while_begin", "neuro_while_expression", 
                   "neuro_while_end", "input_", "output", "output_recursive", 
                   "neuro_getOutput", "neuro_finishOutput", "condition_else", 
                   "neuro_else", "expressions", "expression_definition", 
                   "neuro_expression", "token_and", "token_or", "relational_exprs", 
                   "relational_expr_definition", "neuro_relational", "token_same", 
                   "token_different", "token_greater", "token_greater_eq", 
                   "token_less", "token_less_eq", "sumMinus_exprs", "sumMinus_expr_definition", 
                   "neuro_sumMinus", "token_plus", "token_minus", "multiDiv_exprs", 
                   "multiDiv_expr_definition", "neuro_multiDiv", "token_multiplication", 
                   "token_division", "factor", "token_lparen", "token_rparen", 
                   "constant", "id_", "id_definition_", "init_class", "neuro_initEval", 
                   "neuro_createConstructor", "evaluate_class", "evaluate_function", 
                   "neuro_params", "evaluate_array" ]

    EOF = Token.EOF
    STRING=1
    FLOAT=2
    INT=3
    BOOLEAN=4
    TOK_AND=5
    TOK_OR=6
    TRUE=7
    FALSE=8
    TOK_IF=9
    TOK_ELSE=10
    TOK_WHILE=11
    TOK_VAR=12
    TOK_PROGRAM=13
    TOK_CLASS=14
    TOK_PRIVATE=15
    TOK_PUBLIC=16
    TOK_MAIN=17
    TOK_INIT=18
    TOK_READ=19
    TOK_FUNCTION=20
    TOK_WRITE=21
    TOK_LPAREN=22
    TOK_RPAREN=23
    TOK_LBRACE=24
    TOK_RBRACE=25
    TOK_LBRACKET=26
    TOK_RBRACKET=27
    TOK_PLUS=28
    TOK_MINUS=29
    TOK_MULTIPLICATION=30
    TOK_DIVISION=31
    TOK_EQUAL=32
    TOK_DIFFERENT=33
    TOK_GREATER=34
    TOK_LESS=35
    TOK_GREATER_EQ=36
    TOK_LESS_EQ=37
    TOK_SAME=38
    TOK_SEMICOLON=39
    TOK_COLON=40
    TOK_DOT=41
    TOK_COMMA=42
    TOK_INT=43
    TOK_FLOAT=44
    TOK_BOOLEAN=45
    TOK_STRING=46
    TOK_RETURN=47
    TOK_ID=48
    ESPACIOS=49

    def __init__(self, input:TokenStream, output:TextIO = sys.stdout):
        super().__init__(input, output)
        self.checkVersion("4.7.1")
        self._interp = ParserATNSimulator(self, self.atn, self.decisionsToDFA, self.sharedContextCache)
        self._predicates = None



    class ProgramaContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_PROGRAM(self):
            return self.getToken(one_for_allParser.TOK_PROGRAM, 0)

        def TOK_ID(self):
            return self.getToken(one_for_allParser.TOK_ID, 0)

        def TOK_SEMICOLON(self):
            return self.getToken(one_for_allParser.TOK_SEMICOLON, 0)

        def neuro_jump_main(self):
            return self.getTypedRuleContext(one_for_allParser.Neuro_jump_mainContext,0)


        def restOfProgram(self):
            return self.getTypedRuleContext(one_for_allParser.RestOfProgramContext,0)


        def classes(self):
            return self.getTypedRuleContext(one_for_allParser.ClassesContext,0)


        def variables(self):
            return self.getTypedRuleContext(one_for_allParser.VariablesContext,0)


        def routines(self):
            return self.getTypedRuleContext(one_for_allParser.RoutinesContext,0)


        def getRuleIndex(self):
            return one_for_allParser.RULE_programa

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterPrograma" ):
                listener.enterPrograma(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitPrograma" ):
                listener.exitPrograma(self)




    def programa(self):

        localctx = one_for_allParser.ProgramaContext(self, self._ctx, self.state)
        self.enterRule(localctx, 0, self.RULE_programa)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 152
            self.match(one_for_allParser.TOK_PROGRAM)
            self.state = 153
            self.match(one_for_allParser.TOK_ID)
            self.state = 154
            self.match(one_for_allParser.TOK_SEMICOLON)
            self.state = 156
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            if _la==one_for_allParser.TOK_CLASS:
                self.state = 155
                self.classes()


            self.state = 159
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            if _la==one_for_allParser.TOK_VAR:
                self.state = 158
                self.variables()


            self.state = 161
            self.neuro_jump_main()
            self.state = 163
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            if _la==one_for_allParser.TOK_FUNCTION:
                self.state = 162
                self.routines()


            self.state = 165
            self.restOfProgram()
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Neuro_jump_mainContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser


        def getRuleIndex(self):
            return one_for_allParser.RULE_neuro_jump_main

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterNeuro_jump_main" ):
                listener.enterNeuro_jump_main(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitNeuro_jump_main" ):
                listener.exitNeuro_jump_main(self)




    def neuro_jump_main(self):

        localctx = one_for_allParser.Neuro_jump_mainContext(self, self._ctx, self.state)
        self.enterRule(localctx, 2, self.RULE_neuro_jump_main)
        try:
            self.enterOuterAlt(localctx, 1)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class RestOfProgramContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def main(self):
            return self.getTypedRuleContext(one_for_allParser.MainContext,0)


        def getRuleIndex(self):
            return one_for_allParser.RULE_restOfProgram

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterRestOfProgram" ):
                listener.enterRestOfProgram(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitRestOfProgram" ):
                listener.exitRestOfProgram(self)




    def restOfProgram(self):

        localctx = one_for_allParser.RestOfProgramContext(self, self._ctx, self.state)
        self.enterRule(localctx, 4, self.RULE_restOfProgram)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 169
            self.main()
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class ClassesContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def class_definition(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.Class_definitionContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.Class_definitionContext,i)


        def getRuleIndex(self):
            return one_for_allParser.RULE_classes

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterClasses" ):
                listener.enterClasses(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitClasses" ):
                listener.exitClasses(self)




    def classes(self):

        localctx = one_for_allParser.ClassesContext(self, self._ctx, self.state)
        self.enterRule(localctx, 6, self.RULE_classes)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 172 
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while True:
                self.state = 171
                self.class_definition()
                self.state = 174 
                self._errHandler.sync(self)
                _la = self._input.LA(1)
                if not (_la==one_for_allParser.TOK_CLASS):
                    break

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Class_definitionContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_CLASS(self):
            return self.getToken(one_for_allParser.TOK_CLASS, 0)

        def TOK_ID(self):
            return self.getToken(one_for_allParser.TOK_ID, 0)

        def TOK_LBRACE(self):
            return self.getToken(one_for_allParser.TOK_LBRACE, 0)

        def constructor(self):
            return self.getTypedRuleContext(one_for_allParser.ConstructorContext,0)


        def TOK_RBRACE(self):
            return self.getToken(one_for_allParser.TOK_RBRACE, 0)

        def inheritance(self):
            return self.getTypedRuleContext(one_for_allParser.InheritanceContext,0)


        def class_public(self):
            return self.getTypedRuleContext(one_for_allParser.Class_publicContext,0)


        def class_private(self):
            return self.getTypedRuleContext(one_for_allParser.Class_privateContext,0)


        def getRuleIndex(self):
            return one_for_allParser.RULE_class_definition

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterClass_definition" ):
                listener.enterClass_definition(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitClass_definition" ):
                listener.exitClass_definition(self)




    def class_definition(self):

        localctx = one_for_allParser.Class_definitionContext(self, self._ctx, self.state)
        self.enterRule(localctx, 8, self.RULE_class_definition)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 176
            self.match(one_for_allParser.TOK_CLASS)
            self.state = 177
            self.match(one_for_allParser.TOK_ID)
            self.state = 179
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            if _la==one_for_allParser.TOK_COLON:
                self.state = 178
                self.inheritance()


            self.state = 181
            self.match(one_for_allParser.TOK_LBRACE)
            self.state = 183
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            if _la==one_for_allParser.TOK_PUBLIC:
                self.state = 182
                self.class_public()


            self.state = 186
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            if _la==one_for_allParser.TOK_PRIVATE:
                self.state = 185
                self.class_private()


            self.state = 188
            self.constructor()
            self.state = 189
            self.match(one_for_allParser.TOK_RBRACE)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class InheritanceContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_COLON(self):
            return self.getToken(one_for_allParser.TOK_COLON, 0)

        def TOK_ID(self):
            return self.getToken(one_for_allParser.TOK_ID, 0)

        def neuro_inheritance(self):
            return self.getTypedRuleContext(one_for_allParser.Neuro_inheritanceContext,0)


        def getRuleIndex(self):
            return one_for_allParser.RULE_inheritance

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterInheritance" ):
                listener.enterInheritance(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitInheritance" ):
                listener.exitInheritance(self)




    def inheritance(self):

        localctx = one_for_allParser.InheritanceContext(self, self._ctx, self.state)
        self.enterRule(localctx, 10, self.RULE_inheritance)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 191
            self.match(one_for_allParser.TOK_COLON)
            self.state = 192
            self.match(one_for_allParser.TOK_ID)
            self.state = 193
            self.neuro_inheritance()
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Neuro_inheritanceContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser


        def getRuleIndex(self):
            return one_for_allParser.RULE_neuro_inheritance

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterNeuro_inheritance" ):
                listener.enterNeuro_inheritance(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitNeuro_inheritance" ):
                listener.exitNeuro_inheritance(self)




    def neuro_inheritance(self):

        localctx = one_for_allParser.Neuro_inheritanceContext(self, self._ctx, self.state)
        self.enterRule(localctx, 12, self.RULE_neuro_inheritance)
        try:
            self.enterOuterAlt(localctx, 1)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Class_publicContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_PUBLIC(self, i:int=None):
            if i is None:
                return self.getTokens(one_for_allParser.TOK_PUBLIC)
            else:
                return self.getToken(one_for_allParser.TOK_PUBLIC, i)

        def variables(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.VariablesContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.VariablesContext,i)


        def routines(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.RoutinesContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.RoutinesContext,i)


        def getRuleIndex(self):
            return one_for_allParser.RULE_class_public

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterClass_public" ):
                listener.enterClass_public(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitClass_public" ):
                listener.exitClass_public(self)




    def class_public(self):

        localctx = one_for_allParser.Class_publicContext(self, self._ctx, self.state)
        self.enterRule(localctx, 14, self.RULE_class_public)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 201 
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while True:
                self.state = 201
                self._errHandler.sync(self)
                la_ = self._interp.adaptivePredict(self._input,7,self._ctx)
                if la_ == 1:
                    self.state = 197
                    self.match(one_for_allParser.TOK_PUBLIC)
                    self.state = 198
                    self.variables()
                    pass

                elif la_ == 2:
                    self.state = 199
                    self.match(one_for_allParser.TOK_PUBLIC)
                    self.state = 200
                    self.routines()
                    pass


                self.state = 203 
                self._errHandler.sync(self)
                _la = self._input.LA(1)
                if not (_la==one_for_allParser.TOK_PUBLIC):
                    break

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Class_privateContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_PRIVATE(self, i:int=None):
            if i is None:
                return self.getTokens(one_for_allParser.TOK_PRIVATE)
            else:
                return self.getToken(one_for_allParser.TOK_PRIVATE, i)

        def variables(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.VariablesContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.VariablesContext,i)


        def routines(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.RoutinesContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.RoutinesContext,i)


        def getRuleIndex(self):
            return one_for_allParser.RULE_class_private

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterClass_private" ):
                listener.enterClass_private(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitClass_private" ):
                listener.exitClass_private(self)




    def class_private(self):

        localctx = one_for_allParser.Class_privateContext(self, self._ctx, self.state)
        self.enterRule(localctx, 16, self.RULE_class_private)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 209 
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while True:
                self.state = 209
                self._errHandler.sync(self)
                la_ = self._interp.adaptivePredict(self._input,9,self._ctx)
                if la_ == 1:
                    self.state = 205
                    self.match(one_for_allParser.TOK_PRIVATE)
                    self.state = 206
                    self.variables()
                    pass

                elif la_ == 2:
                    self.state = 207
                    self.match(one_for_allParser.TOK_PRIVATE)
                    self.state = 208
                    self.routines()
                    pass


                self.state = 211 
                self._errHandler.sync(self)
                _la = self._input.LA(1)
                if not (_la==one_for_allParser.TOK_PRIVATE):
                    break

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class ConstructorContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_INIT(self):
            return self.getToken(one_for_allParser.TOK_INIT, 0)

        def TOK_LPAREN(self):
            return self.getToken(one_for_allParser.TOK_LPAREN, 0)

        def TOK_RPAREN(self):
            return self.getToken(one_for_allParser.TOK_RPAREN, 0)

        def block(self):
            return self.getTypedRuleContext(one_for_allParser.BlockContext,0)


        def parameters(self):
            return self.getTypedRuleContext(one_for_allParser.ParametersContext,0)


        def getRuleIndex(self):
            return one_for_allParser.RULE_constructor

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterConstructor" ):
                listener.enterConstructor(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitConstructor" ):
                listener.exitConstructor(self)




    def constructor(self):

        localctx = one_for_allParser.ConstructorContext(self, self._ctx, self.state)
        self.enterRule(localctx, 18, self.RULE_constructor)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 213
            self.match(one_for_allParser.TOK_INIT)
            self.state = 214
            self.match(one_for_allParser.TOK_LPAREN)
            self.state = 216
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            if _la==one_for_allParser.TOK_VAR:
                self.state = 215
                self.parameters()


            self.state = 218
            self.match(one_for_allParser.TOK_RPAREN)
            self.state = 219
            self.block()
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class RoutinesContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def routine_definition(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.Routine_definitionContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.Routine_definitionContext,i)


        def getRuleIndex(self):
            return one_for_allParser.RULE_routines

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterRoutines" ):
                listener.enterRoutines(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitRoutines" ):
                listener.exitRoutines(self)




    def routines(self):

        localctx = one_for_allParser.RoutinesContext(self, self._ctx, self.state)
        self.enterRule(localctx, 20, self.RULE_routines)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 222 
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while True:
                self.state = 221
                self.routine_definition()
                self.state = 224 
                self._errHandler.sync(self)
                _la = self._input.LA(1)
                if not (_la==one_for_allParser.TOK_FUNCTION):
                    break

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Routine_definitionContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_FUNCTION(self):
            return self.getToken(one_for_allParser.TOK_FUNCTION, 0)

        def data_type(self):
            return self.getTypedRuleContext(one_for_allParser.Data_typeContext,0)


        def TOK_ID(self):
            return self.getToken(one_for_allParser.TOK_ID, 0)

        def TOK_LPAREN(self):
            return self.getToken(one_for_allParser.TOK_LPAREN, 0)

        def TOK_RPAREN(self):
            return self.getToken(one_for_allParser.TOK_RPAREN, 0)

        def block(self):
            return self.getTypedRuleContext(one_for_allParser.BlockContext,0)


        def parameters(self):
            return self.getTypedRuleContext(one_for_allParser.ParametersContext,0)


        def getRuleIndex(self):
            return one_for_allParser.RULE_routine_definition

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterRoutine_definition" ):
                listener.enterRoutine_definition(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitRoutine_definition" ):
                listener.exitRoutine_definition(self)




    def routine_definition(self):

        localctx = one_for_allParser.Routine_definitionContext(self, self._ctx, self.state)
        self.enterRule(localctx, 22, self.RULE_routine_definition)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 226
            self.match(one_for_allParser.TOK_FUNCTION)
            self.state = 227
            self.data_type()
            self.state = 228
            self.match(one_for_allParser.TOK_ID)
            self.state = 229
            self.match(one_for_allParser.TOK_LPAREN)
            self.state = 231
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            if _la==one_for_allParser.TOK_VAR:
                self.state = 230
                self.parameters()


            self.state = 233
            self.match(one_for_allParser.TOK_RPAREN)
            self.state = 234
            self.block()
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class ParametersContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_VAR(self):
            return self.getToken(one_for_allParser.TOK_VAR, 0)

        def data_type(self):
            return self.getTypedRuleContext(one_for_allParser.Data_typeContext,0)


        def TOK_ID(self):
            return self.getToken(one_for_allParser.TOK_ID, 0)

        def parameters_recursive(self):
            return self.getTypedRuleContext(one_for_allParser.Parameters_recursiveContext,0)


        def TOK_LBRACKET(self):
            return self.getToken(one_for_allParser.TOK_LBRACKET, 0)

        def expressions(self):
            return self.getTypedRuleContext(one_for_allParser.ExpressionsContext,0)


        def neuro_array(self):
            return self.getTypedRuleContext(one_for_allParser.Neuro_arrayContext,0)


        def TOK_RBRACKET(self):
            return self.getToken(one_for_allParser.TOK_RBRACKET, 0)

        def getRuleIndex(self):
            return one_for_allParser.RULE_parameters

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterParameters" ):
                listener.enterParameters(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitParameters" ):
                listener.exitParameters(self)




    def parameters(self):

        localctx = one_for_allParser.ParametersContext(self, self._ctx, self.state)
        self.enterRule(localctx, 24, self.RULE_parameters)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 236
            self.match(one_for_allParser.TOK_VAR)
            self.state = 237
            self.data_type()
            self.state = 238
            self.match(one_for_allParser.TOK_ID)
            self.state = 244
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            if _la==one_for_allParser.TOK_LBRACKET:
                self.state = 239
                self.match(one_for_allParser.TOK_LBRACKET)
                self.state = 240
                self.expressions()
                self.state = 241
                self.neuro_array()
                self.state = 242
                self.match(one_for_allParser.TOK_RBRACKET)


            self.state = 246
            self.parameters_recursive()
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Parameters_recursiveContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_COMMA(self, i:int=None):
            if i is None:
                return self.getTokens(one_for_allParser.TOK_COMMA)
            else:
                return self.getToken(one_for_allParser.TOK_COMMA, i)

        def TOK_VAR(self, i:int=None):
            if i is None:
                return self.getTokens(one_for_allParser.TOK_VAR)
            else:
                return self.getToken(one_for_allParser.TOK_VAR, i)

        def neuroparam_rec(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.Neuroparam_recContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.Neuroparam_recContext,i)


        def data_type(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.Data_typeContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.Data_typeContext,i)


        def TOK_ID(self, i:int=None):
            if i is None:
                return self.getTokens(one_for_allParser.TOK_ID)
            else:
                return self.getToken(one_for_allParser.TOK_ID, i)

        def TOK_LBRACKET(self, i:int=None):
            if i is None:
                return self.getTokens(one_for_allParser.TOK_LBRACKET)
            else:
                return self.getToken(one_for_allParser.TOK_LBRACKET, i)

        def expressions(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.ExpressionsContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.ExpressionsContext,i)


        def neuro_array(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.Neuro_arrayContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.Neuro_arrayContext,i)


        def TOK_RBRACKET(self, i:int=None):
            if i is None:
                return self.getTokens(one_for_allParser.TOK_RBRACKET)
            else:
                return self.getToken(one_for_allParser.TOK_RBRACKET, i)

        def getRuleIndex(self):
            return one_for_allParser.RULE_parameters_recursive

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterParameters_recursive" ):
                listener.enterParameters_recursive(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitParameters_recursive" ):
                listener.exitParameters_recursive(self)




    def parameters_recursive(self):

        localctx = one_for_allParser.Parameters_recursiveContext(self, self._ctx, self.state)
        self.enterRule(localctx, 26, self.RULE_parameters_recursive)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 262
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while _la==one_for_allParser.TOK_COMMA:
                self.state = 248
                self.match(one_for_allParser.TOK_COMMA)
                self.state = 249
                self.match(one_for_allParser.TOK_VAR)
                self.state = 250
                self.neuroparam_rec()
                self.state = 251
                self.data_type()
                self.state = 252
                self.match(one_for_allParser.TOK_ID)
                self.state = 258
                self._errHandler.sync(self)
                _la = self._input.LA(1)
                if _la==one_for_allParser.TOK_LBRACKET:
                    self.state = 253
                    self.match(one_for_allParser.TOK_LBRACKET)
                    self.state = 254
                    self.expressions()
                    self.state = 255
                    self.neuro_array()
                    self.state = 256
                    self.match(one_for_allParser.TOK_RBRACKET)


                self.state = 264
                self._errHandler.sync(self)
                _la = self._input.LA(1)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Neuro_arrayContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser


        def getRuleIndex(self):
            return one_for_allParser.RULE_neuro_array

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterNeuro_array" ):
                listener.enterNeuro_array(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitNeuro_array" ):
                listener.exitNeuro_array(self)




    def neuro_array(self):

        localctx = one_for_allParser.Neuro_arrayContext(self, self._ctx, self.state)
        self.enterRule(localctx, 28, self.RULE_neuro_array)
        try:
            self.enterOuterAlt(localctx, 1)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Neuroparam_recContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser


        def getRuleIndex(self):
            return one_for_allParser.RULE_neuroparam_rec

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterNeuroparam_rec" ):
                listener.enterNeuroparam_rec(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitNeuroparam_rec" ):
                listener.exitNeuroparam_rec(self)




    def neuroparam_rec(self):

        localctx = one_for_allParser.Neuroparam_recContext(self, self._ctx, self.state)
        self.enterRule(localctx, 30, self.RULE_neuroparam_rec)
        try:
            self.enterOuterAlt(localctx, 1)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class VariablesContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def variable_definition(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.Variable_definitionContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.Variable_definitionContext,i)


        def variable_assign(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.Variable_assignContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.Variable_assignContext,i)


        def getRuleIndex(self):
            return one_for_allParser.RULE_variables

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterVariables" ):
                listener.enterVariables(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitVariables" ):
                listener.exitVariables(self)




    def variables(self):

        localctx = one_for_allParser.VariablesContext(self, self._ctx, self.state)
        self.enterRule(localctx, 32, self.RULE_variables)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 271 
            self._errHandler.sync(self)
            _alt = 1
            while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                if _alt == 1:
                    self.state = 271
                    self._errHandler.sync(self)
                    la_ = self._interp.adaptivePredict(self._input,17,self._ctx)
                    if la_ == 1:
                        self.state = 269
                        self.variable_definition()
                        pass

                    elif la_ == 2:
                        self.state = 270
                        self.variable_assign()
                        pass



                else:
                    raise NoViableAltException(self)
                self.state = 273 
                self._errHandler.sync(self)
                _alt = self._interp.adaptivePredict(self._input,18,self._ctx)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Variable_definitionContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_VAR(self):
            return self.getToken(one_for_allParser.TOK_VAR, 0)

        def data_type(self):
            return self.getTypedRuleContext(one_for_allParser.Data_typeContext,0)


        def TOK_ID(self, i:int=None):
            if i is None:
                return self.getTokens(one_for_allParser.TOK_ID)
            else:
                return self.getToken(one_for_allParser.TOK_ID, i)

        def TOK_SEMICOLON(self):
            return self.getToken(one_for_allParser.TOK_SEMICOLON, 0)

        def TOK_LBRACKET(self, i:int=None):
            if i is None:
                return self.getTokens(one_for_allParser.TOK_LBRACKET)
            else:
                return self.getToken(one_for_allParser.TOK_LBRACKET, i)

        def expressions(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.ExpressionsContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.ExpressionsContext,i)


        def TOK_RBRACKET(self, i:int=None):
            if i is None:
                return self.getTokens(one_for_allParser.TOK_RBRACKET)
            else:
                return self.getToken(one_for_allParser.TOK_RBRACKET, i)

        def TOK_COMMA(self, i:int=None):
            if i is None:
                return self.getTokens(one_for_allParser.TOK_COMMA)
            else:
                return self.getToken(one_for_allParser.TOK_COMMA, i)

        def getRuleIndex(self):
            return one_for_allParser.RULE_variable_definition

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterVariable_definition" ):
                listener.enterVariable_definition(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitVariable_definition" ):
                listener.exitVariable_definition(self)




    def variable_definition(self):

        localctx = one_for_allParser.Variable_definitionContext(self, self._ctx, self.state)
        self.enterRule(localctx, 34, self.RULE_variable_definition)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 275
            self.match(one_for_allParser.TOK_VAR)
            self.state = 276
            self.data_type()
            self.state = 277
            self.match(one_for_allParser.TOK_ID)
            self.state = 282
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            if _la==one_for_allParser.TOK_LBRACKET:
                self.state = 278
                self.match(one_for_allParser.TOK_LBRACKET)
                self.state = 279
                self.expressions()
                self.state = 280
                self.match(one_for_allParser.TOK_RBRACKET)


            self.state = 294
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while _la==one_for_allParser.TOK_COMMA:
                self.state = 284
                self.match(one_for_allParser.TOK_COMMA)
                self.state = 285
                self.match(one_for_allParser.TOK_ID)
                self.state = 290
                self._errHandler.sync(self)
                _la = self._input.LA(1)
                if _la==one_for_allParser.TOK_LBRACKET:
                    self.state = 286
                    self.match(one_for_allParser.TOK_LBRACKET)
                    self.state = 287
                    self.expressions()
                    self.state = 288
                    self.match(one_for_allParser.TOK_RBRACKET)


                self.state = 296
                self._errHandler.sync(self)
                _la = self._input.LA(1)

            self.state = 297
            self.match(one_for_allParser.TOK_SEMICOLON)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Variable_assignContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_VAR(self):
            return self.getToken(one_for_allParser.TOK_VAR, 0)

        def data_type(self):
            return self.getTypedRuleContext(one_for_allParser.Data_typeContext,0)


        def TOK_ID(self, i:int=None):
            if i is None:
                return self.getTokens(one_for_allParser.TOK_ID)
            else:
                return self.getToken(one_for_allParser.TOK_ID, i)

        def TOK_EQUAL(self, i:int=None):
            if i is None:
                return self.getTokens(one_for_allParser.TOK_EQUAL)
            else:
                return self.getToken(one_for_allParser.TOK_EQUAL, i)

        def expressions(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.ExpressionsContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.ExpressionsContext,i)


        def TOK_SEMICOLON(self):
            return self.getToken(one_for_allParser.TOK_SEMICOLON, 0)

        def TOK_LBRACKET(self, i:int=None):
            if i is None:
                return self.getTokens(one_for_allParser.TOK_LBRACKET)
            else:
                return self.getToken(one_for_allParser.TOK_LBRACKET, i)

        def TOK_RBRACKET(self, i:int=None):
            if i is None:
                return self.getTokens(one_for_allParser.TOK_RBRACKET)
            else:
                return self.getToken(one_for_allParser.TOK_RBRACKET, i)

        def TOK_COMMA(self, i:int=None):
            if i is None:
                return self.getTokens(one_for_allParser.TOK_COMMA)
            else:
                return self.getToken(one_for_allParser.TOK_COMMA, i)

        def getRuleIndex(self):
            return one_for_allParser.RULE_variable_assign

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterVariable_assign" ):
                listener.enterVariable_assign(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitVariable_assign" ):
                listener.exitVariable_assign(self)




    def variable_assign(self):

        localctx = one_for_allParser.Variable_assignContext(self, self._ctx, self.state)
        self.enterRule(localctx, 36, self.RULE_variable_assign)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 299
            self.match(one_for_allParser.TOK_VAR)
            self.state = 300
            self.data_type()
            self.state = 301
            self.match(one_for_allParser.TOK_ID)
            self.state = 306
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            if _la==one_for_allParser.TOK_LBRACKET:
                self.state = 302
                self.match(one_for_allParser.TOK_LBRACKET)
                self.state = 303
                self.expressions()
                self.state = 304
                self.match(one_for_allParser.TOK_RBRACKET)


            self.state = 308
            self.match(one_for_allParser.TOK_EQUAL)
            self.state = 309
            self.expressions()
            self.state = 322
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while _la==one_for_allParser.TOK_COMMA:
                self.state = 310
                self.match(one_for_allParser.TOK_COMMA)
                self.state = 311
                self.match(one_for_allParser.TOK_ID)
                self.state = 316
                self._errHandler.sync(self)
                _la = self._input.LA(1)
                if _la==one_for_allParser.TOK_LBRACKET:
                    self.state = 312
                    self.match(one_for_allParser.TOK_LBRACKET)
                    self.state = 313
                    self.expressions()
                    self.state = 314
                    self.match(one_for_allParser.TOK_RBRACKET)


                self.state = 318
                self.match(one_for_allParser.TOK_EQUAL)
                self.state = 319
                self.expressions()
                self.state = 324
                self._errHandler.sync(self)
                _la = self._input.LA(1)

            self.state = 325
            self.match(one_for_allParser.TOK_SEMICOLON)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Data_typeContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_INT(self):
            return self.getToken(one_for_allParser.TOK_INT, 0)

        def TOK_FLOAT(self):
            return self.getToken(one_for_allParser.TOK_FLOAT, 0)

        def TOK_STRING(self):
            return self.getToken(one_for_allParser.TOK_STRING, 0)

        def TOK_BOOLEAN(self):
            return self.getToken(one_for_allParser.TOK_BOOLEAN, 0)

        def TOK_ID(self):
            return self.getToken(one_for_allParser.TOK_ID, 0)

        def getRuleIndex(self):
            return one_for_allParser.RULE_data_type

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterData_type" ):
                listener.enterData_type(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitData_type" ):
                listener.exitData_type(self)




    def data_type(self):

        localctx = one_for_allParser.Data_typeContext(self, self._ctx, self.state)
        self.enterRule(localctx, 38, self.RULE_data_type)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 327
            _la = self._input.LA(1)
            if not((((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << one_for_allParser.TOK_INT) | (1 << one_for_allParser.TOK_FLOAT) | (1 << one_for_allParser.TOK_BOOLEAN) | (1 << one_for_allParser.TOK_STRING) | (1 << one_for_allParser.TOK_ID))) != 0)):
                self._errHandler.recoverInline(self)
            else:
                self._errHandler.reportMatch(self)
                self.consume()
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class MainContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_MAIN(self):
            return self.getToken(one_for_allParser.TOK_MAIN, 0)

        def block(self):
            return self.getTypedRuleContext(one_for_allParser.BlockContext,0)


        def getRuleIndex(self):
            return one_for_allParser.RULE_main

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterMain" ):
                listener.enterMain(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitMain" ):
                listener.exitMain(self)




    def main(self):

        localctx = one_for_allParser.MainContext(self, self._ctx, self.state)
        self.enterRule(localctx, 40, self.RULE_main)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 329
            self.match(one_for_allParser.TOK_MAIN)
            self.state = 330
            self.block()
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class BlockContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_LBRACE(self):
            return self.getToken(one_for_allParser.TOK_LBRACE, 0)

        def statute(self):
            return self.getTypedRuleContext(one_for_allParser.StatuteContext,0)


        def TOK_RBRACE(self):
            return self.getToken(one_for_allParser.TOK_RBRACE, 0)

        def getRuleIndex(self):
            return one_for_allParser.RULE_block

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterBlock" ):
                listener.enterBlock(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitBlock" ):
                listener.exitBlock(self)




    def block(self):

        localctx = one_for_allParser.BlockContext(self, self._ctx, self.state)
        self.enterRule(localctx, 42, self.RULE_block)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 332
            self.match(one_for_allParser.TOK_LBRACE)
            self.state = 333
            self.statute()
            self.state = 334
            self.match(one_for_allParser.TOK_RBRACE)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Return_exprContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_RETURN(self):
            return self.getToken(one_for_allParser.TOK_RETURN, 0)

        def expressions(self):
            return self.getTypedRuleContext(one_for_allParser.ExpressionsContext,0)


        def TOK_SEMICOLON(self):
            return self.getToken(one_for_allParser.TOK_SEMICOLON, 0)

        def getRuleIndex(self):
            return one_for_allParser.RULE_return_expr

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterReturn_expr" ):
                listener.enterReturn_expr(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitReturn_expr" ):
                listener.exitReturn_expr(self)




    def return_expr(self):

        localctx = one_for_allParser.Return_exprContext(self, self._ctx, self.state)
        self.enterRule(localctx, 44, self.RULE_return_expr)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 336
            self.match(one_for_allParser.TOK_RETURN)
            self.state = 337
            self.expressions()
            self.state = 338
            self.match(one_for_allParser.TOK_SEMICOLON)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class StatuteContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def assignment(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.AssignmentContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.AssignmentContext,i)


        def condition(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.ConditionContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.ConditionContext,i)


        def loop(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.LoopContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.LoopContext,i)


        def output(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.OutputContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.OutputContext,i)


        def input_(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.Input_Context)
            else:
                return self.getTypedRuleContext(one_for_allParser.Input_Context,i)


        def variables(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.VariablesContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.VariablesContext,i)


        def return_expr(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.Return_exprContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.Return_exprContext,i)


        def getRuleIndex(self):
            return one_for_allParser.RULE_statute

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterStatute" ):
                listener.enterStatute(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitStatute" ):
                listener.exitStatute(self)




    def statute(self):

        localctx = one_for_allParser.StatuteContext(self, self._ctx, self.state)
        self.enterRule(localctx, 46, self.RULE_statute)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 349
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << one_for_allParser.TOK_IF) | (1 << one_for_allParser.TOK_WHILE) | (1 << one_for_allParser.TOK_VAR) | (1 << one_for_allParser.TOK_READ) | (1 << one_for_allParser.TOK_WRITE) | (1 << one_for_allParser.TOK_RETURN) | (1 << one_for_allParser.TOK_ID))) != 0):
                self.state = 347
                self._errHandler.sync(self)
                token = self._input.LA(1)
                if token in [one_for_allParser.TOK_ID]:
                    self.state = 340
                    self.assignment()
                    pass
                elif token in [one_for_allParser.TOK_IF]:
                    self.state = 341
                    self.condition()
                    pass
                elif token in [one_for_allParser.TOK_WHILE]:
                    self.state = 342
                    self.loop()
                    pass
                elif token in [one_for_allParser.TOK_WRITE]:
                    self.state = 343
                    self.output()
                    pass
                elif token in [one_for_allParser.TOK_READ]:
                    self.state = 344
                    self.input_()
                    pass
                elif token in [one_for_allParser.TOK_VAR]:
                    self.state = 345
                    self.variables()
                    pass
                elif token in [one_for_allParser.TOK_RETURN]:
                    self.state = 346
                    self.return_expr()
                    pass
                else:
                    raise NoViableAltException(self)

                self.state = 351
                self._errHandler.sync(self)
                _la = self._input.LA(1)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class AssignmentContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def id_(self):
            return self.getTypedRuleContext(one_for_allParser.Id_Context,0)


        def TOK_EQUAL(self):
            return self.getToken(one_for_allParser.TOK_EQUAL, 0)

        def expressions(self):
            return self.getTypedRuleContext(one_for_allParser.ExpressionsContext,0)


        def TOK_SEMICOLON(self):
            return self.getToken(one_for_allParser.TOK_SEMICOLON, 0)

        def getRuleIndex(self):
            return one_for_allParser.RULE_assignment

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterAssignment" ):
                listener.enterAssignment(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitAssignment" ):
                listener.exitAssignment(self)




    def assignment(self):

        localctx = one_for_allParser.AssignmentContext(self, self._ctx, self.state)
        self.enterRule(localctx, 48, self.RULE_assignment)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 352
            self.id_()
            self.state = 353
            self.match(one_for_allParser.TOK_EQUAL)
            self.state = 354
            self.expressions()
            self.state = 355
            self.match(one_for_allParser.TOK_SEMICOLON)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class ConditionContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_IF(self):
            return self.getToken(one_for_allParser.TOK_IF, 0)

        def TOK_LPAREN(self):
            return self.getToken(one_for_allParser.TOK_LPAREN, 0)

        def expressions(self):
            return self.getTypedRuleContext(one_for_allParser.ExpressionsContext,0)


        def TOK_RPAREN(self):
            return self.getToken(one_for_allParser.TOK_RPAREN, 0)

        def neuro_if(self):
            return self.getTypedRuleContext(one_for_allParser.Neuro_ifContext,0)


        def block(self):
            return self.getTypedRuleContext(one_for_allParser.BlockContext,0)


        def condition_else(self):
            return self.getTypedRuleContext(one_for_allParser.Condition_elseContext,0)


        def neuro_endif(self):
            return self.getTypedRuleContext(one_for_allParser.Neuro_endifContext,0)


        def getRuleIndex(self):
            return one_for_allParser.RULE_condition

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterCondition" ):
                listener.enterCondition(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitCondition" ):
                listener.exitCondition(self)




    def condition(self):

        localctx = one_for_allParser.ConditionContext(self, self._ctx, self.state)
        self.enterRule(localctx, 50, self.RULE_condition)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 357
            self.match(one_for_allParser.TOK_IF)
            self.state = 358
            self.match(one_for_allParser.TOK_LPAREN)
            self.state = 359
            self.expressions()
            self.state = 360
            self.match(one_for_allParser.TOK_RPAREN)
            self.state = 361
            self.neuro_if()
            self.state = 362
            self.block()
            self.state = 363
            self.condition_else()
            self.state = 364
            self.neuro_endif()
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Neuro_ifContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser


        def getRuleIndex(self):
            return one_for_allParser.RULE_neuro_if

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterNeuro_if" ):
                listener.enterNeuro_if(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitNeuro_if" ):
                listener.exitNeuro_if(self)




    def neuro_if(self):

        localctx = one_for_allParser.Neuro_ifContext(self, self._ctx, self.state)
        self.enterRule(localctx, 52, self.RULE_neuro_if)
        try:
            self.enterOuterAlt(localctx, 1)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Neuro_endifContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser


        def getRuleIndex(self):
            return one_for_allParser.RULE_neuro_endif

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterNeuro_endif" ):
                listener.enterNeuro_endif(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitNeuro_endif" ):
                listener.exitNeuro_endif(self)




    def neuro_endif(self):

        localctx = one_for_allParser.Neuro_endifContext(self, self._ctx, self.state)
        self.enterRule(localctx, 54, self.RULE_neuro_endif)
        try:
            self.enterOuterAlt(localctx, 1)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class LoopContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_WHILE(self):
            return self.getToken(one_for_allParser.TOK_WHILE, 0)

        def neuro_while_begin(self):
            return self.getTypedRuleContext(one_for_allParser.Neuro_while_beginContext,0)


        def TOK_LPAREN(self):
            return self.getToken(one_for_allParser.TOK_LPAREN, 0)

        def expressions(self):
            return self.getTypedRuleContext(one_for_allParser.ExpressionsContext,0)


        def TOK_RPAREN(self):
            return self.getToken(one_for_allParser.TOK_RPAREN, 0)

        def neuro_while_expression(self):
            return self.getTypedRuleContext(one_for_allParser.Neuro_while_expressionContext,0)


        def block(self):
            return self.getTypedRuleContext(one_for_allParser.BlockContext,0)


        def neuro_while_end(self):
            return self.getTypedRuleContext(one_for_allParser.Neuro_while_endContext,0)


        def getRuleIndex(self):
            return one_for_allParser.RULE_loop

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterLoop" ):
                listener.enterLoop(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitLoop" ):
                listener.exitLoop(self)




    def loop(self):

        localctx = one_for_allParser.LoopContext(self, self._ctx, self.state)
        self.enterRule(localctx, 56, self.RULE_loop)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 370
            self.match(one_for_allParser.TOK_WHILE)
            self.state = 371
            self.neuro_while_begin()
            self.state = 372
            self.match(one_for_allParser.TOK_LPAREN)
            self.state = 373
            self.expressions()
            self.state = 374
            self.match(one_for_allParser.TOK_RPAREN)
            self.state = 375
            self.neuro_while_expression()
            self.state = 376
            self.block()
            self.state = 377
            self.neuro_while_end()
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Neuro_while_beginContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser


        def getRuleIndex(self):
            return one_for_allParser.RULE_neuro_while_begin

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterNeuro_while_begin" ):
                listener.enterNeuro_while_begin(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitNeuro_while_begin" ):
                listener.exitNeuro_while_begin(self)




    def neuro_while_begin(self):

        localctx = one_for_allParser.Neuro_while_beginContext(self, self._ctx, self.state)
        self.enterRule(localctx, 58, self.RULE_neuro_while_begin)
        try:
            self.enterOuterAlt(localctx, 1)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Neuro_while_expressionContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser


        def getRuleIndex(self):
            return one_for_allParser.RULE_neuro_while_expression

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterNeuro_while_expression" ):
                listener.enterNeuro_while_expression(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitNeuro_while_expression" ):
                listener.exitNeuro_while_expression(self)




    def neuro_while_expression(self):

        localctx = one_for_allParser.Neuro_while_expressionContext(self, self._ctx, self.state)
        self.enterRule(localctx, 60, self.RULE_neuro_while_expression)
        try:
            self.enterOuterAlt(localctx, 1)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Neuro_while_endContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser


        def getRuleIndex(self):
            return one_for_allParser.RULE_neuro_while_end

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterNeuro_while_end" ):
                listener.enterNeuro_while_end(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitNeuro_while_end" ):
                listener.exitNeuro_while_end(self)




    def neuro_while_end(self):

        localctx = one_for_allParser.Neuro_while_endContext(self, self._ctx, self.state)
        self.enterRule(localctx, 62, self.RULE_neuro_while_end)
        try:
            self.enterOuterAlt(localctx, 1)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Input_Context(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_READ(self):
            return self.getToken(one_for_allParser.TOK_READ, 0)

        def TOK_LPAREN(self):
            return self.getToken(one_for_allParser.TOK_LPAREN, 0)

        def expressions(self):
            return self.getTypedRuleContext(one_for_allParser.ExpressionsContext,0)


        def TOK_COMMA(self):
            return self.getToken(one_for_allParser.TOK_COMMA, 0)

        def TOK_ID(self):
            return self.getToken(one_for_allParser.TOK_ID, 0)

        def TOK_RPAREN(self):
            return self.getToken(one_for_allParser.TOK_RPAREN, 0)

        def TOK_SEMICOLON(self):
            return self.getToken(one_for_allParser.TOK_SEMICOLON, 0)

        def getRuleIndex(self):
            return one_for_allParser.RULE_input_

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterInput_" ):
                listener.enterInput_(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitInput_" ):
                listener.exitInput_(self)




    def input_(self):

        localctx = one_for_allParser.Input_Context(self, self._ctx, self.state)
        self.enterRule(localctx, 64, self.RULE_input_)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 385
            self.match(one_for_allParser.TOK_READ)
            self.state = 386
            self.match(one_for_allParser.TOK_LPAREN)
            self.state = 387
            self.expressions()
            self.state = 388
            self.match(one_for_allParser.TOK_COMMA)
            self.state = 389
            self.match(one_for_allParser.TOK_ID)
            self.state = 390
            self.match(one_for_allParser.TOK_RPAREN)
            self.state = 391
            self.match(one_for_allParser.TOK_SEMICOLON)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class OutputContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_WRITE(self):
            return self.getToken(one_for_allParser.TOK_WRITE, 0)

        def TOK_LPAREN(self):
            return self.getToken(one_for_allParser.TOK_LPAREN, 0)

        def expressions(self):
            return self.getTypedRuleContext(one_for_allParser.ExpressionsContext,0)


        def neuro_getOutput(self):
            return self.getTypedRuleContext(one_for_allParser.Neuro_getOutputContext,0)


        def neuro_finishOutput(self):
            return self.getTypedRuleContext(one_for_allParser.Neuro_finishOutputContext,0)


        def TOK_RPAREN(self):
            return self.getToken(one_for_allParser.TOK_RPAREN, 0)

        def TOK_SEMICOLON(self):
            return self.getToken(one_for_allParser.TOK_SEMICOLON, 0)

        def output_recursive(self):
            return self.getTypedRuleContext(one_for_allParser.Output_recursiveContext,0)


        def getRuleIndex(self):
            return one_for_allParser.RULE_output

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterOutput" ):
                listener.enterOutput(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitOutput" ):
                listener.exitOutput(self)




    def output(self):

        localctx = one_for_allParser.OutputContext(self, self._ctx, self.state)
        self.enterRule(localctx, 66, self.RULE_output)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 393
            self.match(one_for_allParser.TOK_WRITE)
            self.state = 394
            self.match(one_for_allParser.TOK_LPAREN)
            self.state = 395
            self.expressions()
            self.state = 396
            self.neuro_getOutput()
            self.state = 398
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            if _la==one_for_allParser.TOK_COMMA:
                self.state = 397
                self.output_recursive()


            self.state = 400
            self.neuro_finishOutput()
            self.state = 401
            self.match(one_for_allParser.TOK_RPAREN)
            self.state = 402
            self.match(one_for_allParser.TOK_SEMICOLON)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Output_recursiveContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_COMMA(self, i:int=None):
            if i is None:
                return self.getTokens(one_for_allParser.TOK_COMMA)
            else:
                return self.getToken(one_for_allParser.TOK_COMMA, i)

        def expressions(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.ExpressionsContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.ExpressionsContext,i)


        def neuro_getOutput(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.Neuro_getOutputContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.Neuro_getOutputContext,i)


        def getRuleIndex(self):
            return one_for_allParser.RULE_output_recursive

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterOutput_recursive" ):
                listener.enterOutput_recursive(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitOutput_recursive" ):
                listener.exitOutput_recursive(self)




    def output_recursive(self):

        localctx = one_for_allParser.Output_recursiveContext(self, self._ctx, self.state)
        self.enterRule(localctx, 68, self.RULE_output_recursive)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 408 
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while True:
                self.state = 404
                self.match(one_for_allParser.TOK_COMMA)
                self.state = 405
                self.expressions()
                self.state = 406
                self.neuro_getOutput()
                self.state = 410 
                self._errHandler.sync(self)
                _la = self._input.LA(1)
                if not (_la==one_for_allParser.TOK_COMMA):
                    break

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Neuro_getOutputContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser


        def getRuleIndex(self):
            return one_for_allParser.RULE_neuro_getOutput

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterNeuro_getOutput" ):
                listener.enterNeuro_getOutput(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitNeuro_getOutput" ):
                listener.exitNeuro_getOutput(self)




    def neuro_getOutput(self):

        localctx = one_for_allParser.Neuro_getOutputContext(self, self._ctx, self.state)
        self.enterRule(localctx, 70, self.RULE_neuro_getOutput)
        try:
            self.enterOuterAlt(localctx, 1)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Neuro_finishOutputContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser


        def getRuleIndex(self):
            return one_for_allParser.RULE_neuro_finishOutput

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterNeuro_finishOutput" ):
                listener.enterNeuro_finishOutput(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitNeuro_finishOutput" ):
                listener.exitNeuro_finishOutput(self)




    def neuro_finishOutput(self):

        localctx = one_for_allParser.Neuro_finishOutputContext(self, self._ctx, self.state)
        self.enterRule(localctx, 72, self.RULE_neuro_finishOutput)
        try:
            self.enterOuterAlt(localctx, 1)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Condition_elseContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def neuro_else(self):
            return self.getTypedRuleContext(one_for_allParser.Neuro_elseContext,0)


        def TOK_ELSE(self):
            return self.getToken(one_for_allParser.TOK_ELSE, 0)

        def block(self):
            return self.getTypedRuleContext(one_for_allParser.BlockContext,0)


        def getRuleIndex(self):
            return one_for_allParser.RULE_condition_else

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterCondition_else" ):
                listener.enterCondition_else(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitCondition_else" ):
                listener.exitCondition_else(self)




    def condition_else(self):

        localctx = one_for_allParser.Condition_elseContext(self, self._ctx, self.state)
        self.enterRule(localctx, 74, self.RULE_condition_else)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 420
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            if _la==one_for_allParser.TOK_ELSE:
                self.state = 416
                self.neuro_else()
                self.state = 417
                self.match(one_for_allParser.TOK_ELSE)
                self.state = 418
                self.block()


        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Neuro_elseContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser


        def getRuleIndex(self):
            return one_for_allParser.RULE_neuro_else

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterNeuro_else" ):
                listener.enterNeuro_else(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitNeuro_else" ):
                listener.exitNeuro_else(self)




    def neuro_else(self):

        localctx = one_for_allParser.Neuro_elseContext(self, self._ctx, self.state)
        self.enterRule(localctx, 76, self.RULE_neuro_else)
        try:
            self.enterOuterAlt(localctx, 1)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class ExpressionsContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def expression_definition(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.Expression_definitionContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.Expression_definitionContext,i)


        def getRuleIndex(self):
            return one_for_allParser.RULE_expressions

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterExpressions" ):
                listener.enterExpressions(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitExpressions" ):
                listener.exitExpressions(self)




    def expressions(self):

        localctx = one_for_allParser.ExpressionsContext(self, self._ctx, self.state)
        self.enterRule(localctx, 78, self.RULE_expressions)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 425 
            self._errHandler.sync(self)
            _alt = 1
            while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                if _alt == 1:
                    self.state = 424
                    self.expression_definition()

                else:
                    raise NoViableAltException(self)
                self.state = 427 
                self._errHandler.sync(self)
                _alt = self._interp.adaptivePredict(self._input,30,self._ctx)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Expression_definitionContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def relational_exprs(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.Relational_exprsContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.Relational_exprsContext,i)


        def neuro_expression(self):
            return self.getTypedRuleContext(one_for_allParser.Neuro_expressionContext,0)


        def token_and(self):
            return self.getTypedRuleContext(one_for_allParser.Token_andContext,0)


        def token_or(self):
            return self.getTypedRuleContext(one_for_allParser.Token_orContext,0)


        def getRuleIndex(self):
            return one_for_allParser.RULE_expression_definition

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterExpression_definition" ):
                listener.enterExpression_definition(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitExpression_definition" ):
                listener.exitExpression_definition(self)




    def expression_definition(self):

        localctx = one_for_allParser.Expression_definitionContext(self, self._ctx, self.state)
        self.enterRule(localctx, 80, self.RULE_expression_definition)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 429
            self.relational_exprs()
            self.state = 437
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            if _la==one_for_allParser.TOK_AND or _la==one_for_allParser.TOK_OR:
                self.state = 432
                self._errHandler.sync(self)
                token = self._input.LA(1)
                if token in [one_for_allParser.TOK_AND]:
                    self.state = 430
                    self.token_and()
                    pass
                elif token in [one_for_allParser.TOK_OR]:
                    self.state = 431
                    self.token_or()
                    pass
                else:
                    raise NoViableAltException(self)

                self.state = 434
                self.relational_exprs()
                self.state = 435
                self.neuro_expression()


        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Neuro_expressionContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser


        def getRuleIndex(self):
            return one_for_allParser.RULE_neuro_expression

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterNeuro_expression" ):
                listener.enterNeuro_expression(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitNeuro_expression" ):
                listener.exitNeuro_expression(self)




    def neuro_expression(self):

        localctx = one_for_allParser.Neuro_expressionContext(self, self._ctx, self.state)
        self.enterRule(localctx, 82, self.RULE_neuro_expression)
        try:
            self.enterOuterAlt(localctx, 1)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Token_andContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_AND(self):
            return self.getToken(one_for_allParser.TOK_AND, 0)

        def getRuleIndex(self):
            return one_for_allParser.RULE_token_and

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterToken_and" ):
                listener.enterToken_and(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitToken_and" ):
                listener.exitToken_and(self)




    def token_and(self):

        localctx = one_for_allParser.Token_andContext(self, self._ctx, self.state)
        self.enterRule(localctx, 84, self.RULE_token_and)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 441
            self.match(one_for_allParser.TOK_AND)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Token_orContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_OR(self):
            return self.getToken(one_for_allParser.TOK_OR, 0)

        def getRuleIndex(self):
            return one_for_allParser.RULE_token_or

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterToken_or" ):
                listener.enterToken_or(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitToken_or" ):
                listener.exitToken_or(self)




    def token_or(self):

        localctx = one_for_allParser.Token_orContext(self, self._ctx, self.state)
        self.enterRule(localctx, 86, self.RULE_token_or)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 443
            self.match(one_for_allParser.TOK_OR)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Relational_exprsContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def relational_expr_definition(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.Relational_expr_definitionContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.Relational_expr_definitionContext,i)


        def getRuleIndex(self):
            return one_for_allParser.RULE_relational_exprs

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterRelational_exprs" ):
                listener.enterRelational_exprs(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitRelational_exprs" ):
                listener.exitRelational_exprs(self)




    def relational_exprs(self):

        localctx = one_for_allParser.Relational_exprsContext(self, self._ctx, self.state)
        self.enterRule(localctx, 88, self.RULE_relational_exprs)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 446 
            self._errHandler.sync(self)
            _alt = 1
            while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                if _alt == 1:
                    self.state = 445
                    self.relational_expr_definition()

                else:
                    raise NoViableAltException(self)
                self.state = 448 
                self._errHandler.sync(self)
                _alt = self._interp.adaptivePredict(self._input,33,self._ctx)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Relational_expr_definitionContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def sumMinus_exprs(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.SumMinus_exprsContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.SumMinus_exprsContext,i)


        def neuro_relational(self):
            return self.getTypedRuleContext(one_for_allParser.Neuro_relationalContext,0)


        def token_same(self):
            return self.getTypedRuleContext(one_for_allParser.Token_sameContext,0)


        def token_different(self):
            return self.getTypedRuleContext(one_for_allParser.Token_differentContext,0)


        def token_greater(self):
            return self.getTypedRuleContext(one_for_allParser.Token_greaterContext,0)


        def token_greater_eq(self):
            return self.getTypedRuleContext(one_for_allParser.Token_greater_eqContext,0)


        def token_less(self):
            return self.getTypedRuleContext(one_for_allParser.Token_lessContext,0)


        def token_less_eq(self):
            return self.getTypedRuleContext(one_for_allParser.Token_less_eqContext,0)


        def getRuleIndex(self):
            return one_for_allParser.RULE_relational_expr_definition

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterRelational_expr_definition" ):
                listener.enterRelational_expr_definition(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitRelational_expr_definition" ):
                listener.exitRelational_expr_definition(self)




    def relational_expr_definition(self):

        localctx = one_for_allParser.Relational_expr_definitionContext(self, self._ctx, self.state)
        self.enterRule(localctx, 90, self.RULE_relational_expr_definition)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 450
            self.sumMinus_exprs()
            self.state = 462
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            if (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << one_for_allParser.TOK_DIFFERENT) | (1 << one_for_allParser.TOK_GREATER) | (1 << one_for_allParser.TOK_LESS) | (1 << one_for_allParser.TOK_GREATER_EQ) | (1 << one_for_allParser.TOK_LESS_EQ) | (1 << one_for_allParser.TOK_SAME))) != 0):
                self.state = 457
                self._errHandler.sync(self)
                token = self._input.LA(1)
                if token in [one_for_allParser.TOK_SAME]:
                    self.state = 451
                    self.token_same()
                    pass
                elif token in [one_for_allParser.TOK_DIFFERENT]:
                    self.state = 452
                    self.token_different()
                    pass
                elif token in [one_for_allParser.TOK_GREATER]:
                    self.state = 453
                    self.token_greater()
                    pass
                elif token in [one_for_allParser.TOK_GREATER_EQ]:
                    self.state = 454
                    self.token_greater_eq()
                    pass
                elif token in [one_for_allParser.TOK_LESS]:
                    self.state = 455
                    self.token_less()
                    pass
                elif token in [one_for_allParser.TOK_LESS_EQ]:
                    self.state = 456
                    self.token_less_eq()
                    pass
                else:
                    raise NoViableAltException(self)

                self.state = 459
                self.sumMinus_exprs()
                self.state = 460
                self.neuro_relational()


        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Neuro_relationalContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser


        def getRuleIndex(self):
            return one_for_allParser.RULE_neuro_relational

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterNeuro_relational" ):
                listener.enterNeuro_relational(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitNeuro_relational" ):
                listener.exitNeuro_relational(self)




    def neuro_relational(self):

        localctx = one_for_allParser.Neuro_relationalContext(self, self._ctx, self.state)
        self.enterRule(localctx, 92, self.RULE_neuro_relational)
        try:
            self.enterOuterAlt(localctx, 1)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Token_sameContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_SAME(self):
            return self.getToken(one_for_allParser.TOK_SAME, 0)

        def getRuleIndex(self):
            return one_for_allParser.RULE_token_same

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterToken_same" ):
                listener.enterToken_same(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitToken_same" ):
                listener.exitToken_same(self)




    def token_same(self):

        localctx = one_for_allParser.Token_sameContext(self, self._ctx, self.state)
        self.enterRule(localctx, 94, self.RULE_token_same)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 466
            self.match(one_for_allParser.TOK_SAME)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Token_differentContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_DIFFERENT(self):
            return self.getToken(one_for_allParser.TOK_DIFFERENT, 0)

        def getRuleIndex(self):
            return one_for_allParser.RULE_token_different

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterToken_different" ):
                listener.enterToken_different(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitToken_different" ):
                listener.exitToken_different(self)




    def token_different(self):

        localctx = one_for_allParser.Token_differentContext(self, self._ctx, self.state)
        self.enterRule(localctx, 96, self.RULE_token_different)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 468
            self.match(one_for_allParser.TOK_DIFFERENT)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Token_greaterContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_GREATER(self):
            return self.getToken(one_for_allParser.TOK_GREATER, 0)

        def getRuleIndex(self):
            return one_for_allParser.RULE_token_greater

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterToken_greater" ):
                listener.enterToken_greater(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitToken_greater" ):
                listener.exitToken_greater(self)




    def token_greater(self):

        localctx = one_for_allParser.Token_greaterContext(self, self._ctx, self.state)
        self.enterRule(localctx, 98, self.RULE_token_greater)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 470
            self.match(one_for_allParser.TOK_GREATER)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Token_greater_eqContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_GREATER_EQ(self):
            return self.getToken(one_for_allParser.TOK_GREATER_EQ, 0)

        def getRuleIndex(self):
            return one_for_allParser.RULE_token_greater_eq

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterToken_greater_eq" ):
                listener.enterToken_greater_eq(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitToken_greater_eq" ):
                listener.exitToken_greater_eq(self)




    def token_greater_eq(self):

        localctx = one_for_allParser.Token_greater_eqContext(self, self._ctx, self.state)
        self.enterRule(localctx, 100, self.RULE_token_greater_eq)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 472
            self.match(one_for_allParser.TOK_GREATER_EQ)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Token_lessContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_LESS(self):
            return self.getToken(one_for_allParser.TOK_LESS, 0)

        def getRuleIndex(self):
            return one_for_allParser.RULE_token_less

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterToken_less" ):
                listener.enterToken_less(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitToken_less" ):
                listener.exitToken_less(self)




    def token_less(self):

        localctx = one_for_allParser.Token_lessContext(self, self._ctx, self.state)
        self.enterRule(localctx, 102, self.RULE_token_less)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 474
            self.match(one_for_allParser.TOK_LESS)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Token_less_eqContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_LESS_EQ(self):
            return self.getToken(one_for_allParser.TOK_LESS_EQ, 0)

        def getRuleIndex(self):
            return one_for_allParser.RULE_token_less_eq

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterToken_less_eq" ):
                listener.enterToken_less_eq(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitToken_less_eq" ):
                listener.exitToken_less_eq(self)




    def token_less_eq(self):

        localctx = one_for_allParser.Token_less_eqContext(self, self._ctx, self.state)
        self.enterRule(localctx, 104, self.RULE_token_less_eq)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 476
            self.match(one_for_allParser.TOK_LESS_EQ)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class SumMinus_exprsContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def sumMinus_expr_definition(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.SumMinus_expr_definitionContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.SumMinus_expr_definitionContext,i)


        def getRuleIndex(self):
            return one_for_allParser.RULE_sumMinus_exprs

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterSumMinus_exprs" ):
                listener.enterSumMinus_exprs(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitSumMinus_exprs" ):
                listener.exitSumMinus_exprs(self)




    def sumMinus_exprs(self):

        localctx = one_for_allParser.SumMinus_exprsContext(self, self._ctx, self.state)
        self.enterRule(localctx, 106, self.RULE_sumMinus_exprs)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 479 
            self._errHandler.sync(self)
            _alt = 1
            while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                if _alt == 1:
                    self.state = 478
                    self.sumMinus_expr_definition()

                else:
                    raise NoViableAltException(self)
                self.state = 481 
                self._errHandler.sync(self)
                _alt = self._interp.adaptivePredict(self._input,36,self._ctx)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class SumMinus_expr_definitionContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def multiDiv_exprs(self):
            return self.getTypedRuleContext(one_for_allParser.MultiDiv_exprsContext,0)


        def neuro_sumMinus(self):
            return self.getTypedRuleContext(one_for_allParser.Neuro_sumMinusContext,0)


        def token_plus(self):
            return self.getTypedRuleContext(one_for_allParser.Token_plusContext,0)


        def token_minus(self):
            return self.getTypedRuleContext(one_for_allParser.Token_minusContext,0)


        def getRuleIndex(self):
            return one_for_allParser.RULE_sumMinus_expr_definition

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterSumMinus_expr_definition" ):
                listener.enterSumMinus_expr_definition(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitSumMinus_expr_definition" ):
                listener.exitSumMinus_expr_definition(self)




    def sumMinus_expr_definition(self):

        localctx = one_for_allParser.SumMinus_expr_definitionContext(self, self._ctx, self.state)
        self.enterRule(localctx, 108, self.RULE_sumMinus_expr_definition)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 483
            self.multiDiv_exprs()
            self.state = 484
            self.neuro_sumMinus()
            self.state = 487
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [one_for_allParser.TOK_PLUS]:
                self.state = 485
                self.token_plus()
                pass
            elif token in [one_for_allParser.TOK_MINUS]:
                self.state = 486
                self.token_minus()
                pass
            elif token in [one_for_allParser.STRING, one_for_allParser.FLOAT, one_for_allParser.INT, one_for_allParser.BOOLEAN, one_for_allParser.TOK_AND, one_for_allParser.TOK_OR, one_for_allParser.TOK_LPAREN, one_for_allParser.TOK_RPAREN, one_for_allParser.TOK_RBRACKET, one_for_allParser.TOK_DIFFERENT, one_for_allParser.TOK_GREATER, one_for_allParser.TOK_LESS, one_for_allParser.TOK_GREATER_EQ, one_for_allParser.TOK_LESS_EQ, one_for_allParser.TOK_SAME, one_for_allParser.TOK_SEMICOLON, one_for_allParser.TOK_COMMA, one_for_allParser.TOK_ID]:
                pass
            else:
                pass
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Neuro_sumMinusContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser


        def getRuleIndex(self):
            return one_for_allParser.RULE_neuro_sumMinus

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterNeuro_sumMinus" ):
                listener.enterNeuro_sumMinus(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitNeuro_sumMinus" ):
                listener.exitNeuro_sumMinus(self)




    def neuro_sumMinus(self):

        localctx = one_for_allParser.Neuro_sumMinusContext(self, self._ctx, self.state)
        self.enterRule(localctx, 110, self.RULE_neuro_sumMinus)
        try:
            self.enterOuterAlt(localctx, 1)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Token_plusContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_PLUS(self):
            return self.getToken(one_for_allParser.TOK_PLUS, 0)

        def getRuleIndex(self):
            return one_for_allParser.RULE_token_plus

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterToken_plus" ):
                listener.enterToken_plus(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitToken_plus" ):
                listener.exitToken_plus(self)




    def token_plus(self):

        localctx = one_for_allParser.Token_plusContext(self, self._ctx, self.state)
        self.enterRule(localctx, 112, self.RULE_token_plus)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 491
            self.match(one_for_allParser.TOK_PLUS)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Token_minusContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_MINUS(self):
            return self.getToken(one_for_allParser.TOK_MINUS, 0)

        def getRuleIndex(self):
            return one_for_allParser.RULE_token_minus

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterToken_minus" ):
                listener.enterToken_minus(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitToken_minus" ):
                listener.exitToken_minus(self)




    def token_minus(self):

        localctx = one_for_allParser.Token_minusContext(self, self._ctx, self.state)
        self.enterRule(localctx, 114, self.RULE_token_minus)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 493
            self.match(one_for_allParser.TOK_MINUS)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class MultiDiv_exprsContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def multiDiv_expr_definition(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.MultiDiv_expr_definitionContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.MultiDiv_expr_definitionContext,i)


        def getRuleIndex(self):
            return one_for_allParser.RULE_multiDiv_exprs

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterMultiDiv_exprs" ):
                listener.enterMultiDiv_exprs(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitMultiDiv_exprs" ):
                listener.exitMultiDiv_exprs(self)




    def multiDiv_exprs(self):

        localctx = one_for_allParser.MultiDiv_exprsContext(self, self._ctx, self.state)
        self.enterRule(localctx, 116, self.RULE_multiDiv_exprs)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 496 
            self._errHandler.sync(self)
            _alt = 1
            while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                if _alt == 1:
                    self.state = 495
                    self.multiDiv_expr_definition()

                else:
                    raise NoViableAltException(self)
                self.state = 498 
                self._errHandler.sync(self)
                _alt = self._interp.adaptivePredict(self._input,38,self._ctx)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class MultiDiv_expr_definitionContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def factor(self):
            return self.getTypedRuleContext(one_for_allParser.FactorContext,0)


        def neuro_multiDiv(self):
            return self.getTypedRuleContext(one_for_allParser.Neuro_multiDivContext,0)


        def token_multiplication(self):
            return self.getTypedRuleContext(one_for_allParser.Token_multiplicationContext,0)


        def token_division(self):
            return self.getTypedRuleContext(one_for_allParser.Token_divisionContext,0)


        def getRuleIndex(self):
            return one_for_allParser.RULE_multiDiv_expr_definition

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterMultiDiv_expr_definition" ):
                listener.enterMultiDiv_expr_definition(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitMultiDiv_expr_definition" ):
                listener.exitMultiDiv_expr_definition(self)




    def multiDiv_expr_definition(self):

        localctx = one_for_allParser.MultiDiv_expr_definitionContext(self, self._ctx, self.state)
        self.enterRule(localctx, 118, self.RULE_multiDiv_expr_definition)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 500
            self.factor()
            self.state = 501
            self.neuro_multiDiv()
            self.state = 504
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [one_for_allParser.TOK_MULTIPLICATION]:
                self.state = 502
                self.token_multiplication()
                pass
            elif token in [one_for_allParser.TOK_DIVISION]:
                self.state = 503
                self.token_division()
                pass
            elif token in [one_for_allParser.STRING, one_for_allParser.FLOAT, one_for_allParser.INT, one_for_allParser.BOOLEAN, one_for_allParser.TOK_AND, one_for_allParser.TOK_OR, one_for_allParser.TOK_LPAREN, one_for_allParser.TOK_RPAREN, one_for_allParser.TOK_RBRACKET, one_for_allParser.TOK_PLUS, one_for_allParser.TOK_MINUS, one_for_allParser.TOK_DIFFERENT, one_for_allParser.TOK_GREATER, one_for_allParser.TOK_LESS, one_for_allParser.TOK_GREATER_EQ, one_for_allParser.TOK_LESS_EQ, one_for_allParser.TOK_SAME, one_for_allParser.TOK_SEMICOLON, one_for_allParser.TOK_COMMA, one_for_allParser.TOK_ID]:
                pass
            else:
                pass
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Neuro_multiDivContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser


        def getRuleIndex(self):
            return one_for_allParser.RULE_neuro_multiDiv

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterNeuro_multiDiv" ):
                listener.enterNeuro_multiDiv(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitNeuro_multiDiv" ):
                listener.exitNeuro_multiDiv(self)




    def neuro_multiDiv(self):

        localctx = one_for_allParser.Neuro_multiDivContext(self, self._ctx, self.state)
        self.enterRule(localctx, 120, self.RULE_neuro_multiDiv)
        try:
            self.enterOuterAlt(localctx, 1)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Token_multiplicationContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_MULTIPLICATION(self):
            return self.getToken(one_for_allParser.TOK_MULTIPLICATION, 0)

        def getRuleIndex(self):
            return one_for_allParser.RULE_token_multiplication

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterToken_multiplication" ):
                listener.enterToken_multiplication(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitToken_multiplication" ):
                listener.exitToken_multiplication(self)




    def token_multiplication(self):

        localctx = one_for_allParser.Token_multiplicationContext(self, self._ctx, self.state)
        self.enterRule(localctx, 122, self.RULE_token_multiplication)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 508
            self.match(one_for_allParser.TOK_MULTIPLICATION)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Token_divisionContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_DIVISION(self):
            return self.getToken(one_for_allParser.TOK_DIVISION, 0)

        def getRuleIndex(self):
            return one_for_allParser.RULE_token_division

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterToken_division" ):
                listener.enterToken_division(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitToken_division" ):
                listener.exitToken_division(self)




    def token_division(self):

        localctx = one_for_allParser.Token_divisionContext(self, self._ctx, self.state)
        self.enterRule(localctx, 124, self.RULE_token_division)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 510
            self.match(one_for_allParser.TOK_DIVISION)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class FactorContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def token_lparen(self):
            return self.getTypedRuleContext(one_for_allParser.Token_lparenContext,0)


        def expressions(self):
            return self.getTypedRuleContext(one_for_allParser.ExpressionsContext,0)


        def token_rparen(self):
            return self.getTypedRuleContext(one_for_allParser.Token_rparenContext,0)


        def constant(self):
            return self.getTypedRuleContext(one_for_allParser.ConstantContext,0)


        def getRuleIndex(self):
            return one_for_allParser.RULE_factor

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterFactor" ):
                listener.enterFactor(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitFactor" ):
                listener.exitFactor(self)




    def factor(self):

        localctx = one_for_allParser.FactorContext(self, self._ctx, self.state)
        self.enterRule(localctx, 126, self.RULE_factor)
        try:
            self.state = 517
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [one_for_allParser.TOK_LPAREN]:
                self.enterOuterAlt(localctx, 1)
                self.state = 512
                self.token_lparen()
                self.state = 513
                self.expressions()
                self.state = 514
                self.token_rparen()
                pass
            elif token in [one_for_allParser.STRING, one_for_allParser.FLOAT, one_for_allParser.INT, one_for_allParser.BOOLEAN, one_for_allParser.TOK_ID]:
                self.enterOuterAlt(localctx, 2)
                self.state = 516
                self.constant()
                pass
            else:
                raise NoViableAltException(self)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Token_lparenContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_LPAREN(self):
            return self.getToken(one_for_allParser.TOK_LPAREN, 0)

        def getRuleIndex(self):
            return one_for_allParser.RULE_token_lparen

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterToken_lparen" ):
                listener.enterToken_lparen(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitToken_lparen" ):
                listener.exitToken_lparen(self)




    def token_lparen(self):

        localctx = one_for_allParser.Token_lparenContext(self, self._ctx, self.state)
        self.enterRule(localctx, 128, self.RULE_token_lparen)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 519
            self.match(one_for_allParser.TOK_LPAREN)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Token_rparenContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_RPAREN(self):
            return self.getToken(one_for_allParser.TOK_RPAREN, 0)

        def getRuleIndex(self):
            return one_for_allParser.RULE_token_rparen

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterToken_rparen" ):
                listener.enterToken_rparen(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitToken_rparen" ):
                listener.exitToken_rparen(self)




    def token_rparen(self):

        localctx = one_for_allParser.Token_rparenContext(self, self._ctx, self.state)
        self.enterRule(localctx, 130, self.RULE_token_rparen)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 521
            self.match(one_for_allParser.TOK_RPAREN)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class ConstantContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def FLOAT(self):
            return self.getToken(one_for_allParser.FLOAT, 0)

        def INT(self):
            return self.getToken(one_for_allParser.INT, 0)

        def STRING(self):
            return self.getToken(one_for_allParser.STRING, 0)

        def BOOLEAN(self):
            return self.getToken(one_for_allParser.BOOLEAN, 0)

        def id_(self):
            return self.getTypedRuleContext(one_for_allParser.Id_Context,0)


        def getRuleIndex(self):
            return one_for_allParser.RULE_constant

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterConstant" ):
                listener.enterConstant(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitConstant" ):
                listener.exitConstant(self)




    def constant(self):

        localctx = one_for_allParser.ConstantContext(self, self._ctx, self.state)
        self.enterRule(localctx, 132, self.RULE_constant)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 528
            self._errHandler.sync(self)
            token = self._input.LA(1)
            if token in [one_for_allParser.FLOAT]:
                self.state = 523
                self.match(one_for_allParser.FLOAT)
                pass
            elif token in [one_for_allParser.INT]:
                self.state = 524
                self.match(one_for_allParser.INT)
                pass
            elif token in [one_for_allParser.STRING]:
                self.state = 525
                self.match(one_for_allParser.STRING)
                pass
            elif token in [one_for_allParser.BOOLEAN]:
                self.state = 526
                self.match(one_for_allParser.BOOLEAN)
                pass
            elif token in [one_for_allParser.TOK_ID]:
                self.state = 527
                self.id_()
                pass
            else:
                raise NoViableAltException(self)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Id_Context(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def id_definition_(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.Id_definition_Context)
            else:
                return self.getTypedRuleContext(one_for_allParser.Id_definition_Context,i)


        def getRuleIndex(self):
            return one_for_allParser.RULE_id_

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterId_" ):
                listener.enterId_(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitId_" ):
                listener.exitId_(self)




    def id_(self):

        localctx = one_for_allParser.Id_Context(self, self._ctx, self.state)
        self.enterRule(localctx, 134, self.RULE_id_)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 531 
            self._errHandler.sync(self)
            _alt = 1
            while _alt!=2 and _alt!=ATN.INVALID_ALT_NUMBER:
                if _alt == 1:
                    self.state = 530
                    self.id_definition_()

                else:
                    raise NoViableAltException(self)
                self.state = 533 
                self._errHandler.sync(self)
                _alt = self._interp.adaptivePredict(self._input,42,self._ctx)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Id_definition_Context(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_ID(self):
            return self.getToken(one_for_allParser.TOK_ID, 0)

        def evaluate_class(self):
            return self.getTypedRuleContext(one_for_allParser.Evaluate_classContext,0)


        def evaluate_function(self):
            return self.getTypedRuleContext(one_for_allParser.Evaluate_functionContext,0)


        def evaluate_array(self):
            return self.getTypedRuleContext(one_for_allParser.Evaluate_arrayContext,0)


        def init_class(self):
            return self.getTypedRuleContext(one_for_allParser.Init_classContext,0)


        def getRuleIndex(self):
            return one_for_allParser.RULE_id_definition_

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterId_definition_" ):
                listener.enterId_definition_(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitId_definition_" ):
                listener.exitId_definition_(self)




    def id_definition_(self):

        localctx = one_for_allParser.Id_definition_Context(self, self._ctx, self.state)
        self.enterRule(localctx, 136, self.RULE_id_definition_)
        try:
            self.state = 540
            self._errHandler.sync(self)
            la_ = self._interp.adaptivePredict(self._input,43,self._ctx)
            if la_ == 1:
                self.enterOuterAlt(localctx, 1)
                self.state = 535
                self.match(one_for_allParser.TOK_ID)
                pass

            elif la_ == 2:
                self.enterOuterAlt(localctx, 2)
                self.state = 536
                self.evaluate_class()
                pass

            elif la_ == 3:
                self.enterOuterAlt(localctx, 3)
                self.state = 537
                self.evaluate_function()
                pass

            elif la_ == 4:
                self.enterOuterAlt(localctx, 4)
                self.state = 538
                self.evaluate_array()
                pass

            elif la_ == 5:
                self.enterOuterAlt(localctx, 5)
                self.state = 539
                self.init_class()
                pass


        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Init_classContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_ID(self):
            return self.getToken(one_for_allParser.TOK_ID, 0)

        def TOK_EQUAL(self):
            return self.getToken(one_for_allParser.TOK_EQUAL, 0)

        def TOK_INIT(self):
            return self.getToken(one_for_allParser.TOK_INIT, 0)

        def TOK_LPAREN(self):
            return self.getToken(one_for_allParser.TOK_LPAREN, 0)

        def neuro_createConstructor(self):
            return self.getTypedRuleContext(one_for_allParser.Neuro_createConstructorContext,0)


        def TOK_RPAREN(self):
            return self.getToken(one_for_allParser.TOK_RPAREN, 0)

        def TOK_SEMICOLON(self):
            return self.getToken(one_for_allParser.TOK_SEMICOLON, 0)

        def expressions(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.ExpressionsContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.ExpressionsContext,i)


        def neuro_initEval(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.Neuro_initEvalContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.Neuro_initEvalContext,i)


        def TOK_COMMA(self, i:int=None):
            if i is None:
                return self.getTokens(one_for_allParser.TOK_COMMA)
            else:
                return self.getToken(one_for_allParser.TOK_COMMA, i)

        def getRuleIndex(self):
            return one_for_allParser.RULE_init_class

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterInit_class" ):
                listener.enterInit_class(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitInit_class" ):
                listener.exitInit_class(self)




    def init_class(self):

        localctx = one_for_allParser.Init_classContext(self, self._ctx, self.state)
        self.enterRule(localctx, 138, self.RULE_init_class)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 542
            self.match(one_for_allParser.TOK_ID)
            self.state = 543
            self.match(one_for_allParser.TOK_EQUAL)
            self.state = 544
            self.match(one_for_allParser.TOK_INIT)
            self.state = 545
            self.match(one_for_allParser.TOK_LPAREN)
            self.state = 553
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << one_for_allParser.STRING) | (1 << one_for_allParser.FLOAT) | (1 << one_for_allParser.INT) | (1 << one_for_allParser.BOOLEAN) | (1 << one_for_allParser.TOK_LPAREN) | (1 << one_for_allParser.TOK_ID))) != 0):
                self.state = 546
                self.expressions()
                self.state = 547
                self.neuro_initEval()
                self.state = 549
                self._errHandler.sync(self)
                _la = self._input.LA(1)
                if _la==one_for_allParser.TOK_COMMA:
                    self.state = 548
                    self.match(one_for_allParser.TOK_COMMA)


                self.state = 555
                self._errHandler.sync(self)
                _la = self._input.LA(1)

            self.state = 556
            self.neuro_createConstructor()
            self.state = 557
            self.match(one_for_allParser.TOK_RPAREN)
            self.state = 558
            self.match(one_for_allParser.TOK_SEMICOLON)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Neuro_initEvalContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser


        def getRuleIndex(self):
            return one_for_allParser.RULE_neuro_initEval

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterNeuro_initEval" ):
                listener.enterNeuro_initEval(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitNeuro_initEval" ):
                listener.exitNeuro_initEval(self)




    def neuro_initEval(self):

        localctx = one_for_allParser.Neuro_initEvalContext(self, self._ctx, self.state)
        self.enterRule(localctx, 140, self.RULE_neuro_initEval)
        try:
            self.enterOuterAlt(localctx, 1)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Neuro_createConstructorContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser


        def getRuleIndex(self):
            return one_for_allParser.RULE_neuro_createConstructor

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterNeuro_createConstructor" ):
                listener.enterNeuro_createConstructor(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitNeuro_createConstructor" ):
                listener.exitNeuro_createConstructor(self)




    def neuro_createConstructor(self):

        localctx = one_for_allParser.Neuro_createConstructorContext(self, self._ctx, self.state)
        self.enterRule(localctx, 142, self.RULE_neuro_createConstructor)
        try:
            self.enterOuterAlt(localctx, 1)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Evaluate_classContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_ID(self, i:int=None):
            if i is None:
                return self.getTokens(one_for_allParser.TOK_ID)
            else:
                return self.getToken(one_for_allParser.TOK_ID, i)

        def TOK_DOT(self):
            return self.getToken(one_for_allParser.TOK_DOT, 0)

        def TOK_LPAREN(self):
            return self.getToken(one_for_allParser.TOK_LPAREN, 0)

        def expressions(self):
            return self.getTypedRuleContext(one_for_allParser.ExpressionsContext,0)


        def TOK_RPAREN(self):
            return self.getToken(one_for_allParser.TOK_RPAREN, 0)

        def getRuleIndex(self):
            return one_for_allParser.RULE_evaluate_class

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterEvaluate_class" ):
                listener.enterEvaluate_class(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitEvaluate_class" ):
                listener.exitEvaluate_class(self)




    def evaluate_class(self):

        localctx = one_for_allParser.Evaluate_classContext(self, self._ctx, self.state)
        self.enterRule(localctx, 144, self.RULE_evaluate_class)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 564
            self.match(one_for_allParser.TOK_ID)
            self.state = 565
            self.match(one_for_allParser.TOK_DOT)
            self.state = 566
            self.match(one_for_allParser.TOK_ID)
            self.state = 571
            self._errHandler.sync(self)
            la_ = self._interp.adaptivePredict(self._input,46,self._ctx)
            if la_ == 1:
                self.state = 567
                self.match(one_for_allParser.TOK_LPAREN)
                self.state = 568
                self.expressions()
                self.state = 569
                self.match(one_for_allParser.TOK_RPAREN)


        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Evaluate_functionContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_ID(self):
            return self.getToken(one_for_allParser.TOK_ID, 0)

        def TOK_LPAREN(self):
            return self.getToken(one_for_allParser.TOK_LPAREN, 0)

        def neuro_params(self):
            return self.getTypedRuleContext(one_for_allParser.Neuro_paramsContext,0)


        def TOK_RPAREN(self):
            return self.getToken(one_for_allParser.TOK_RPAREN, 0)

        def expressions(self, i:int=None):
            if i is None:
                return self.getTypedRuleContexts(one_for_allParser.ExpressionsContext)
            else:
                return self.getTypedRuleContext(one_for_allParser.ExpressionsContext,i)


        def TOK_COMMA(self, i:int=None):
            if i is None:
                return self.getTokens(one_for_allParser.TOK_COMMA)
            else:
                return self.getToken(one_for_allParser.TOK_COMMA, i)

        def getRuleIndex(self):
            return one_for_allParser.RULE_evaluate_function

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterEvaluate_function" ):
                listener.enterEvaluate_function(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitEvaluate_function" ):
                listener.exitEvaluate_function(self)




    def evaluate_function(self):

        localctx = one_for_allParser.Evaluate_functionContext(self, self._ctx, self.state)
        self.enterRule(localctx, 146, self.RULE_evaluate_function)
        self._la = 0 # Token type
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 573
            self.match(one_for_allParser.TOK_ID)
            self.state = 574
            self.match(one_for_allParser.TOK_LPAREN)
            self.state = 581
            self._errHandler.sync(self)
            _la = self._input.LA(1)
            while (((_la) & ~0x3f) == 0 and ((1 << _la) & ((1 << one_for_allParser.STRING) | (1 << one_for_allParser.FLOAT) | (1 << one_for_allParser.INT) | (1 << one_for_allParser.BOOLEAN) | (1 << one_for_allParser.TOK_LPAREN) | (1 << one_for_allParser.TOK_ID))) != 0):
                self.state = 575
                self.expressions()
                self.state = 577
                self._errHandler.sync(self)
                _la = self._input.LA(1)
                if _la==one_for_allParser.TOK_COMMA:
                    self.state = 576
                    self.match(one_for_allParser.TOK_COMMA)


                self.state = 583
                self._errHandler.sync(self)
                _la = self._input.LA(1)

            self.state = 584
            self.neuro_params()
            self.state = 585
            self.match(one_for_allParser.TOK_RPAREN)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Neuro_paramsContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser


        def getRuleIndex(self):
            return one_for_allParser.RULE_neuro_params

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterNeuro_params" ):
                listener.enterNeuro_params(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitNeuro_params" ):
                listener.exitNeuro_params(self)




    def neuro_params(self):

        localctx = one_for_allParser.Neuro_paramsContext(self, self._ctx, self.state)
        self.enterRule(localctx, 148, self.RULE_neuro_params)
        try:
            self.enterOuterAlt(localctx, 1)

        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx

    class Evaluate_arrayContext(ParserRuleContext):

        def __init__(self, parser, parent:ParserRuleContext=None, invokingState:int=-1):
            super().__init__(parent, invokingState)
            self.parser = parser

        def TOK_ID(self):
            return self.getToken(one_for_allParser.TOK_ID, 0)

        def TOK_LBRACKET(self):
            return self.getToken(one_for_allParser.TOK_LBRACKET, 0)

        def expressions(self):
            return self.getTypedRuleContext(one_for_allParser.ExpressionsContext,0)


        def TOK_RBRACKET(self):
            return self.getToken(one_for_allParser.TOK_RBRACKET, 0)

        def getRuleIndex(self):
            return one_for_allParser.RULE_evaluate_array

        def enterRule(self, listener:ParseTreeListener):
            if hasattr( listener, "enterEvaluate_array" ):
                listener.enterEvaluate_array(self)

        def exitRule(self, listener:ParseTreeListener):
            if hasattr( listener, "exitEvaluate_array" ):
                listener.exitEvaluate_array(self)




    def evaluate_array(self):

        localctx = one_for_allParser.Evaluate_arrayContext(self, self._ctx, self.state)
        self.enterRule(localctx, 150, self.RULE_evaluate_array)
        try:
            self.enterOuterAlt(localctx, 1)
            self.state = 589
            self.match(one_for_allParser.TOK_ID)
            self.state = 590
            self.match(one_for_allParser.TOK_LBRACKET)
            self.state = 591
            self.expressions()
            self.state = 592
            self.match(one_for_allParser.TOK_RBRACKET)
        except RecognitionException as re:
            localctx.exception = re
            self._errHandler.reportError(self, re)
            self._errHandler.recover(self, re)
        finally:
            self.exitRule()
        return localctx





